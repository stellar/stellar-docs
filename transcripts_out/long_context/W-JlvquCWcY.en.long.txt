Hi everyone hi everyone hope everybody is having a fantastic hope everybody is having a fantastic. hope everybody is having a fantastic friday morning afternoon wherever you friday morning afternoon wherever you. Friday morning afternoon wherever you are are are my name is devneal I'm a software. My name is devneal I'm a software my name is devneal I'm a software engineer at sdf on the voyager team. Engineer at sdf on the voyager team engineer at sdf on the voyager team we focus on exploring the Stellar. We focus on exploring the Stellar we focus on exploring the Stellar ecosystem through data. Ecosystem through data ecosystem through data analytics and liquidity today i'll be. Analytics and liquidity today i'll be analytics and liquidity today i'll be talking about data analytics on Stellar. Talking about data analytics on Stellar talking about data analytics on Stellar so the goal of our team as well as a lot. So the goal of our team as well as a lot so the goal of our team as well as a lot. Of the work that I do at sdf of the work that I do at sdf of the work that I do at sdf. Is to do the fundamental meta work that is to do the fundamental meta work that is to do the fundamental meta work that. Powers the rest of the network powers the rest of the network powers the rest of the network. How can we ensure that assets have how can we ensure that assets have how can we ensure that assets have. Robust markets robust markets robust markets how can we improve the visibility of the. How can we improve the visibility of the how can we improve the visibility of the. Network both inside network both inside network both inside and outside sdf and how do we use data. And outside sdf and how do we use data and outside sdf and how do we use data to further drive network growth. To further drive network growth to further drive network growth in this talk i'll be talking about the. In this talk i'll be talking about the in this talk i'll be talking about the first version of our data analytics. First version of our data analytics first version of our data analytics system system. System targeted and answering those three targeted and answering those three targeted and answering those three. Questions as well as many others questions as well as many others questions as well as many others. So who is this helpful for anyone so who is this helpful for anyone so who is this helpful for anyone. Interested in interested in interested in one building analytics pipelines from one building analytics pipelines from. One building analytics pipelines from zero to one zero to one zero to one I hope our experience is generally. I hope our experience is generally I hope our experience is generally helpful to people who have a bunch of. Helpful to people who have a bunch of helpful to people who have a bunch of data data. Data that are just trying to build out some that are just trying to build out some. That are just trying to build out some analytic system analytic system analytic system. Two exploring the Stellar network i'll two exploring the Stellar network i'll two exploring the Stellar network i'll. Present some useful access patterns present some useful access patterns present some useful access patterns. Tips for navigating the Stellar data set tips for navigating the Stellar data set. Tips for navigating the Stellar data set and a few illustrative examples and a few illustrative examples. And a few illustrative examples with basic sql knowledge you can ask with basic sql knowledge you can ask. With basic sql knowledge you can ask some powerful network-wide questions some powerful network-wide questions. Some powerful network-wide questions three scaling analytics from one to one three scaling analytics from one to one. Three scaling analytics from one to one hundred hundred hundred if you have a working data pipeline. If you have a working data pipeline if you have a working data pipeline what's next i'll share some of my. What's next i'll share some of my what's next i'll share some of my thoughts on the subject. Thoughts on the subject thoughts on the subject and i'd love to hear your wants and i'd love to hear your wants. And i'd love to hear your wants as a brief roadmap of the talk it'll be as a brief roadmap of the talk it'll be. As a brief roadmap of the talk it'll be in four parts in four parts in four parts. First design what we wanted to build first design what we wanted to build first design what we wanted to build. Second implementation how we built it second implementation how we built it second implementation how we built it. Design and implementation are the meat design and implementation are the meat design and implementation are the meat. Of this talk of this talk of this talk as it is an engineering talk after all as it is an engineering talk after all. As it is an engineering talk after all third analysis third analysis third analysis. I'll display some interesting queries i'll display some interesting queries i'll display some interesting queries. Along with some strategic tips on using along with some strategic tips on using along with some strategic tips on using. Our public data set our public data set our public data set in the interest of time and network. In the interest of time and network in the interest of time and network connections over the talk. Connections over the talk connections over the talk I'm not going to live code but I will. I'm not going to live code but I will I'm not going to live code but I will share links for folks do their own. Share links for folks do their own share links for folks do their own exploring exploring. Exploring and finally next steps what's in the and finally next steps what's in the. And finally next steps what's in the pipeline no pun intended for data pipeline no pun intended for data. Pipeline no pun intended for data analytics analytics analytics I note that if you have questions. I note that if you have questions I note that if you have questions there's a qr code. There's a qr code there's a qr code on the youtube and you can also ask on the youtube and you can also ask. On the youtube and you can also ask questions of the youtube chat questions of the youtube chat. Questions of the youtube chat and i'll be answering those questions at and i'll be answering those questions at. And i'll be answering those questions at the end to make sure I get through all the end to make sure I get through all. The end to make sure I get through all this material this material this material so first design. To understand the design goals let's to understand the design goals let's first talk about our motivations. First talk about our motivations first talk about our motivations why did we even want a cloud scale data. Why did we even want a cloud scale data why did we even want a cloud scale data pipeline. Pipeline pipeline ultimately we want to quickly and ultimately we want to quickly and. Ultimately we want to quickly and efficiently generate the histories of efficiently generate the histories of. Efficiently generate the histories of assets accounts markets whatever over assets accounts markets whatever over. Assets accounts markets whatever over the history of the network the history of the network. The history of the network the primary use case is internal the primary use case is internal. The primary use case is internal business analytics we wanted to make it business analytics we wanted to make it. Business analytics we wanted to make it as as as easy as possible for our business. Easy as possible for our business easy as possible for our business development and ecosystem teams. Development and ecosystem teams development and ecosystem teams to understand the effects of their. To understand the effects of their to understand the effects of their efforts so Stellar uses the widely used. Efforts so Stellar uses the widely used efforts so Stellar uses the widely used database as some postgres which has been. Database as some postgres which has been database as some postgres which has been. An industry standard for an industry standard for an industry standard for 20 25 years so Stellar core writes data. 20 25 years so Stellar core writes data 20 25 years so Stellar core writes data to postgres tables. To postgres tables to postgres tables and then horizon our api to Stellar core and then horizon our api to Stellar core. And then horizon our api to Stellar core uses uses uses the core data but it also has its own. The core data but it also has its own the core data but it also has its own database because it's a web application. Database because it's a web application database because it's a web application so the pros of this are that it's well. So the pros of this are that it's well so the pros of this are that it's well known and well documented. Known and well documented known and well documented it's great for tran processing a bunch. It's great for tran processing a bunch it's great for tran processing a bunch of online transactions. Of online transactions of online transactions when there's a bunch coming into you in. When there's a bunch coming into you in when there's a bunch coming into you in a highly concurrent heavy write. A highly concurrent heavy write a highly concurrent heavy write environment environment. Environment the cons are also pretty well the cons are also pretty well the cons are also pretty well. Documented documented documented it's slow for historical queries for it's slow for historical queries for. It's slow for historical queries for specific column values specific column values. Specific column values which makes it much worse for analytics which makes it much worse for analytics. Which makes it much worse for analytics horizons database structure and indices horizons database structure and indices. Horizons database structure and indices are optimized for the exposed api of are optimized for the exposed api of. Are optimized for the exposed api of verizon verizon verizon that also means that if you're trying to. That also means that if you're trying to that also means that if you're trying to. Do deeper queries across a bunch of do deeper queries across a bunch of do deeper queries across a bunch of. Different accounts or tables different accounts or tables different accounts or tables. It quickly becomes inefficient so for it quickly becomes inefficient so for it quickly becomes inefficient so for. Example complex joins or filters example complex joins or filters example complex joins or filters. Become really extremely time inefficient become really extremely time inefficient. Become really extremely time inefficient apps and indexes apps and indexes apps and indexes. A good example of this would be trying a good example of this would be trying a good example of this would be trying. To do analysis of the network but to do analysis of the network but to do analysis of the network but. Excluding excluding excluding arbitrage operations because that would arbitrage operations because that would. Arbitrage operations because that would require a bunch of joints of different require a bunch of joints of different. Require a bunch of joints of different tables tables tables and then now you have to make filters. And then now you have to make filters and then now you have to make filters over a really really big table. Over a really really big table over a really really big table so to understand behavior at scale it. So to understand behavior at scale it so to understand behavior at scale it became pretty clear to us that we would. Became pretty clear to us that we would became pretty clear to us that we would have to build some new infrastructure. It's also important to talk about our it's also important to talk about our goals so above all. Goals so above all goals so above all we wanted value for internal we wanted value for internal. We wanted value for internal stakeholders this is a really important stakeholders this is a really important. Stakeholders this is a really important node when you're building data products node when you're building data products. Node when you're building data products it's really easy to nerd out and build it's really easy to nerd out and build. It's really easy to nerd out and build something that's really cool for something that's really cool for. Something that's really cool for engineers engineers engineers but the end user is always your. But the end user is always your but the end user is always your non-technical users if product. Non-technical users if product non-technical users if product guarantees guarantees. Guarantees don't align with business needs then you don't align with business needs then you. Don't align with business needs then you won't ship the right solution for your won't ship the right solution for your. Won't ship the right solution for your end users end users end users and even worse you might just make more. And even worse you might just make more and even worse you might just make more work for yourself because you have to. Work for yourself because you have to work for yourself because you have to onboard a bunch of people into a. Onboard a bunch of people into a onboard a bunch of people into a non-intuitive system. Non-intuitive system non-intuitive system second open source or open access open second open source or open access open. Second open source or open access open source is really core to fdf dna source is really core to fdf dna. Source is really core to fdf dna and we want to support open source tools and we want to support open source tools. And we want to support open source tools wherever possible wherever possible wherever possible. Of course some things require spend like of course some things require spend like. Of course some things require spend like cloud infrastructure cloud infrastructure. Cloud infrastructure but we want to optimize for open access but we want to optimize for open access. But we want to optimize for open access in the organization in the organization in the organization. Followed by easy public access third followed by easy public access third followed by easy public access third. A daily updated data set well some a daily updated data set well some a daily updated data set well some. Businesses need real-time updates businesses need real-time updates businesses need real-time updates. At the point that we were when we at the point that we were when we at the point that we were when we. Started building this daily updates were started building this daily updates were. Started building this daily updates were sufficient for the course grain metrics sufficient for the course grain metrics. Sufficient for the course grain metrics that we wanted to do that we wanted to do. That we wanted to do fourth seamless integration with our fourth seamless integration with our. Fourth seamless integration with our current staff current staff current staff as mentioned before we rely heavily on. As mentioned before we rely heavily on as mentioned before we rely heavily on postgres. Postgres postgres as our databases and when you have as our databases and when you have. As our databases and when you have existing tools existing tools existing tools you need to make sure that support for. You need to make sure that support for you need to make sure that support for those tools is well tested in anything. Those tools is well tested in anything those tools is well tested in anything you bolt onto your system. You bolt onto your system you bolt onto your system additionally it had to also be deployed. Additionally it had to also be deployed additionally it had to also be deployed easily. Easily easily it had to be in-house controlled on our it had to be in-house controlled on our. It had to be in-house controlled on our infrastructure and easy to deploy by our infrastructure and easy to deploy by our. Infrastructure and easy to deploy by our site for liability and ops team site for liability and ops team. Site for liability and ops team so our stack last year migrated from so our stack last year migrated from. So our stack last year migrated from puppet to docker and kubernetes puppet to docker and kubernetes. Puppet to docker and kubernetes so we needed technology that easily so we needed technology that easily. So we needed technology that easily integrated with this and for some quick integrated with this and for some quick. Integrated with this and for some quick buzzword explanation buzzword explanation. Buzzword explanation puppet is a legacy system administration puppet is a legacy system administration. Puppet is a legacy system administration software docker lets you software docker lets you. Software docker lets you contain custom programs in their contain custom programs in their. Contain custom programs in their environment and kubernetes is environment and kubernetes is. Environment and kubernetes is orchestration software that lets you orchestration software that lets you. Orchestration software that lets you decide how those containers decide how those containers. Decide how those containers are then deployed and run and fifth and are then deployed and run and fifth and. Are then deployed and run and fifth and finally easy metrics and visualization finally easy metrics and visualization. Finally easy metrics and visualization this is pretty self-explanatory it this is pretty self-explanatory it. this is pretty self-explanatory it lowers the bar for non-technical users lowers the bar for non-technical users. Lowers the bar for non-technical users and it brings much more value to the and it brings much more value to the. And it brings much more value to the organization as a whole so many of the requirements about birth. So many of the requirements about birth fuzzy some are more technical and tools fuzzy some are more technical and tools. Fuzzy some are more technical and tools oriented oriented oriented so how do those break down into. So how do those break down into so how do those break down into technical decisions. Technical decisions technical decisions so this is ordered from most to least so this is ordered from most to least. So this is ordered from most to least defined defined defined as a deployment infrastructure we would. As a deployment infrastructure we would as a deployment infrastructure we would use docker and kubernetes. Use docker and kubernetes use docker and kubernetes this would be important for this would be important for. This would be important for orchestrating software having regularly orchestrating software having regularly. Orchestrating software having regularly scheduled cron jobs and the like scheduled cron jobs and the like. Scheduled cron jobs and the like it was already our technical stack so we it was already our technical stack so we. It was already our technical stack so we needed to play with it needed to play with it. Needed to play with it second the cloud scale warehouse this second the cloud scale warehouse this. Second the cloud scale warehouse this needed a bunch of capabilities needed a bunch of capabilities. Needed a bunch of capabilities determined by what I just said determined by what I just said. Determined by what I just said it had to have scripting abilities it had to have scripting abilities. It had to have scripting abilities really good postgres integration really good postgres integration. Really good postgres integration and really easy organization-wide and really easy organization-wide. And really easy organization-wide credentialing so all engineers and credentialing so all engineers and. Credentialing so all engineers and non-engineers non-engineers non-engineers could easily access the warehouse and. Could easily access the warehouse and could easily access the warehouse and make their own queries. Make their own queries make their own queries third metrics and visualization this was. Third metrics and visualization this was third metrics and visualization this was. The least defined for sure the least defined for sure the least defined for sure we decided that it would be secondary to. We decided that it would be secondary to we decided that it would be secondary to. A data warehouse because ultimately the a data warehouse because ultimately the a data warehouse because ultimately the. Engine engine engine matters more than whatever you're doing matters more than whatever you're doing. Matters more than whatever you're doing on top of it but we did know that we on top of it but we did know that we. On top of it but we did know that we want this to be open source want this to be open source. Want this to be open source free and easy for non-technical users free and easy for non-technical users. Free and easy for non-technical users through something like the drag and drop interface. Interface let's now talk about implementation so the first was infrastructure docker. So the first was infrastructure docker and kubernetes and kubernetes and kubernetes. While this decision was made for us some while this decision was made for us some. While this decision was made for us some details of it made everything a lot details of it made everything a lot. Details of it made everything a lot easier easier easier which is what commonly happens when you. Which is what commonly happens when you which is what commonly happens when you have to integrate with an existing stack. Have to integrate with an existing stack have to integrate with an existing stack. Docker-based containerization gave us a docker-based containerization gave us a docker-based containerization gave us a. Really easy standard for evaluation of really easy standard for evaluation of really easy standard for evaluation of. Other tools other tools other tools particularly visualization could it be particularly visualization could it be. Particularly visualization could it be easily deployed on our infrastructure easily deployed on our infrastructure. Easily deployed on our infrastructure second kubernetes cron jobs gave us an second kubernetes cron jobs gave us an. Second kubernetes cron jobs gave us an easy scheduling method easy scheduling method. Easy scheduling method for running scripts deployed via docker for running scripts deployed via docker. For running scripts deployed via docker we could just set a schedule and run the we could just set a schedule and run the. We could just set a schedule and run the procedure as procedure as procedure as is it was also really easy to integrate. Is it was also really easy to integrate is it was also really easy to integrate the postgres cluster. The postgres cluster the postgres cluster it was easy to provision external it was easy to provision external. It was easy to provision external storage in case we needed to have storage in case we needed to have. Storage in case we needed to have external memory for the data pipeline external memory for the data pipeline. External memory for the data pipeline and it also allowed for retries on and it also allowed for retries on. And it also allowed for retries on failure failure failure in all this is a really good deployment. In all this is a really good deployment in all this is a really good deployment stack and it's pretty clear why it's. Stack and it's pretty clear why it's stack and it's pretty clear why it's become the modern stack of choice. Become the modern stack of choice become the modern stack of choice it's really good for integrating a lot. It's really good for integrating a lot it's really good for integrating a lot of different technology it's really. Of different technology it's really of different technology it's really resilient. Resilient resilient in general it's pretty easy to work with in general it's pretty easy to work with. In general it's pretty easy to work with no real complaints about docker and no real complaints about docker and. No real complaints about docker and kubernetes second for the cloud data warehouse i. Second for the cloud data warehouse I was kind of worried about this at first was kind of worried about this at first. Was kind of worried about this at first because there are a ton of options because there are a ton of options. Because there are a ton of options but google bigquery actually ended up but google bigquery actually ended up. But google bigquery actually ended up being a really easy choice for us being a really easy choice for us. Being a really easy choice for us for one the queries are super fast they for one the queries are super fast they. For one the queries are super fast they were 10 to even a thousand times faster were 10 to even a thousand times faster. Were 10 to even a thousand times faster than some queries from the verizon than some queries from the verizon. Than some queries from the verizon database database database we were honestly just blown away by how. We were honestly just blown away by how we were honestly just blown away by how much better it was. Much better it was much better it was second intermediate cloud storage where second intermediate cloud storage where. Second intermediate cloud storage where do files live do files live do files live. During the data pipeline google cloud during the data pipeline google cloud during the data pipeline google cloud. Has a cloud storage service which is has a cloud storage service which is has a cloud storage service which is. Called google cloud storage called google cloud storage called google cloud storage. This means that we can separate the this means that we can separate the this means that we can separate the. Pipeline into a few different parts pipeline into a few different parts pipeline into a few different parts. One export tables from postgres to disk one export tables from postgres to disk one export tables from postgres to disk. To to to upload from the disk to cloud storage upload from the disk to cloud storage. Upload from the disk to cloud storage and three download from cloud storage to and three download from cloud storage to. And three download from cloud storage to bigquery bigquery bigquery so separating the pipeline like that. So separating the pipeline like that so separating the pipeline like that reduced the risk of failure and it also. Reduced the risk of failure and it also reduced the risk of failure and it also made retries less expensive because we. Made retries less expensive because we made retries less expensive because we would just retry one of the scripts. Would just retry one of the scripts would just retry one of the scripts third there was really painless. Third there was really painless third there was really painless command-line scripting. Command-line scripting command-line scripting it's super straightforward to script. It's super straightforward to script it's super straightforward to script exporting files from postgres then. Exporting files from postgres then exporting files from postgres then uploading to bigquery. Uploading to bigquery uploading to bigquery it made creating a basic pipeline really. It made creating a basic pipeline really it made creating a basic pipeline really. Easy to reason about from the command easy to reason about from the command easy to reason about from the command. Line line line and also in turn pretty easy to and also in turn pretty easy to and also in turn pretty easy to. Containerize because we were just containerize because we were just containerize because we were just. Uploading a bash script into the docker uploading a bash script into the docker uploading a bash script into the docker. Container container container fourth google suite authentication so fourth google suite authentication so. fourth google suite authentication so within within within sdf we used g suite so it meant that. Sdf we used g suite so it meant that sdf we used g suite so it meant that everyone had g suite permissions. Everyone had g suite permissions everyone had g suite permissions it also meant it was really easy to set. It also meant it was really easy to set it also meant it was really easy to set up and share permissions across the. Up and share permissions across the up and share permissions across the organization. Organization organization I would say that this is like a low I would say that this is like a low. I would say that this is like a low priority in terms of deciding a priority in terms of deciding a. Priority in terms of deciding a warehouse but it is actually why we warehouse but it is actually why we. Warehouse but it is actually why we tried tried tried bigquery up first because it was really. Bigquery up first because it was really bigquery up first because it was really easy to integrate within our. Easy to integrate within our easy to integrate within our organization organization. Organization and I suspect that organizations that and I suspect that organizations that. And I suspect that organizations that run on microsoft like microsoft teams or run on microsoft like microsoft teams or. Run on microsoft like microsoft teams or whatever whatever whatever might have similar experience with azure. Might have similar experience with azure might have similar experience with azure. So I do think it probably determines so I do think it probably determines so I do think it probably determines. Live organizational needs third for metrics we decided to use third for metrics we decided to use. Google sheets google sheets google sheets this was actually more straightforward this was actually more straightforward. This was actually more straightforward than the warehouse because we decided than the warehouse because we decided. Than the warehouse because we decided that we wanted some basic data science that we wanted some basic data science. That we wanted some basic data science capabilities that were slightly outside capabilities that were slightly outside. Capabilities that were slightly outside the the the scope of queries and after we talked to. Scope of queries and after we talked to scope of queries and after we talked to a bunch of folks around the organization. A bunch of folks around the organization a bunch of folks around the organization. It made the most sense to surface this it made the most sense to surface this it made the most sense to surface this. Through spreadsheets it's a really through spreadsheets it's a really through spreadsheets it's a really. Common user interface for non-technical common user interface for non-technical common user interface for non-technical. Folks and it keeps data tabular so you folks and it keeps data tabular so you folks and it keeps data tabular so you. Can pretty easily connect can pretty easily connect can pretty easily connect here's whatever the table I got out and. Here's whatever the table I got out and here's whatever the table I got out and here's how it looks on the actual. Here's how it looks on the actual here's how it looks on the actual spreadsheet spreadsheet. Spreadsheet so python scripts are also the right so python scripts are also the right. So python scripts are also the right tool for post processing by a lot tool for post processing by a lot. Tool for post processing by a lot it really is a swiss army knife for data it really is a swiss army knife for data. It really is a swiss army knife for data you can really easily read a table you can really easily read a table. You can really easily read a table from bigquery run some custom from bigquery run some custom. From bigquery run some custom post-processing using common data post-processing using common data. Post-processing using common data science tools like pandas science tools like pandas. Science tools like pandas and then write the output to a google and then write the output to a google. And then write the output to a google sheet finally note that we deployed sheet finally note that we deployed. Sheet finally note that we deployed these scripts in a server-less fashion these scripts in a server-less fashion. These scripts in a server-less fashion on google cloud scheduler on google cloud scheduler. On google cloud scheduler once the bigquery dataset was updated by once the bigquery dataset was updated by. Once the bigquery dataset was updated by the kubernetes orchestrated cron job the kubernetes orchestrated cron job. The kubernetes orchestrated cron job you could then trigger these scripts and you could then trigger these scripts and. You could then trigger these scripts and then update the spreadsheet it was a then update the spreadsheet it was a. Then update the spreadsheet it was a really cool event driven architecture really cool event driven architecture. Really cool event driven architecture really simple really powerful and really simple really powerful and. Really simple really powerful and honestly I think that honestly I think that honestly I think that. This sort of way to automate metrics is this sort of way to automate metrics is this sort of way to automate metrics is. A really good one fourth and finally visualization this fourth and finally visualization this. Was by and far away the hardest part of was by and far away the hardest part of was by and far away the hardest part of. The implementation the implementation the implementation since there's actually a million tools. Since there's actually a million tools since there's actually a million tools and documentation that compares them. And documentation that compares them and documentation that compares them directly doesn't really exist. Directly doesn't really exist directly doesn't really exist so at this point like we've settled on. So at this point like we've settled on so at this point like we've settled on bigquery so we wanted really easy. Bigquery so we wanted really easy bigquery so we wanted really easy bigquery integration. Bigquery integration bigquery integration really easy deployment on docker and really easy deployment on docker and. Really easy deployment on docker and kubernetes some nice visualizations that kubernetes some nice visualizations that. Kubernetes some nice visualizations that use drag and drop use drag and drop use drag and drop. And some sql and we also wanted to be and some sql and we also wanted to be and some sql and we also wanted to be. Open source so I tried a lot of tools open source so I tried a lot of tools open source so I tried a lot of tools. That that that fit some or all of those capabilities fit some or all of those capabilities. Fit some or all of those capabilities some of the most some of the most some of the most. Prominent ones that we looked at were prominent ones that we looked at were prominent ones that we looked at were. Google data studio apache superset and google data studio apache superset and google data studio apache superset and. Looker looker looker what we generally found was the tools what we generally found was the tools. What we generally found was the tools that played nice with bigquery that played nice with bigquery. That played nice with bigquery usually either didn't have drag and drop usually either didn't have drag and drop. Usually either didn't have drag and drop or weren't free or weren't free or weren't free. And so we ended up settling on metabase and so we ended up settling on metabase and so we ended up settling on metabase. Because it honestly fit all of our because it honestly fit all of our because it honestly fit all of our. Original pillars quite well original pillars quite well original pillars quite well. It has both sql as well as a drag and it has both sql as well as a drag and it has both sql as well as a drag and. Drop interface drop interface drop interface it's free and really easy to set up and. It's free and really easy to set up and it's free and really easy to set up and I think if you need to mvp a pipeline. I think if you need to mvp a pipeline I think if you need to mvp a pipeline it's a really good option. Finally let's talk about some of the finally let's talk about some of the downsides of our v1 implementation. Downsides of our v1 implementation downsides of our v1 implementation for one daily frequency is slow while. For one daily frequency is slow while for one daily frequency is slow while good enough for initial use cases. Good enough for initial use cases good enough for initial use cases a daily update limits building out data. A daily update limits building out data a daily update limits building out data intensive apps on seller. Intensive apps on seller intensive apps on seller we want to get closer to real-time. We want to get closer to real-time we want to get closer to real-time updates for next version of the system. Updates for next version of the system updates for next version of the system two observing failures is hard we were. Two observing failures is hard we were two observing failures is hard we were still learning our way around kubernetes. Still learning our way around kubernetes still learning our way around kubernetes. Logging logging logging and ideally we want to be able to reach and ideally we want to be able to reach. And ideally we want to be able to reach by really specific granular portions by really specific granular portions. By really specific granular portions when they fail when they fail when they fail. So there are good task management so there are good task management so there are good task management. Systems out there and that seemed like a systems out there and that seemed like a. Systems out there and that seemed like a natural evolution of the system natural evolution of the system. Natural evolution of the system three visualizations were private we'd three visualizations were private we'd. Three visualizations were private we'd love to expose our information love to expose our information. Love to expose our information visualizations publicly visualizations publicly visualizations publicly. But we can't mix the platform that we but we can't mix the platform that we but we can't mix the platform that we. Use for internal business analytics with use for internal business analytics with. Use for internal business analytics with everyone else everyone else everyone else. So we decided that we'd have to think so we decided that we'd have to think so we decided that we'd have to think. About an intermediate solution about an intermediate solution about an intermediate solution. And four exploring data is painful so and four exploring data is painful so and four exploring data is painful so. You'll notice I didn't actually talk you'll notice I didn't actually talk you'll notice I didn't actually talk. About a data science platform above about a data science platform above about a data science platform above. And while serverless functions provide and while serverless functions provide and while serverless functions provide. Some capabilities for robust and regular some capabilities for robust and regular. Some capabilities for robust and regular jobs jobs jobs ideally the platform enables exploratory. Ideally the platform enables exploratory ideally the platform enables exploratory. Data analysis through scripts data analysis through scripts data analysis through scripts. Every data scientist now uses jupiter every data scientist now uses jupiter every data scientist now uses jupiter. Notebooks and notebooks and notebooks and we want to make it really easy to do the. We want to make it really easy to do the we want to make it really easy to do the. Same on Stellar data so now let's look at some basic analysis so now let's look at some basic analysis. Of some queries on our system so for one we'll start off with an easy so for one we'll start off with an easy. Query what account has the highest lumen query what account has the highest lumen. Query what account has the highest lumen balance balance balance I call this easy because it's pretty. I call this easy because it's pretty I call this easy because it's pretty short but it's really cool because it. Short but it's really cool because it short but it's really cool because it illustrates. Illustrates illustrates how powerful even basic sql tools are so how powerful even basic sql tools are so. How powerful even basic sql tools are so this shows some really basic sql syntax this shows some really basic sql syntax. This shows some really basic sql syntax select from order by and limit select from order by and limit. Select from order by and limit those give you the tools to ask basic those give you the tools to ask basic. Those give you the tools to ask basic ordinal questions about Stellar history ordinal questions about Stellar history. Ordinal questions about Stellar history select from chooses specific fields from select from chooses specific fields from. Select from chooses specific fields from a table order by orders the results of a table order by orders the results of. A table order by orders the results of the field the field the field and limit says how many you want to see. And limit says how many you want to see and limit says how many you want to see as you can all see the account with the. As you can all see the account with the as you can all see the account with the most lumens is the galaxy void account. Most lumens is the galaxy void account most lumens is the galaxy void account which received the lumen burn last. Which received the lumen burn last which received the lumen burn last merity now a medium difficulty ferry how many. Now a medium difficulty ferry how many payments of an asset are made daily payments of an asset are made daily. Payments of an asset are made daily so we show you some new syntax here date so we show you some new syntax here date. So we show you some new syntax here date converts a time to justice day converts a time to justice day. Converts a time to justice day sum is an example aggregation function sum is an example aggregation function. Sum is an example aggregation function which takes a bunch of which takes a bunch of. Which takes a bunch of results and then combines them into one results and then combines them into one. Results and then combines them into one specific number specific number specific number. And where can be used for various and where can be used for various and where can be used for various. Condition where clauses condition where clauses condition where clauses shown here finally group by will group. Shown here finally group by will group shown here finally group by will group by by. By a specific field so this lets us pretty a specific field so this lets us pretty. A specific field so this lets us pretty organize organize organize pretty quickly organize and group. Pretty quickly organize and group pretty quickly organize and group results by day. Results by day results by day compute daily amounts and do some pretty compute daily amounts and do some pretty. Compute daily amounts and do some pretty good aggregations good aggregations good aggregations. All in all it's actually really simple all in all it's actually really simple all in all it's actually really simple. To be able to make these to be able to make these to be able to make these sort of day-by-day analysis and it's. Sort of day-by-day analysis and it's sort of day-by-day analysis and it's really core part of some of. Really core part of some of really core part of some of the organizational metrics we track. So finally a high difficulty query how so finally a high difficulty query how many trades of a trading pair are made. Many trades of a trading pair are made many trades of a trading pair are made per day. Per day per day you'll notice that this has a lot of you'll notice that this has a lot of. You'll notice that this has a lot of lines but the actual primitives are lines but the actual primitives are. Lines but the actual primitives are pretty similar to things you just saw pretty similar to things you just saw. Pretty similar to things you just saw it has some new syntax so we use with as it has some new syntax so we use with as. It has some new syntax so we use with as to create some temporary in-memory to create some temporary in-memory. To create some temporary in-memory tables to query and join lets us join tables to query and join lets us join. Tables to query and join lets us join together different tables on common together different tables on common. Together different tables on common fields fields fields so you can have some really big tables. So you can have some really big tables so you can have some really big tables that you can now condition. That you can now condition that you can now condition filter group so on so forth. Filter group so on so forth filter group so on so forth once again I want to say that like the. Once again I want to say that like the once again I want to say that like the queries are not the focus of this. Queries are not the focus of this queries are not the focus of this particular talk the engineering is much. Particular talk the engineering is much particular talk the engineering is much more of one. More of one more of one but feel free to reach out to me either but feel free to reach out to me either. But feel free to reach out to me either on the youtube chat or after on the youtube chat or after. On the youtube chat or after I'm happy to provide more instructions I'm happy to provide more instructions. I'm happy to provide more instructions on how anyone on how anyone on how anyone can make these queries we also put out a. Can make these queries we also put out a can make these queries we also put out a. Blog post earlier this summer blog post earlier this summer blog post earlier this summer. That covers a lot of this and I highly that covers a lot of this and I highly that covers a lot of this and I highly. Recommend checking it out so forth and finally let's talk about so forth and finally let's talk about. Some next steps some next steps some next steps to motivate these think about the. To motivate these think about the to motivate these think about the downsides from implementation and we'll. Downsides from implementation and we'll downsides from implementation and we'll talk about some of the things we could. Talk about some of the things we could talk about some of the things we could do do. Do so for one going from slow to real-time so for one going from slow to real-time. So for one going from slow to real-time frequency frequency frequency so new horizon capabilities like the new. So new horizon capabilities like the new so new horizon capabilities like the new. Ingestion engine ingestion engine ingestion engine help us get closer to real time because. Help us get closer to real time because help us get closer to real time because that enables much faster extraction of. That enables much faster extraction of that enables much faster extraction of data from Stellar core. Data from Stellar core data from Stellar core and history archives our awesome intern. And history archives our awesome intern and history archives our awesome intern isaiah turner. Isaiah turner isaiah turner has been building a command line tool has been building a command line tool. Has been building a command line tool that uses these capabilities that uses these capabilities. That uses these capabilities to read in data in close to real time to read in data in close to real time. To read in data in close to real time and then and then and then output it in the expected schema and the. Output it in the expected schema and the output it in the expected schema and the. Link to it is right here in the slice second going from low to high second going from low to high. Observability observability observability fixing failures is pretty hard but task. Fixing failures is pretty hard but task fixing failures is pretty hard but task management makes observing and debugging. Management makes observing and debugging management makes observing and debugging. A lot easier a lot easier a lot easier so while our current system wasn't so while our current system wasn't. So while our current system wasn't unmanageable the number of moving parts unmanageable the number of moving parts. Unmanageable the number of moving parts made reading kubernetes logs the primary made reading kubernetes logs the primary. Made reading kubernetes logs the primary solution solution solution it's important to note that we added. It's important to note that we added it's important to note that we added some sentry logging around business. Some sentry logging around business some sentry logging around business metric metric. Metric but the thing about all of that is that but the thing about all of that is that. But the thing about all of that is that it shows you that a problem happened it shows you that a problem happened. It shows you that a problem happened it doesn't really tell you where it did it doesn't really tell you where it did. It doesn't really tell you where it did or what to do to fix it or what to do to fix it. Or what to do to fix it so combined with the above tooling so combined with the above tooling. So combined with the above tooling isaiah has been working on an airflow isaiah has been working on an airflow. Isaiah has been working on an airflow task management system for the pipeline task management system for the pipeline. Task management system for the pipeline airflow is a task management system that airflow is a task management system that. Airflow is a task management system that airbnb open sourced a few years ago airbnb open sourced a few years ago. Airbnb open sourced a few years ago and honestly it's been great in our and honestly it's been great in our. And honestly it's been great in our experience at being able to orchestrate experience at being able to orchestrate. Experience at being able to orchestrate a bunch of different smaller scripts a bunch of different smaller scripts. A bunch of different smaller scripts being able to say hey this failed and being able to say hey this failed and. Being able to say hey this failed and giving a really nice ui giving a really nice ui. Giving a really nice ui for engineers to go and just retry for engineers to go and just retry. For engineers to go and just retry different parts so this has the same different parts so this has the same. Different parts so this has the same overall flow as before overall flow as before. Overall flow as before it reads ledgers from Stellar core it it reads ledgers from Stellar core it. It reads ledgers from Stellar core it writes structured documents to google writes structured documents to google. Writes structured documents to google cloud cloud cloud and then it uses those as changes to the. And then it uses those as changes to the and then it uses those as changes to the. Bigquery tables bigquery tables bigquery tables so this one is almost done it should be. So this one is almost done it should be so this one is almost done it should be done next week and the link to that. Done next week and the link to that done next week and the link to that which is it's already open. Which is it's already open which is it's already open source is on the slides as well. Source is on the slides as well source is on the slides as well third going from private to soon public. Third going from private to soon public third going from private to soon public visualization. Visualization visualization we're thinking about displaying markets we're thinking about displaying markets. We're thinking about displaying markets and corridors in a public-facing site and corridors in a public-facing site. And corridors in a public-facing site like `stellar.org` like `stellar.org` like `stellar.org`. It'll make it easier for prospective it'll make it easier for prospective it'll make it easier for prospective. Anchors to see what the volume looks anchors to see what the volume looks anchors to see what the volume looks. Like in and out of specific businesses like in and out of specific businesses like in and out of specific businesses. And countries and countries and countries we're just reasoning about the right we're just reasoning about the right. We're just reasoning about the right strategy in a way that meets both strategy in a way that meets both. Strategy in a way that meets both internal and external needs internal and external needs. Internal and external needs so once the new data system is stable so once the new data system is stable. So once the new data system is stable we're going to see how you can leverage we're going to see how you can leverage. We're going to see how you can leverage bigquery data warehousing bigquery data warehousing. Bigquery data warehousing to build a scalable web application on to build a scalable web application on. To build a scalable web application on top of it it's its own engineering top of it it's its own engineering. Top of it it's its own engineering challenge challenge challenge because it's pretty hard to do that in a. Because it's pretty hard to do that in a because it's pretty hard to do that in a. Time efficient way time efficient way time efficient way but it's a really exciting one and I'm. But it's a really exciting one and I'm but it's a really exciting one and I'm excited to get cracking on it. Fourth and finally data exploration is fourth and finally data exploration is painful so a data science platform is. Painful so a data science platform is painful so a data science platform is very much tbd. Very much tbd very much tbd if anybody in the community wants to if anybody in the community wants to. If anybody in the community wants to take this challenge on take this challenge on. Take this challenge on I'm more than happy to see some I'm more than happy to see some. I'm more than happy to see some community implementation community implementation. Community implementation and feel free to reach out to me with and feel free to reach out to me with. And feel free to reach out to me with either ideas or either ideas or either ideas or. A desire to try to figure out how to do a desire to try to figure out how to do a desire to try to figure out how to do. It I'm very happy to talk about it it I'm very happy to talk about it it I'm very happy to talk about it. So that's all for me I hope you really so that's all for me I hope you really so that's all for me I hope you really. Enjoyed hearing about this pipeline and enjoyed hearing about this pipeline and enjoyed hearing about this pipeline and. All the stuff we've been doing all the stuff we've been doing all the stuff we've been doing. And I'm happy to answer any questions so one question that's been asked are so one question that's been asked are. There any cool projects using this data there any cool projects using this data there any cool projects using this data. Set that you wish existed set that you wish existed set that you wish existed so i'll start by plugging again the two. So i'll start by plugging again the two so i'll start by plugging again the two things that I just said. Things that I just said things that I just said because I think they enable a lot of the. Because I think they enable a lot of the because I think they enable a lot of the. Cool projects so for one I think it cool projects so for one I think it cool projects so for one I think it. Should be really easy to see should be really easy to see should be really easy to see. Here's what all the major anchors on here's what all the major anchors on here's what all the major anchors on. Stellar are doing and Stellar are doing and Stellar are doing and it should be really easy to see what the. It should be really easy to see what the it should be really easy to see what the. Volume in and out of specific quarters volume in and out of specific quarters volume in and out of specific quarters. Looks like looks like looks like and it should be even easier to see what and it should be even easier to see what. And it should be even easier to see what the rates look like the rates look like the rates look like. I think the rates are really hard to be I think the rates are really hard to be I think the rates are really hard to be. Able to do on this data set but really able to do on this data set but really able to do on this data set but really. Powerful powerful powerful so for example one of the reasons that so for example one of the reasons that. So for example one of the reasons that the the the the euro t to naira corridor has been. the euro t to naira corridor has been the euro t to naira corridor has been. Killing it lately killing it lately killing it lately has been because the rates for that are. Has been because the rates for that are has been because the rates for that are so much better than what you would get. So much better than what you would get so much better than what you would get when you have really good rates on. When you have really good rates on when you have really good rates on Stellar it makes the whole network work. Stellar it makes the whole network work Stellar it makes the whole network work and I think that applications that. And I think that applications that and I think that applications that surface information like that like the. Surface information like that like the surface information like that like the key killer applications of Stellar. Key killer applications of Stellar key killer applications of Stellar are the most useful to leverage this. Are the most useful to leverage this are the most useful to leverage this data set in the short term. Data set in the short term data set in the short term longer term things that I think would be. Longer term things that I think would be longer term things that I think would be. Cool that leveraged this data set cool that leveraged this data set cool that leveraged this data set. I think it could be really cool to I think it could be really cool to I think it could be really cool to. See how assets on the see how assets on the see how assets on the decks itself can function as a hedge. Decks itself can function as a hedge decks itself can function as a hedge against inflation. Against inflation against inflation through sort of price histories over through sort of price histories over. Through sort of price histories over time this is one of the things that time this is one of the things that. Time this is one of the things that people talk about as a goal for crypto people talk about as a goal for crypto. People talk about as a goal for crypto and one of the things that with vibrant and one of the things that with vibrant. And one of the things that with vibrant sdf has started working on sdf has started working on. Sdf has started working on and I think that if there were projects and I think that if there were projects. And I think that if there were projects that demonstrated that longitudinal that demonstrated that longitudinal. That demonstrated that longitudinal history it would be another really cool history it would be another really cool. History it would be another really cool value value value for Stellar in the network. For Stellar in the network for Stellar in the network so another question what can a community. So another question what can a community so another question what can a community. Do to help expand Stellar do to help expand Stellar do to help expand Stellar and improve it for those who do not. And improve it for those who do not and improve it for those who do not understand the engineering aspect of. Understand the engineering aspect of understand the engineering aspect of that that. That so that's a good and interesting so that's a good and interesting so that's a good and interesting. Question question question I will say that you don't need to I will say that you don't need to. I will say that you don't need to understand the engineering aspect of understand the engineering aspect of. Understand the engineering aspect of what I just talked about to use the data what I just talked about to use the data. What I just talked about to use the data set set set that's one thing that we really tried to. That's one thing that we really tried to that's one thing that we really tried to. Make sure we could do which is just make sure we could do which is just make sure we could do which is just. Being able to use some basic sql queries being able to use some basic sql queries. Being able to use some basic sql queries and show some really powerful data what. And show some really powerful data what and show some really powerful data what can the community do to expand. Can the community do to expand can the community do to expand on it lots of things but within the. On it lots of things but within the on it lots of things but within the scope of this talk. Scope of this talk scope of this talk I would say that it looks like telling I would say that it looks like telling. I would say that it looks like telling people that hey Stellar is really cool people that hey Stellar is really cool. People that hey Stellar is really cool but then also showing them what the but then also showing them what the. But then also showing them what the volume on Stellar looks like volume on Stellar looks like. Volume on Stellar looks like so this is one thing that i've thought a so this is one thing that i've thought a. So this is one thing that i've thought a lot over the course of the summer lot over the course of the summer. Lot over the course of the summer when we've had a lot of volume on when we've had a lot of volume on. When we've had a lot of volume on ethereum with d5 right ethereum with d5 right ethereum with d5 right. How do you show similar volume with how do you show similar volume with how do you show similar volume with. Stellar because Stellar is one of the Stellar because Stellar is one of the Stellar because Stellar is one of the. Few layer ones that can actually do few layer ones that can actually do few layer ones that can actually do. Layer two things like that layer two things like that layer two things like that so I think demonstrating that value like. So I think demonstrating that value like so I think demonstrating that value like. That exists that exists that exists and showing people that seller isn't and showing people that seller isn't. And showing people that seller isn't just a payments platform with xlm just a payments platform with xlm. Just a payments platform with xlm there's all this other stuff you can do there's all this other stuff you can do. There's all this other stuff you can do on top of it I think that's one of the on top of it I think that's one of the. On top of it I think that's one of the things that becomes a lot easier things that becomes a lot easier. Things that becomes a lot easier with really publicly queriable network with really publicly queriable network. With really publicly queriable network history it would be really cool for history it would be really cool for. History it would be really cool for community members community members community members. To promote it in a data-driven fashion to promote it in a data-driven fashion to promote it in a data-driven fashion. Awesome so it looks like no more awesome so it looks like no more awesome so it looks like no more. Questions so questions so questions so last call if anyone has anything else last call if anyone has anything else. Last call if anyone has anything else but but but feel free to reach out to me either over. Feel free to reach out to me either over feel free to reach out to me either over. Key base my key base username is devnet key base my key base username is devnet key base my key base username is devnet. Nil or over twitter my twitter username nil or over twitter my twitter username nil or over twitter my twitter username. Is debna sir is debna sir is debna sir d-e-b-n-i-l-s-u-r I'm happy to d-e-b-n-i-l-s-u-r I'm happy to. D-e-b-n-i-l-s-u-r I'm happy to talk about things Stellar related as talk about things Stellar related as. Talk about things Stellar related as well as waste lovers data set in the well as waste lovers data set in the. Well as waste lovers data set in the community.
