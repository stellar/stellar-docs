Okay I think we have like a couple of.Things on the agenda so..I think the first one was .Around.Please. to kind of give a quick update of on.Where we are and then .And then like we have a follow-up. discussions on the archiving work.That Garen has been working on.Maybe I can start with yeah face given.That this is like a quick thing. so yeah so like we have we started.To kind of go back to the that fee.Cap that I was looking at the draft.It was first put together end of June.Last year so it has been sitting.Accumulating dust for a long time and .Yeah so we're actually like looking into.This again. we started a. by doing a couple things so first one.Was around..Refreshing the the CAP to reflect.As much as possible where we left it.Where it left things off in the on the.Mailing list. there's plenty of still of open.Questions.And yeah we're going to go over that. I think the other thing was that we.Started a thread on this code on the.Channels.So.Yeah at this point it's more like yeah.We need to go through.And iterate on this before we can.Give more updates on on what's going to.Be next on the on the feed front and.Basically like the yeah what we're.Realizing is that there are a lot of.Things that we didn't incorporate yet.Like there are.You know this was written before we had.For example the pre-flight.In the picture things like that so.Yeah there will be a.For sure a little more a few more.Changes that need to have to be done.But that's kind of what we are with.This not everyone to kind of spend.More time on this just like you know.I'm inviting people to. to kind of follow the conversations.And .Yeah.Talk about and maybe help on you know.Helping us making decisions on this one.Do we maybe want to keep a free high.Level overview of what is there and you.Know what are the open questions we are.Trying to solve a recent page let's.Spend more time on the archival.Proposal.Yeah I think that yeah like so I guess.Yeah good good point like the type of.Things we are trying to.. big issues I would say that we need.To. to kind of converge on on the feed.Front is.On what type of experience we want to.Expose to contract developers when it.Comes to the different markets that that.Exist in the system.So we have the different resource.Types we have a. Ledger space we have a compute so.Like when when transactions execute.We have a network bandwidth and NBS I.Think in terms of C markets that's.Canada we have other things that are.Related more to external systems so like.When people for example.Produce metadata that then then gets.Consumed by systems like horizon or.Sort of an OPC or yeah like still are.Expert in red like uses this kind of.Of a data stream so like making it that.People can just.Spam those other systems is is part of.The you know in school for for the the.Fee schedule. and then what did I forget oh yeah .We have also archives what has.Basically answered. mandatory right like published to.Those history archives.So making sure so that people don't use.That as they are alternative to.S3 or you know like.Other places that you know when people.Can store data if they want want to the.Difference here is that those history.Archives are.Romantic analysis forever after so there.Are some constraints there. and yeah so like the type of problems.Around those this the the model.For fees is how do we make it that we.Can balance usability so right now you.Know people used to do the classic.System they have.A very simple way to think about things.Basically you have a base fee for one.Operation if your transaction contains.More than one you just multiply and.That's kind of your your base in a way.To kind of think think about the you.Know in terms of fee and if you want to.Get ahead of other transactions on the.Network for whatever reason.It just increase your your feeling.That's kind of it right.And.In SOROBAN like the.Because of the competition between those.Different.Resource types that are open-ended right.In terms of.Consumption and competition so. yeah we're going to need.Something a little bit better than that.I mean like they're they're like in.Places like in.You know Italian they have. you know a version of what you can do.Do with these so this is a.Single fee for for everything. there are like proposals to make it.Maybe okay it comes to.To different resource types but that's.Nothing yet in Italian it is implemented.In other on cases like polkadot I think.But yeah that's why we are kind of.Trying to get.Something usable.Okay.I think that's kind of what I wanted to.Talk about on the feed from just you.Know heads up it's coming.Let's see and yeah we have the next.Guarant that I think wanted to give us a.Little more updates on last time there.Was like we started to talk about the.Archive.Mechanism that allows to to save space.On the on the Ledger.So that we can keep the network.As cheap as as possible. and I think there were a few.Interesting follow-up conversations that.Also happen after that in this Garden.Of this goal so.Aaron and give us maybe a.Little a few updates on what's going on.There.Yeah so I guess first I want to talk a.Little or just have some time for.Questions about the interface that we.Talked about last week and so kind of.Just like a high level summary of what.We went over last time is essentially.All sort of on data has this rent fee.And this rent balance. and so every Ledger or periodically.You have to pay rent for keeping an.Entry live on The Ledger and then.Whenever an entry runs out of its rent.Balance it could still be in from The.Ledger and then sent to the archive and.So with that interface we've kind of.Exposed three different classes of.Storage these kind of three different.Types of storage replace today what.Is currently the storage layer which is.Like end dot storage in your smart.Contract code and so with these three.Types of storage Ares we have a unique.Storage which is there's only ever one.Version of the entry that exists the.Entry either exists on the bucket list.Or there's a single version of that.Entry on the archive but never both.And this is useful for types of data.That have security concerns such as.Nonsense or certain types of.Authorization where there could be.Security risks and issues if you have.Multiple versions of that entry that.Could be restored kind of the the use.Case here is if you could think about. Implement a nonce where you didn't.Have this unique storage guarantee you.Could find yourself where you have a.Version one of the nonce in the archive.Of like say value five and then version.Two of the nonce and the archive with a.Different value and then you can imagine.How a malicious user could restore those.Entries in such a way that your knots.Values out of date and not the correct.Value that should be so that's unique.Data it's more expensive because you.Have to prove that something doesn't.Exist in the archive whenever you create.Something new and so there's a little.Bit of work that needs to be done so.It's the most expensive data type but.It's reserved for like those security.And high-risk sort of entries and then.After unique storage we have what's.Called recreatable storage which is a.Similar in that recreable storage.Entries whenever you run out of rent.Balance also get sent to the archive the.Only difference is that recreatable.Storage might have different versions in.The archiver multiple different versions.Exists at the same time the reason for.This is that whenever you create a.Recreatable storage entry you don't.Check the archive to see if something.Already exists there and so say you have.Something like a balance that got.Archived and then you go to create a new.Version of that after your old key got.Archived in recreatable storage you.Don't check the archive and so you just.Create a new entry with the exact same.Key and so you have this key collision.And so that's it's a little cheaper.Than unique storage because you don't.Have to check the archive and actually.Show that this entry is unique that.Could be multiple versions of it so it's.Cheaper but it's not appropriate for.Security types such as like nonsense or.Auth where you don't want multiple.Versions and so that's unique storage.And recreatable storage both of which.Can be archived and then the final type.Of storage is called temporary storage.And this are for short-lived entries and.So whenever a temporary storage entry.Runs out of rent it just gets deleted it.Doesn't get sent to the archive and so.Temporary storage is an appropriate for.Sensitive data that you want to keep.Around like user balances but can be.Useful for data types that either don't.Need to live very often like a.Short-term authorization to let an.Address spend your funds for instance or.For data types that can be easily.Recreated if they get deleted such as.Like a payment path or a payment Channel.Or something like that.And so I think. now even I think first I just want to.Open up the floor for questions and to.Talk about this kind of like a interface.And in particular talk about this like.Three-tiered approach and having three.Different classes of storage because I.Know that there's a little controversial.And it's definitely a little bit more.Complex on the current interface just.Wondering if there are any questions. that. I do I do have a question if if I can.Go for it.So this is in in my sense this is.Actually a very good design I like it .Excuse me I'm wondering in terms of.Staging this work I it's quite.Complicated and involved in some some.Quantity of it is going to depend on.Some pretty big components being built.Out in terms of the archivers. which is fine and and I think we can.I think we can do some staging I'm.I'm.In the sense of you know deploying.Versions of zoroban that have the.Interface but but you know some of it is.Just defined to do nothing at this point.Or that sort of thing.I'm a little bit concerned about the.Unique storage one because unique. right off the bat has to have these.These exclusion proofs in order to do.Any rights is that correct.Yes I think what we could do is we can.Still do a staging process right. and so I think what this would.Probably look like in practice is.Whenever we launch sort button we don't.Have the archive built out and so kind.Of the current plan for you know v0.On launch is to have the interface set.So to expose the unique recreable and.Temporary storage entry types to the.User and then to charge rent. and so the the thing that won't be.There though is that whenever your rent.Balance goes to zero you won't get.Delayed and you won't get sent to the.Archive because the archive won't be.Built yet right and so I think for.Unique data in particular what we.Probably just want to do is we can still.I think we still should launch unique.Data and recreable storage. just so that contracts can have the.Correct Paradigm written at launch but.What we can do I think at the.Implementation level is just the four .Just special cases right so like before.We have these proofs we can just say. essentially like creating unique.Entries does not require proof of.Exclusion until we actually provide an.Interface for those proof of exclusions.That's that's exactly the part I was I.Was asking about is is do you think we.Would just sort of make it an optional.Field at first and then when we rev the.Protocol the optional field has to have.A value in it and we'll Define what that.Value is in the future well we could do.That we're actually now that I'm.Thinking about it what we could do is.Just zero initialize through cache.And say the root archive hash is null.And then proof of exclusion become.Trivial right because if your hash is.Null then you're guaranteed that it's.Empty and so I actually think we can.Provide proofs of exclusion on day Zero.Actually. if we just Define the the null hash.And so the proof will always be null but.That's about proof if your root hash is.Null okay the other thing I'm thinking.Is that.You want this you want to use uniques.For nonsense and it seems like we we.Update nonsense quite a lot.And so I'm a little bit concerned about.Sort of an expensive.Operation that involves constructing a.Proof of exclusion.Has to.Adhere to every every nonce update.Certainly I wonder about the nonsense.That are maintained by the auth system.Maybe Dima could speak to that I think.The third yeah I can I'm sorry if you.Don't mind current so I think guaranteed.Is using non's example is well just .An example of why this problem.Matters for the built-in nonsense at.Least we decided to move forward with.A temporary knowns approach or nonsense.And signatures basically have some time.Boundaries and certain the temporary.Ledger entries so they don't even run.Again.And I would say this should be a.Preferred approach right like I.Reiterated this several times in the.Discussions here on Discord that with.The existence of temporary storage it's.A really good idea to try benefit from.It and.Try to design for it right like in this.Case of nonsense right we can have this.We need to bump it multiple times and.It's not super convenient and stuff and.I I think the main use case for The.Unique storage is really some admin data.Like you really don't want your admin.Entry to be taken over by someone just.Because it has expired right you have a.Token contract that you have insured.Once a year ago and you have never.Touched it but you don't want to wake.After a year the rent has expired you.Don't really want someone else to just.Re-initialize it because the entry has.Expired so I feel like this is the main.Use case and this is a really pretty.Cold entries if you think about it right.So yeah I think thinking about this a.Bit I sort of retract my concern.Because I think you're right that if if.The system has a well-defined notion of.Temporary storage with with time limits.On it then you just you just time bound.Anything that is that is.You you propagate those time bounds to.The things that use that storage such.That they they would they would become.Invalid at the same moment so I can.See that being quite quite a viable.Approach I like that that's good thank.You I also once make one.Additional clarification I think in your.Original question you said oh do you.Have to like provide a proof of.Exclusion every time you update it and.That's not true you only have to.Provide the proof at creation time. and then of course you have to.Provide proofs if you run out of rent.And then get sent to the archive but.Once it's actually live on the bucket.List then it says just as if you're.Modifying any other entry the proofs.Only apply if it's not on the bucket.List or if you're creating something for.The first time and so if it's like .Again this is just an example but like.If it's a nonsense that's regularly used. then it wouldn't matter it would be.Very cheap and efficient because it.Would never get to the archive okay.And oh I have one other very minor.Question and this is more of a design.Like time to hit the thesaurus we.Already have something in a system.Called an archive I just feel like.We gotta use a different word for this.Because it's just gonna it's just gonna.Follow up a lot of things that are.Already referred our guys yeah maybe.Like deep State source and like the yeah.I don't know what you're gonna call it.But maybe maybe not start with deep.State that might be a tough.A graveyard yeah.Cool so I guess any other questions.About specifically the recreatable.Temporary and then unique storage.Interface before you move on. yes I'd like to ask. why. like is there any reason why you.Don't use something like a bloom filter. to. to check whether the entry already.Exists in the arch Avenue because .Given given the notion that we have a.Bloom filter of all entries in the.Archive we can probably.Avoid having multiple versions of.Archived entries and I think having only.One version in the archive and.Preventing users to recreate.Some entries that already exist in the.Makes a lot of sense easier.Yeah so we definitely investigated this. a lot and we tried to find a way if.There is a way for validators to store.Keys or to at least have some knowledge.Of what's in the archive I think there's.A couple issues there so first the.Goal of the archival state is to bound.The amount of storage that values need.To store and so if they need to store a.Key even though that's you know less.Than storing the entire data entry.That's still an unbounded storage so.That's issue number one but I think in.Particular. you'd have to have a set of keys that.Grows unbounded and that's not a great.Solution because especially for sorbonne.Data types there's a lot of instances.Where the key is actually as big or.Larger than the value because if you can.Think like the keys are 32 bytes. and I'm not you know super in depth.At the current sort of implementation so.Correct me if I'm wrong my understanding.Is keys are 32 bytes but the value for.Instance could be something as small as.I can that's only like four bytes or.Something like that and so I think.You're not getting as good cost savings.As you think if you just store the keys.Business set not to your Bloom filter.Question or if there's a way to store.The keys in a more efficient manner the.Issue with Bloom filters in particular.Is that they don't it's very difficult.To resize the bloom filter and so if you.Say I have Unbound State and say okay.We're going to pick a bloom filter.That's one gigabyte large. but in 10 years you need a larger.Bloom filter because you're getting a.Lot of collisions and stuff it's.Impossible to just resize that bloom.Filter without having all the values.Because whenever you change the size of.The bloom filter you have to rehash.Everything that you've added to the.Bloom filter which would not be possible.For the validators because they've.Thrown all those values away and so.Essentially to resize your Bloom filter.Have to replay history from the.Beginning of time in order to resurface.All the values that need to be in that.Blend filter and additionally there's.Still issues with Bloom filters because.They're probabilistic in nature and so.You would still have key collisions.Sometimes or I guess. or not Keyhole rather because they.Only return. they don't return false Nexus I don't.Think but then there'd be certain keys.That just based on the probabilistic.Nature of the bloom filter the.Validators would think they're in the.Archive even though they weren't in the.Archive and so that would also be an.Issue where just based on whatever.Your hash function is there'd be certain.Keys that would essentially be.Impossible to create because the balloon.Filter thinks they already exist when.They really don't. so that answers your question about.The the bloom filter issue in particular.The issue in general as well.I'm not entirely sure that. the resizing issue is such a.Huge problem because you have an.Archive where you have all the keys.So once in a let's say 10 years it's.Possible to organize a resizing using.The archives as a source of all the.Existing keys.And to make like a maintenance for all.The validators.As for the size of the bloom filter for.Example I just checked and one billion.Entries .With a reasonable.False positives like .Point .0.1 percent .Probability of false negatives takes.About two and a half gigabytes so it's.Not the clutch and it will be enough for.The first billion entries .I think it's a reasonable trade-off for.To avoid.Some other complexities as for the false.Positives case I think since you have.The vehicle tree or some other structure.If it's not set and so on yet then you.Can probably check whether their hive.This is archive contains the given K.Give given key if it's .Let's say it can be a resurrected or.Something like this maybe I'm missing.Something because I haven't think about.This.For quite a long time but.Do you still think that.Using some Bloom filters other.Probabilistic structures won't help to.Prevent collisions of entries in.Archives like maybe there is some other.Option.Because yeah this point looks like one.Of the most controversial things about.The archives to me.Yeah this is a an interesting idea.Actually I think you mentioned that.Perhaps use the bloom filter. as like a almost a caching layer for.Efficiency and then. using the proofs as kind of like a.Back end in case you get a false.Positive I'm still not 100 sure if the.False positive case can be avoided right.Because say like from this would.Be very frustrating from a user.Standpoint say I have a key. or like there's some like.Deterministic way to like Define cues.Right so like I give my address. and then like the address is input.That generates. the keys for entries associated with.My account right like in a token.Contract.If one of those keys is a false positive.Then you just won't be able to create.Any entries based on your .Your the invoker address right and so I.Don't know if there's a way if you get a.False positive to somehow track the.Archive and say oh actually that wasn't.A false positive it really is it really.Doesn't exist I promise. and so I'm not sure.If there is a way to get around that.Case because I think like even if you.Say like a reasonable false positive.Rate like a 0.1 percent that still means.That one out of I think a thousand Keys. or maybe a ten thousand keys I might.Be off by zero or something there but.Essentially like one of the Thousand.Keys. you'll think it's in the archive when.It really isn't which means that you are.Not allowed to create one of the.Thousand one out of a thousand Keys.Which I feel like could be a really.Significant issue from the user.Interface perspective.Do you think that the time of.Checking the existence of the key .Over the Merkel tree or the miracle.Trios or the structure you plan to use.For archive proofs it's like.A really huge time like seconds minutes. or even more because if it's.Relatively small then.Checking.Checking the existence only for.Conflicting entries and you will be.Checking computer and entries only when.Someone tries to create already existing.Entry which.Actually I shouldn't be as. as often operation so like.What are the time requirements for.Checking against the try.Also I think one clarification.Here is that you can't just track.Against the archive directly because the.Archivers don't participate in consensus.And are not validators they are off.Chain right and so you can't just like.Search through the tree brute force and.Trust that the contents are correct so.There has to be some way for the.Archivers to give a proof to validators.That the validators can then validate.Themselves and so I think that's why.Part of the reason we're using this try.Model where we can get both proofs of.Explosion pros of inclusion because I.Think the difference between this.Case and the Ubuntu case is that in the.Ubuntu case you can trust the the.Archive in our case we can't trust the.Archive we have to have some proof via.Like a hash or something and so.I'm still I think I think it could be.Interesting this Bloom filter approach.If we can.Do the bloom filter. and then if there's a collision maybe. say even though there's a collision.In the bloom filter I'm going to go and.Get a proof of exclusion. and that would perhaps make it more.Efficient and mean that in most cases.You can get away with creating entries.Without a perfect exclusion.But I'm still not sure what that would.Look like I guess maybe what we could do.Is you create your entry you check the.Bloom filter and then if you get an.Error on the bloom filter then you go.Try to get proof of exclusion and if.There's a valid proof of exclusion on.Chain that can override the bloom filter.That might be an interesting.Optimization. but.I guess that's second point.For explanation I don't want to steal.The time it's definitely. like I need to make more research.On this and probably we should get back.On this in that sales matter to to.Instill the time. on this question here thanks for the.Explanation yeah I think that's a I.Think it's definitely an interesting.Idea that's definitely worth pursuing .I guess one question I would ask is.Under this proposal of the bloom filter.And whatnot this would make all data.Unique data and so I'm wondering if.There are use cases where a user might.Actually want data to be recreatable .So thinking of the balanced use case I'm.Thinking like is there ever a scenario.Where it's actually an advantage to have.Multiple different versions. as opposed to only having this strict. one unique key. per archive per bucket list so I'm.Thinking like for instance in the.Case of balances where the multiple.Different versions of the balance can.Just be summed together.Is that a Advantage. and is there like a do we still want.To expose a repradable storage interface.So you can be even faster and I guess.Like not have to do this like Bloom.Filter check not because of exclusion.All that sort of stuff or is like a.Strict guarantee one key no collisions. powerful and that we shouldn't expose.This interface at all.To tell the truth from my experience.There is probably a known cases when.You need several versions of the same.Major entry.In most cases it's even a destructive.Problem right because.Creating an account or something else.May.Be a huge problem.I I I'd say that the.Use case for .Like optional recreating .Or maintaining several versions of the.Same Ledger entry is a rather.And I haven't.Seen any use cases for this.And just one question that basically.From the contract.To host interface tend to point like.There is no version in any Video Edit to.Kind of work around some issues in the.Current approach but in general the.Interfaces that like you put something.Into storage and it will stay there.Quote unquote forever or you know you.Put it into Temp Storage then it will.Be removed after a certain time period.But you know like even from the period.Is interface standpoint seriously no.Case for this multiple entry versions.And I think the main reason they are.Thinking of hiding it is just to kind of.Save some time and cost just to be able.To quickly create entries without proof.Of Proof Set exclusion but it's more.Like an implementation detail that.Unfortunately the contract writers would.Need to worry about in some cases versus.Like you know something is there things.That can be used as a feature or the.Contractor correct like if you need any.Sort of person you can build it yourself.Using just or as key so what not so I'm.Pretty sure there is no legitimate case.For recreatable storage Beyond it like.Or requirements to the scalability.Yeah yeah like maybe I can add that.The reason.Right now the the reason we are looking.At this recruitable storage.Is.That we have token balances that are.Interestingly. one of the kind of primary use.Cases for fast at all right and .If we don't have recreatable.Storage we basically have either.Temporaries right entries which for.Balance is a no-go.Or going with those unique entries.And for that you need troops. to create the balance so the cost of.An overhead of. just kind of setting up your wallet.Becomes . you know quite quite big for any new.Token that's kind of the the problem.Here is that .I think the overhead of proofs is.Probably acceptable the first time you.Kind of create your own wallet on your.On the network.But anytime you add a balance for any.Token.It seems.That having this overhead is kind of.Too much. but yeah maybe we that's kind of part.Of this discussion right to see you know.Are we wrong here.Yeah so I guess the the trade-off and.With the bloom filter approach where .You know and let's just put aside like.The resizing and migration issues for.Now but the bloom filter approach all.Data is unique. but the false positive rate is the.Percentage of the time that you will.Need to provide a proof of exclusion for.Creating new entry and so let's just I.Guess the trade-off is everything is.Unique and the interface is easier but.One out of a thousand Creations are very.Slow and require process of create.Precept explosion whereas if we have.Unique data and recreatable data then.The unique data is guaranteed to always.Be slow but the recreatable data is.Guaranteed to always be fast and so I.Guess the trade-off is do we want. all data to be fast most of the time.Or all data creation to be fast most of.The time and sometimes to be really slow.For the easier user interface or have a.More complex user interface where one.Type of data is always slow to create.And one type of data is guaranteed.Always fast to create I guess that's the.The fundamental trade-off at least in my.Mind.And that sounds about right like the.Thing about the blue tilt the other is.That if in the context of like a balance.Right.The ID the the key right of that balance.Is actually deterministic.So as it's deterministic it becomes kind.Of attackable. unless we can come up with like a.Cryptographic you know Broomfield of.Sorts it's it's very easy to.Basically.You know cause certain keys to be to.Have complex in the boom filter and then.You're kind of back to.That you know even though it's one in a.Thousand you know if you're the one that.Is always hit by the.By the one it kind of sucks. what if we utilize B tree index. or some other index or like .Database actually doing this.And besides that the index itself can.Reside on the disk and . the Fast Cash can be implemented .Using the bloom filter and the actual.Track will be carried over the index for.Example B3 index.Database handle this.I mean the issue with an index is we're.Getting to that issue where if we have.Any deterministic index like that we.Need to store the keys right. and then we have that same issue of.Unbalanced State growth and especially.Restore upon data where the keys can.Sometimes be significantly larger to the.Value so.I think any like deterministic data.Structure we can't get back into that.Issue of we have unbalanced State versus.Defeats the purpose of the archive in.The first place.Yeah I just want to remind way.Basically we still need to maintain.Consensus and we cannot just like.Randomly update boom shooter for example.Right it has to be a part of consensus.So it would need to come up with some.Way to Hash it quickly and add it to the.CP values and make sure it's archived.Properly you know.Significant amount of work and .I mean.You could say that the keys are stroke.In The Ledger forever and then you build.Some sort of index on them blockchain.But then you know yeah it kind of no.Longer fulfills the requirement of.Having.Limited Venture state cross which we.Wanted to fulfill so it's kind of an.Issue and yeah that for what source like.It was my first city as well like what.If we just throw keys in The Ledger but.Yeah that unfortunately kind of doesn't.Scale as well.Yeah so I think I think the Bloom.Filter with a proof of exclusion.Fallback for false positives it's an.Interesting idea I think we probably.Have some technical homework to do there. so I think it's all right for.Everyone to move on to the second. topic.I'm not hearing any objection Celtic as.Yes so kind of slipping away from the.User interface now talking about how the.Archiver interface will be set up and so.Currently. there are kind of like two proposals. one where we have an archive.Interface that's a functions similar to.Capture how Horizon functions now where.You go to a specific archiver you have.Some URL endpoint and then you query.That endpoint with the keys you want to.Be archived. and so this is like a a model similar.To what we have today with Verizon some.Of the pros there's pros and cons .What are the cons that you have to have.Like a personal relationship or at least.Know an archiver to go to. and then it's not super clear how we.Could incentivize or monetize this sort.Of interface perhaps you would have to.Like pay a monthly subscription to the.Archive or perhaps you'd have some .Relationship where you like pay your.Archive or per entry lookup or something.Like that but it's not super clear how.We incentivize people actually brought.In archivers in this setup so the second.Scenario is where we have kind of. what I'm referring to as the archive.Miners kind of stealing the minor.Terminology from Bitcoin. so essentially how this would work.Is instead of acquiring an archiver.Directly whenever you need a proof you.Submit a proof request. on chain now this could either be.Implemented at the protocol level where.Proof request is an operation or this.Might also be able to be implemented by.Like a first party smart contract but.That's not really important right now.But essentially you would just submit an.Operation that requests an archival.Proof and then by submitting this.Operation you'd submit meta information.That archivers could then adjust and.That's how the archivers would know.About the requests and as part of this.Operation you would say the key you want.To be proven the type of proof select.Proof of inclusion proof exclusion and.Then also a reward and this reward would.Be variable and you would be the .Would be at the user's discretion as to.What to set this reward to and then this.Operation this request would go on chain.And the metal would be a submit and so.An archival within Injustice meta and.Then pick what .Requests they want to service and so.They could reservice the request that.Has the highest reward first. and then they construct the proof.With the information that they store and.Then they submit the proof another.Operation and then the proof itself .Becomes an entry on The Ledger and so.Once that proof has been submitted and.Validated and the proof is on Ledger.Then the proof or the proof request is.Deleted and the reward is given to.Whoever submitted the correct archival.Proof first and so this is I think a.Better interface because it has a.Clearly defined incentive structure and.Also doesn't require any personal.Relationships with an archiver and so.You don't have to have a URL that you.Talk to or you don't have to have a.Relationship with some company that you.Pay monthly to pay some subscription fee.In order to access the archive it also.Allows archivers to freely. enter and exit the network as they.Please and also by having a variable.Reward that the user can set you can.Also have essentially like a built-in.Supply and demand Dynamics where that.Price fluctuates over time depending on.How many people want to restore.Archived entries and how many archivers.Want to service archives and so I guess. generally speaking what are your.Thoughts on the two approaches and.Kind of the leading approach being this.I'm submitting proof request to the.Chain and then having archivers read.The chain and then submit the proofs.How do we feel about that.Have you ever speak. let's see so like the the thing I'm.Thinking of right in terms of like. meaningful viable product I'm.Thinking the having a way to talk.Directly to archives is is kind of a. foolproof.The the approach where you use the.On-chain state. I think I mean it's I think there.Is like good potential there I think.It's it's going to be fairly tricky.To get this right the reason being.That basically.Your so you have. you're not creating like intrinsic.Value right to certain transactions. that are being published on the.Overlay and therefore a.Like a board of source right can can.Look at this overlay traffic and.Don't run take the data right that is.The primage right the proof.And from the the archival that.Actually did the work.And benefit from the academy so I think.There is like an interesting problem.There to solve.In terms of like how can you safely. disclose the the proof to the.Network without being from.Sinus right.Interesting some entities that.Can be signing it.Refining.Well the issue that was signing is how.Can like like the mental not just.Like take your proof and then sign with.Its own address.And then submit as if it was the.Originator.And I think there might be ways to do it.Right like it's a it's a.Maybe what you you you you it's like a.Multiple multi-step thing right where.You you because you were first to.Disclose let's say the harsh of the.Proof.Before you actually disclosure proof.Then you're the one you know if it's a.Contract that's doing the that work. then we can basically give the.The first you know first one.The benefit I mean at the same time like.A.Yeah maybe a bot can I mean it becomes.Kind of a a cat and you know a nice game.Right like where you.How to do this safely.Yeah I think in the front room.Like because you know yours are like.Super nice people that maybe on I.Mean not trying to game the system.Yeah I thought like the the front.Running I did was just to like if.They're the same proofs multiple the.Same proofs in the same block just or.Randomly pick one but I didn't think.About this proof stealing case. in front running by stealing proof so.This is definitely an interesting issue.To think about but I still I still like.The model where you don't have to have a.Relationship with the archive for a.Couple of reasons so first. it's likely that especially you know. if the archive systems run for a long.Time archivers will not store the entire.Archive I think it's a good idea to let.The archive pick and choose how much or.How little of his or of the archive.History they want to store and so I can.See an archiver that only stores the.Last five years one that stores the last.10 years and then one that's like a more.Expensive on the stores like the last 50.Years for instance I think if you have.To like individually query an archiver.You have this weird interface where for.Things that are three years old you can.Maybe query a cheap archiver and then.For things that are older you have to.Change your URL or something like that.To Target like a different archive that.Has more history state or something like.That and so I think there's still some.Some interface issues with having to.Talk to the archiver directly but at.Least on the top of my head I don't have.A great solution to the stealing proofs.Thing. I think that's the challenges.Yeah I was going to say like the the .I think it's it's a we should definitely.Be looking into those mechanisms that.Are like a little more distributed right.From a you know Discovery Point of View.I think all it means is that.We use. we we have the proper semantics on.Network to allow for for doing this so.Like I think for example like the thing.Where we have .Proofs that are usable independently of. using you know the entries. yeah I think this is like a a key .Property that we need to have right.Because I know like one of the earlier.Drafts. was requiring people to submit proofs.In the same transaction that they.Were going to use the you know the.Actual and actually restore the entry.And obviously this this would not.Work in you know would not enable the.Type of.Of scenarios.Yeah I definitely like having having the. or the proofs themselves be Ledger.Entries.I just I think we just need to find the. the best way to.To make sure the system isn't getting it.Or gained.Yeah yeah there's a because there's not.A clear solution because I mean you.Could submit say like before you submit.The proof If you submit the hash to say.Hey I was here first and then submit the.Proof of the next Ledger but then you.Could open yourself up to Dos attacks.For a malicious user could just generate.A bunch of dummy proofs and then submit.Them for every archive request and then.Archivers would not want to service.Those requests because something's.Already spoken for it and issues like.That so.So I think we need to think about but I.Definitely like I think we definitely.Should have the proofs on chain like.You mentioned. and we should see if there's a way to.Solve this issue in a way that makes.Sense.If you have a you know a few more.Minutes left was there like some.Other.Topic that you wanted to cover as part.Of of this yes I guess one other.Question that's kind of that we don't.Have a great solution for. and this is one that we need to.Figure out here pretty soon because it's.Required to launch for v0 is how to bump.Rent and so right now whenever you.Create an entry. it's created and initializes rent.Balance to some amount but there doesn't.Seem to be a great way in order to bump.Rent and to actually increase that rent.Balance and so kind of the initial.Thought was Hey whenever you access.Something increase the rent. and that's way that the things that.Are accessed most commonly automatically.Have their rent increased and so if you.Access something a lot it will most.Likely be on the buy policy and we'll.Have to unarchive it now for read write.Items it's easy because you have to.Rewrite the entry anyway so you might as.Well bump the rent however it's not.Clear how to bump rent on read only.Items so for instance.If you have auth. say like an auth record that's almost.Never changed but is read often.You would want to bump the rent on reads.So that you wouldn't have to constantly.Unarchive it the issue is because the.Way the bucket list is structured.There's no way to bump rent without.Rewriting the entry because. essentially the way the bucket list.Is structured entries and buckets are.Immutable and so in order to update an.Entry it's not like SQL you can just go.To the entry and then change a value you.Have to completely rewrite the entry and.So we wouldn't want to bump rent on.Every read because then we're implicitly.At the systems level turning reads into.Read writes which we don't want to do.And so I guess in the read write case.We obviously want to bump rent but I was.Wondering if there are any ideas as to.What to do for like read-only data and.How to handle rent in that regard.Well simple way I've been thinking.About is.Well you just said with online but you.Know I'm exposed just some contract.Function but that's free tried access to.The entries that you want to bomb.And nothing else.That will basically.You know to call just as any other.Contract function to bounce around. but that maybe can be generalized to.You know post functions that allows you.Action arbitrary entries without.Accessing them so that you know you.Don't need to .Maintain any invariants in terms of like.Only the contract can modify its own.Data I guess they can all agree that one.Pins or end is always positive right so.Anyone can do that and then you know.Just kind of cost functions it takes a.Bunch of majorities catches them at.Print right.Supposing pumpkins rent by whatever.Mechanism they come up this. which again is not super pretty but.That makes it possible to do the pump.Without touching the contract code and.Increasing inside guys and so on so.You know it's a basically a generic way.To maintain your contracts I think it's.Maybe viable.Yeah I think the host function could be.Good I think the only issue with that is.Key Discovery is still an issue. and then it might be difficult to.Determine what keys you need to bump.Around for in the host function. but perhaps one another thing is we.Could.Expose a explicit rent bump. at like the storage interface. and then also make the current rent.Balance readable.In the smart contract so I could imagine.Something like maybe a common.Paradigm for read-only data would be.Like if you have an off entry whenever.You read it you say you also have a.Check to see if the rent balance has.Fallen below some level and if so then.You call Rent bump on that value. so I guess or I don't know if that.Would be possible then because or none.Of that would be possible and so then.Essentially. there's a g path and an expensive.Path and so if your rent is above the.Value then pre-flight would put that.Entry in the read-only data set but if.Your rent is below a value then.PreFlight would put it in the read write.Set and bump the rent and so I think.That might be also another possible.Solution for for often like read-only.Data I mean that's kind of possible but.Doesn't solve it for everything like.Imagine again your token right and it.Has the you know an admin and let's say.You don't mean this token much. so you don't touch the admin entry.Frequently and then it would still.Expire right you you know the admin.Functions frequently enough so you know.For the important things you.It sure needs some sort of manual.Tracking and you still need to.Understand which entries need to be.Updated they I'm sure we can avoid this.Food just because you know some interest.May be rarely accessible well I think.That's okay actually. because if you don't access admin.Very much and whatever you access it you.Need to restore your admin entry I think.That's okay I think the case I'm talking.About is if you have some really value.That you access a ton that still gets.Archived all the time.Yeah but but my point is that you know.You can still forget to call it so I.Mean rely on automatic bumps is not.Going to always work. and another thing is that imagine.You know.Oh maybe it's not a super good example.But I I've been just thinking about who.Who pays for the bump right it's always.A source account who pays for the bumps.It would be a bit weird like if every.Once in a while.Like some transaction to your contract.Suddenly becomes more expensive because.You need to bounce around but you may be.Bump into rent of some entries that has.Nothing to do with your account.Specifically like for example let's say.You have some found that stores some .Sorry some contracted Source some State.Saying.It's like never going to change.Right and it's always free download.And then there is no clear owner of the.Token paywrites they're not.Owned by any address or anything so what.Would happen is like every once in a.While someone who trades with this.Liquidity pool will need to pay for.Their inbound I was a token payer record. which is a little bit awkward right.Because I just want to trade why would.It charge me more and you know I then.Draw all the incentives to kind of try.To gain this and.President not submit transactions until.Someone else has pumped you know I mean.It's definitely viable on paper but it.Just leads to distribute situations for.You know you're in a bumping rent on the.Some interest.You can respond to know about right I.Guess it also depends on the amount.Because it's well enough and it probably.Doesn't matter but if it's high enough.Then suddenly it becomes pretty annoying.For the user who ended up paying it.Yeah thank you I agree like it we.Probably need to think about those.Couple of angles like the.People that want to kind of maintain.Their their run balance on on those.Like read-only type of items that and.When I say people here could be a.Contract that tries to do like like an.Mm right that wants to kind of ensure.That it keeps alive its own thing at the.Same time there are probably scenarios.Where.You want to kind of .Do that from the outside in some way.Right because you don't want every.I mean yeah in the up cases where this.Is going to not work like if nobody is.Using it or and you need to revalue it.Or I don't know. anyways we have time so.Thank you everybody let's continue.Those conversations actually we should.Probably create like explicit threads.On the. you know on the dev Channel. about those topics and then yeah.We'll keep going.Thank you again.
