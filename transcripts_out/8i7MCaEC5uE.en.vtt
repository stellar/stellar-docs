WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:59.999 align:start position:0%
Okay, we're live alright. Everyone welcome to the Open Protocol Discussion, a biweekly meeting in which we review and plan for upcoming changes. Then provements do the stuff call. We've missed a few meetings because people have been out of town. But our plan is to keep live streaming these so that the world at large anyone who's watching can see what we're working on and all the wonderful thoughts that you have about. I

00:01:00.000 --> 00:01:59.999 align:start position:0%
Don't like Stellar better. These meetings usually focus on reviewing court advancement proposals, aka CAPs, which suggests new features and improvements to the protocol, and at the moment we're focused on Protocol 14, on the upcoming protocol, which will likely include two big CAPs: CAP 23, two part payments, and CAP 33, sponsored reserves. Today we'll cover a few remaining questions about those. We'll also talk a bit about the downstream implications of those CAPs and the preparations underway to make sure horizon and the Stellar SDKs are ready for Protocol 14. So we published some pre reads for this meeting there in the event description and this discussion will make up a lot more sense. If you've done them, so do those if you haven't. There's also just a rough outline of the agenda on the left of the screen and there's also a list of participants in the event description. And for this meeting, instead of introducing everyone, I'll just let anyone watching Google the names to find out who's who. If that's not working in the future, we can take some time to

00:02:00.000 --> 00:02:59.999 align:start position:0%
Introduce ourselves. But let's start there seems simplest. So diving in quick. Status update: CAP 23 and CAP 33 are in final common period. They've been there a little longer than usual. There were a few lingering questions. Discussion was a bit slow because people are way. But barring any blocker is raised in today's discussion, we will be night them with the coveted status of accepted. So first let's talk about those. CAP 23 to part payments. CAP 23 creates a new letter entry called a claimable balance, the new operations that allow you to create and claim a claim of a balance. The goal is to separate the sending and receiving with a payment so you can send a payment to an account that isn't already prepared to receive. It looks like there are a couple of issues here and I will turn it over to John to talk about the first one. Sure so, this is actually. This originates from a question that David brought up, I guess, a few weeks ago, which has kind of

00:03:00.000 --> 00:03:59.999 align:start position:0%
Been lingering. But basically the question is like: right now we're using dislike predicates tree structure which is kind of novel in the Stellar world. You know, in other places we use like linear threshold combinations and stuff like that. But here we have this predicate tree. And David's main concern about this predicate tree is that, you know, XDR doesn't have any built in mechanisms to prevent arbitrary recursion. And so anybody who has an extra parser, first of all, like as a matter of principle, you should be making sure that you're not gonna get infinite recursion. But you could imagine a world in which you have some structure which is like sitting on the edge of the recursion depth limit for different nodes on different architectures and whatever, and maybe some nodes choose that it's acceptable, in some node trees it's unacceptable, and then you end up in some bad, undefined state, depending on potentially a fork in a really bad case, depending on, basically, just how everybody's configured. But they're different XDR, and so the question is

00:04:00.000 --> 00:04:59.999 align:start position:0%
Like, how should we update this predicate tree structure? And David had this proposal to basically turn it into a into disjunctive normal form. But I've heard some opposition from myself, from Nicola and from somebody else that I can't remember right now who the third person is- that this disjunctive normal form idea is not really that great because, like, complicated expressions end up becoming like exponentially large. That's kind of not ideal. So we could either decide that we don't think this is a problem and we're not gonna be anywhere close to the recursion depth limit because, like, probably realistically a transaction, even with this predicate tree structure, has recursion depth, maybe like 10 or 12, and if your system doesn't support like 12 recursions, like that's a problem, hold on that. The idea is that a bad person could submit it to purposely submit a transaction that like pushes the recursion depth right, but that would be

00:05:00.000 --> 00:05:59.999 align:start position:0%
Invalid, no matter what. They're automatically invalid if the depth is greater than four. So, like, if you submit, because we have logic in there too, we have to be exactly. Actually, there's a laterally invalid if any of the predicate trees have depth greater than four. So like it. Might you know, if your XD, our compiler, doesn't generate code that handles recursion like deep recursions, well, it might crash your node, but like if that's the case, your XD are set up, it's garbage and you have a security vulnerability, regardless of whether we've done this or not. Well, if we pick a number like four, we can actually admit it's ugly, but we can actually express that in any XD are pretty good. Tree one, two, three and four is like four different types. You know, leaf one, two and three or something I mean. But so that much is how like. Do we really actually have use cases that involve all of this? Like the thing is, you already have the disjunction because you can have multiple claimants, right, and so the question is, why not do

00:06:00.000 --> 00:06:59.999 align:start position:0%
Something that has just a conjunction, you know, in the claim predicate and then you know we can add something more if it turns out that's not useful enough, or at least come up with some actual, like realistic use case that actually requires, like you know, like four, deep nesting of like hands and wars. So the four wasn't chosen arbitrarily. The four has this like very magic property of making a claim over balanced entry the same size as a, or rather the claimable predicate tree the same size as a data field. So, basically, like this bore was basically saying like if you're gonna pay reserved to get a data field, you might as well pay a reserved to get the same amount of space and claim a little balance. But so that's where the magic floor comes from. But regardless of that, I mean like for me it's not just about whether, like everything I think sensible, then you could express in disjunction format, like I don't see any

00:07:00.000 --> 00:07:59.999 align:start position:0%
Reason why you couldn't do this. But the issue is like if we then subsequently add the conjunctive stuff, then we're no better off than we are now. Like we'd be strictly worse, in fact, because we'd now have this, the disjunction thing, which was your proposal, where basically, if you get disjunction, if you're the same claim into multiple times, that's currently not permitted at all. Claimants are unique in this in the current proposal, but then you'd also be able to build these trees and then you've like kind of violated the like one way to do it rule. So like that's kind of my main like. Basically, if we think we could ever end up in a world where DNF is not good, then we shouldn't start in a world where DNF is the standard, because we'd be no better off in the long run. So that's kind of my main take on it. One other idea I'll pitched you and I'm gonna credit this one too great in it's not my idea. But graden mentioned that we could actually to avoid the infinite recursion thing- XD,

00:08:00.000 --> 00:08:59.999 align:start position:0%
ROP, KO phi, the predicate tree, and like we can, for example, make the xt are opaque version of the predicate tree like 64 bytes right now, and if it's bigger than 64 bytes you're dead. Like that's not gonna work, and then later if we need to get bigger trees, for example for hash Cree images or something, we just increase that number. But that provides like a default bound automatically? I don't know how much anybody cares about this. At the end of the day, like we could definitely do the hard coding thing. There's a lot of different options and I just like I don't know how much it matters to spend time trying to decide like, do people care a lot? Are people really concerned about this recursion thing? What is the use case that's driving the more complex? Like pretty good cheese. Well, the main reason for having the predicate trees is just that it's a lot more powerful than having Linear's like signer weights,

00:09:00.000 --> 00:09:59.999 align:start position:0%
Basically like what we have on accounts. I like there are very simple situations where you would want an or, for example, or maybe even an and or an or, for example. Like you might want a situation where it's like: from now until this time, I can do something, and then from some future time until some other future time, I again have the right to do something. And now you've automatically got this tree structure implicitly. So, but no, but you can already have this because you already have multiple claimants right, so claimants are unique right now. They don't support repetition, but we could do repetition. Sorry, but oh, you're saying even the subunits of the claimants. If you have a conjunction of me before Tuesday and me after Thursday, you're saying those are the same claimant. has appeared multiple pi, correct, and that would be invalid. So, yes, I don't see why would you prohibit that? Like, I can actually see a number of reasons why you might want to do that because, like, maybe

00:10:00.000 --> 00:10:59.999 align:start position:0%
You want to be able to, you want to, be able to be claimed by like a two out of three configuration, and so, like you know, I should be able to sign on two of the claimants, for example. So having repeated claimants actually seems like a very useful thing, unlike this alternating and in or four times. I'm not sure I understand why the repeating would be useful like other than in this disjunctive, normal form at world, like why, what usage could possibly come from that it's strictly less powerful than the tree, like anything you can do with the tree. You could also do with the claimants, like repeated claimants, but the opposite. Anyway, I want to come back to like: then I don't want to spend time about this, if nobody's concerned about this recursion issue, like my stamps on. The recursion

00:11:00.000 --> 00:11:59.999 align:start position:0%
Issue is that if the recursion issue comes into play, you already have a security vulnerability because your XDR compiler doesn't handle recursion well, or your XDR library doesn't handle conversion. Look, Oh, recursion well, so not. But the question is like: do we define a depth specifically for this data structure or we just expect to conform to whatever your XD? Our parser knows how to do this. One has a big depth limit. There are two paths to it. Yeah, there are two paths straight right there. From a security standpoint, you want to be able, like: you shouldn't never use in, you know unbounded num, you know amount of memory if you get untrusted data on the wire right. And then there is the second part, that is a protocol. And fourth thing, that is, what is the maximum depth? And it's fall, so they. In that case, if that's really what we're gonna do, I would argue against the maximum depth because that's hard to

00:12:00.000 --> 00:12:59.999 align:start position:0%
Implement, right, so people get it wrong. If we just have a maximum, do we have a maximum transaction size? Because then, because the thing is like, and maximum transaction size would at least be easy to enforce where did I think I'd rather I'm not go that route because, like right now, like John said, like the four, as it's kind of a nice property where we don't have to deal with variable based reserve requirement only, as soon as we say we have, we bound this to the size of the transaction. Now you're, you have to come up with an onion model. So this for how much to charge for return. Because now, like they're all going to be potentially a lot more predicates that you can put, Kristin, operations can get very big. So what's your? How big is your? Like a bad.

00:13:00.000 --> 00:13:59.999 align:start position:0%
Payment is, you know, can get is very big. So how big is your implementation of the recursion depth, John? How many lines I suppose, for us? Siddarth did it so I don't have it in my head right now, but I my guess is it's probably like on the order of 20. That's how much I think it would take me to implement it, and how many places just invoke that function in the code, because it seems like we're gonna have to check this in a bunch of different places. Right, everything is just one. Yeah, it is very eight, because they're immutable. So it's just like in the validity path you check like hey, like how deep is this? Cool, you're good, I mean, and how so? We need like a like basically every. We need a version in the SDK and then we need to like check that the two are equivalent, right, it seems like any time is it difference? Like, any time an SDK can be convinced to create a transaction of Stellar core we'll consider are incorrect or invalid. That's it,

00:14:00.000 --> 00:14:59.999 align:start position:0%
That's exploitable right. That's it that's exploitable right because I'll convince you that, hey, we're gonna do this thing where you can like: get a claim, a bunch of money or whatever- and then it turns out that you can't because Stellar core rejects the transaction. So I really I don't like this idea. But like, yeah, III don't think we should never do it. Like they're clearly times that's appropriate, but it just it doesn't seem justified here to add, like an extra validity role. That is not like. This is not a good argument. I think because, like in general, like you have an expression and you're saying, oh, like I want to look at the expression and I expect it to just pass in call but like, really like, if this expression is bogus, like it doesn't matter, like you know, it's going to be invited later, right? So maybe the reasons we should make it as easy as possible for SDKs and

00:15:00.000 --> 00:15:59.999 align:start position:0%
Other software in the Stellar ecosystem to replicate the validity rules of Stellar transactions. And obviously sometimes we need to add extra logic. But given that we haven't cited a single use case that it wouldn't be satisfied by a simpler approach here, it just it doesn't seem justified. But again, I mean, I've said my piece, I'm not. I don't object strongly enough that I'm overruling this. I did both to put this to FCP so you guys can heed my advice or ignore it. I guess how would you feel about the like the hard coded thing, the you know least one to three thing, better, much better, because like that would be easy to do and it wouldn't really impact the implementation at all. Because all I would do in the implementation is just parse it once the real, like the leaf four way, or you know depth for way, and then I would just parse it again as an infinitely recursos structure. Once I check that it's fine and you know. And then you can just, like

00:16:00.000 --> 00:16:59.999 align:start position:0%
You know XDR, start, you know SDKs and whatever, could just parse it as the for depth version and it would just work out of the box. Yeah, we would not even use the one with the labels in call. Yeah, we might not even use the one with the labels in core. Exactly, that's a good point because we know that we're secure against arbitrary recursion. So no, but the whole point is we want the logic in core to exactly match the logic in SDKs. Right, so the well, I mean we're paying, the sophistication is full. Maximum depth: fall right, so it would be the same spec, and they'll be giving a canned version to educator. I'm just for. I'm very skeptical that this, the four, is even necessary. Why don't we start with two and then, if we need for, we can do it. Yeah, we could start with two is fine, but I mean, like two hasn't helped you. A ton in the sense that like two has exactly the same

00:17:00.000 --> 00:17:59.999 align:start position:0%
Constraints is full right, like you'd still need to check the depths and everything. Well, no, because two is like much less unwieldy to do with, like a leaf in an internal rate, like now. It's sort of it's not that bad to have two different types for it. Also, you would need, well, I guess, like do you mean is in like Route one? Because no, I meant just like. I just meant when you have an and or an, or it's an andron, or of something that doesn't include andin, or of a leaf that's a lot more restrictive. But again, like, what are the use cases here? This feels to me like were we're building a mechanism without an idea of the use case for the mechanism. Right, and you can always increase the depth, right? That's not? Oh, yeah, that's a third site. You could always increase, you know.

00:18:00.000 --> 00:18:59.999 align:start position:0%
On the other hand, you know it may turn. out that the main bottleneck here is that it's like it may be like very unintuitive to have like and an award like complicated boolean formulas for this stuff. Right, like I think a simple one level, like a disjunction of conjunctions is something that you know it it really makes sense like, okay, there's like three conditions on which we can do this. It's like this and this are true or this is true. But once you start going to more than two deaths, it starts becoming like fairly unintuitive. Like it's what you know expect to, you know feed into your Sat solver because you've generated from whatever, but it's no longer gonna correspond to sort of simple human expectations. So do we actually expect that we're gonna be having compilers generate these like really complicated predicates and that we're just gonna trust these compilers to do something sensible, or do we just like, if we have a use case for that, I'm okay with it, but until we do, I'd say, why

00:19:00.000 --> 00:19:59.999 align:start position:0%
Not just defer having that complexity? I mean, I'm not opposed to going to in the short term and making it super simple and you know we can make it higher in the future when we need it. Like, would that be difficult if we started shallow and decided that it needed to be deeper? Would it be difficult? You know, it'd be very easy. I think that I have an idea how to implement this without the recursion. Maybe we can just allow the predicate to be an array of predicates and allow duplicate claimants in the conditions. So with these two preconditions, we can implement both and our cases, because duplicate claimants- for

00:20:00.000 --> 00:20:59.999 align:start position:0%
Example, two or more claimants with the same account ID, with the same destination- will allow to implement our cases. And making the predicate an array of predicates educates. It, makes they were all soon easier. It's intuitive, it's like it makes sense, it is fairly expressive. Clearly there's a lot of different opinions here. So let's take this. I think we've, like, we've talked out some of the details. Okay, take it to the mailing list and try to come up with what's the right thing to do. Like, the beautiful thing is like none of these changes are going to be very material to the implementation, so we can plug in whichever one we kind of think is the right one, but I don't want

00:21:00.000 --> 00:21:59.999 align:start position:0%
To take the entire time of this meeting talking about this one thing. Okay, so the plan then is to make these suggestions on the mailing list, evaluate them in synchronously and choose one for the implementation soon. Okay, that's what we'll do. Then email after this meeting and kicking that off. Cool then I. Or is there anything else that we need to cover on CAP 23? Or it's that sort of procedure forward with that I think we could probably take. If people want to talk about the other thing, about like changing this before and after notion to having a not, we can do that, but we can probably take that to the mailing list. Oops, they're all kind of bundled up is one kind of topic. So unless anybody really wants to talk about that right now, I'd say let's take it to the mailing list. Great, think it's the mailing list, look out for that in your inbox. Everyone get excited. So then we'll move on to

00:22:00.000 --> 00:22:59.999 align:start position:0%
Cap. Thirty three sponsored reserves. This proposal allows an entity to cover the reserve for accounts controlled by other parties without giving those parties control of the reserve. That extends account entries and ledger entries, so they were pertinent information about sponsorships: it creates new operations to initiate and terminate sponsorship and to update sponsorship information for existing ledger entries. The goal is to allow asset issuers and, while it's never user reserves, basically one issue came up, which is that there was some incompatibility with step 30, which is a Stellar ecosystem proposal that defines an API to allow users to regain access to a Stellar account after they've lost their private key, without providing any third party control of that account, and so I think these there's been some investigation of how to deal with potential incompatibilities and I'll turn it over to you. Yeah, I can give just a quick description of what the incompatibility is, and then we've

00:23:00.000 --> 00:23:59.999 align:start position:0%
Got a short term fix at the SAP level and then John will talk about a potential way. We might want to think about this at the protocol level later on as well. So the incompatibility is that Sept 30- the server that implements Sept 30 because of signing transactions for multiple accounts, it has this rule to find intercept that says that the server should only sign a transaction if the operations and the source Canon, the source count on their transaction and the operations is for the account that's registered, the account for the signing for. And the latest version, the CAP 33, has things like adding signers, including other operations that have to be signed by the sponsor account. So because this transaction that adds a signer that's sponsored, it has multiple accounts signing it, as have 30 server would reject this transaction. So the short term fixed that we're thinking of

00:24:00.000 --> 00:24:59.999 align:start position:0%
For at the SAP level is just to alter, that rule so that a Sept 30 server implementation can choose to allow the sauce account of operations to include some limited set of accounts that are knows that you won't be signing transactions for and that should allow, asked I'd say, the sponsor to that list of limited sub and would allow those transactions to be signed. And John also has an idea of how to deal with this in another way at the protocol level. Do you want to go? You wanna shut up? Yeah, I wasn't sure you were done talking, didn't want to interrupt you. So this harks back to a super duper old issue from actually opened by Jeremy Rubin, like out of more than two years ago it's protocol issued, number 93, if anybody's interested. But

00:25:00.000 --> 00:25:59.999 align:start position:0%
Basically Germany's observation was that signing transactions in the world of Stellar is very susceptible to the confused deputy problem. And the basic idea behind the confused deputy problem- for people listening- is basically like- or at least how it applies in the world of Stellar- is suppose you have two accounts, both of which that can be signed with a single sign or a single private key. And then you look at some transaction and you and somebody asks you to sign it for one of these two accounts, but what you don't realize is that it actually contains transact operations for the other account as well and you've now signed it for both accounts and it's good to go, and now you might have authorized something that you did not mean to authorize. There are other manifestations of this as well. For example, like it could be a more complicated world where, like you, have multiple keys and somebody asks you to sign for a certain set of keys and those keys combine to sign for some third account that you didn't realize you were signing for. So at the

00:26:00.000 --> 00:26:59.999 align:start position:0%
Time, Jeremy opened this issue and asked a question which was something like John will know the best way to implement this. That wasn't knowing, but at the time there was no way to implement. That was this. That wasn't annoying because there was no way to change signatures, but since David's CAP 19, which got like subsumed into CAP 15 and introduced the new transaction envelopes, we actually have the power to change signatures in a very clean way. And so the gist of my proposal is basically to add a new kind of transaction envelope which we'll call like, for the sake of this discussion, transaction envelope- no, confused deputy, but that's a terrible name. We wouldn't actually call it that. I don't know, I'm no good at names. Anyway, somebody else would probably think of it- and basically what we would. This transaction envelope. It would take the normal transaction, but it would require a different type of signature payload, for that matter. So transact signatures for an existing transaction like a train. Action v1 don't work here, but these

00:27:00.000 --> 00:27:59.999 align:start position:0%
Signatures would basically have a new bit field wrapped into the signature payload saying which operations you're signing for and also whether you're signing for the source account, and then when you provide the decorated signature, you provide that bit field again and since the signature is over that bit field, you know that you've gotten the right data. When you verify the signature- like if you try to verify the signature- it contains that big field and so you know whether you have it or not and then you just apply the signature weight to the operations and potentially the source account that matched that bit field. So this would be like a pretty clean approach and it would allow you to sign for like every single thing in a transaction anymore. It's pretty neat. It'd be some work to do and it would require overhauling a lot of the Stellar core signature processing stuff, but I don't think it'd be like breakingly, challenge, challenging, excuse me, but to be clear, the idea would be to try to proceed with CAP 33 now and work on these changes later. Yes, exactly, I mean like from my perspective, as long as

00:28:00.000 --> 00:28:59.999 align:start position:0%
There's a way to solve the problem and we're recognizing that, like the problem is beyond the scope of CAP 33. It's kind of like we could always choose to do this if people are encountering this problem all the time, whereas like if we had no proposed solution at all, then that's a lot scarier, right? I mean, I suppose we can also see how many people use some 30 and how the set level change affects people and whether it's not the problem. Legitimate, right? Yeah, I think that the reason that this incompatibility and compatibility is important is that people who use CAP 33- other people we may use- accept 30 and vice versa and as comparing 20 years, both. But yeah, I think we there's no reason to change that CAP 33 because of this problem. I think what John is saying is right. This is an underlying issue that we should address on the time and we do have a way to move forward with this up with sub 30 we have 33 together anyway.

00:29:00.000 --> 00:29:59.999 align:start position:0%
Alright, it looks like there's one other issue here about changing sponsorship checks. The truth. Sorry, I was trying to remember what the what I from applying to the validity. Yeah, so, right now, the way that the CAP 33 is written, the way that I've been implementing it, like we would accept transactions that have like, for example, like bad sandwich egg, but these transactions are 100% guaranteed to fail at the time of apply. You don't need like. Normally, when we do validity checks we're doing them on a single operation level. But like the reason for that is normally just because operations have side effects and we can't necessarily tell what they are. But for all of these sponsorship operations, like for beginning and ending in the sandwich King, like you don't need to do

00:30:00.000 --> 00:30:59.999 align:start position:0%
Anything to note. Like I can look at a transaction and tell you if it's properly sandwiched without applying any of the intermediate operations. And so the question is whether we should allow these transactions to make it to apply time and then fail at that point for being improperly sandwiched, or whether we should just say like no, your transaction stupid and it's invalid. Doing that would probably require some new machinery, but like it's not conceptually hard at all, it's just new stuff to build, whereas doing it at apply time is very easy, which is why I took that approach, but it has the disadvantage of allowing people to spend money on stuff that and also spend time on the network with stuff that's like obviously not going to work. So I don't know, people have a strong feeling about this. I know I've discussed it with Nikolai before, but I don't know whether he- what I don't really know which way he wants to go with that really cold. It's worth. I

00:31:00.000 --> 00:31:59.999 align:start position:0%
Would have thought we would check this kind of thing in the SDKs as well, even possibly in horizon. I mean actually thought about it, but, as you say, it seems trivial to check. I mean like, yeah, like for me it seems like it would be a good candidate to have this as the validation step, because it- you know, I'm trying to- its a usability thing. I think. That said, you know if we think that some bitching is more like remote in kind of a niche thing, maybe it's not worth it. I mean, either way is fine. To me it's more like, yeah, trade off of were classes,

00:32:00.000 --> 00:32:59.999 align:start position:0%
Because we can always change that later on to, so it's not like that's exactly, is gonna say that we always have the power to change this later. I also don't think it makes a huge difference to usability, because somebody's running these types of transactions is probably gonna be running a lot of these transactions, so they're gonna find out really early in development. Like they're not kind of- hopefully, I hope, I think I'm likely- then they kind of run like 10 000 of these transactions and then see them or fail. They're probably going to run one during testing. See a fail, fix the code. and then move on. Then there is a strong point. This is like a kind of like an enterprise tool, not really an individual user tool. Yeah, and if it is a user tool, it's probably not gonna be at a scale that is okay. So

00:33:00.000 --> 00:33:59.999 align:start position:0%
It seems like the answer is: don't worry about that great. Are there any other sort of comments, questions or suggestions about? Kathy? Actually not. As I mentioned earlier, ambit worried about the locked phones clawback logic. Without it, this proposal seems incomplete. And sponsor the sponsor sponsoring entity has no means to recover its phones from government sponsored accounts. We agreed to sync on this later, so just with the record, I think it's important to articulate this towards the timeline for this feature.

00:34:00.000 --> 00:34:59.999 align:start position:0%
Like this year, the desired feature list is fully parked, but next year will definitely introduce some way to deal with such situations, because companies that are willing to sponsor reserves for their client accounts must have confidence that they will be able to claim the walked funds in the future. I think it's important. But if you have some ideas about how to do this, I mean, like I would definitely welcome a proposal about how to do this. I definitely think that be a be valuable. I haven't really spent any time thinking about how to do this, other than the fact that it's like, probably possible with the current design, albeit, like, probably not that easy. But yeah, if

00:35:00.000 --> 00:35:59.999 align:start position:0%
You have a like, definitely like- submitted proposal. I'll definitely look at it. So I spent like a ton of time thinking about this. I have lots of context on it, sure, okay, great. I mean I feel like, even though there's, it seems like there's still a little bit to be resolved on uncap 23 33 it's feeling like it's in a pretty good spot and obviously these are things that were intending to include in Protocol 14, and already the horizon team and people that work on SDKs have started to think about what that means. And so I know Eric put together a working group to sort of go through some of the issues, figure out some decisions, and I think he's going to give us a summary of where they're at. Yeah, I don't have a same person except to say that we had a lot of discussions. We went

00:36:00.000 --> 00:36:59.999 align:start position:0%
Through and tried to think about use cases and then we tried to think about how this stuff would actually work and we came up with problems and the CAPs and we went back and modified the CAP and then we came back again. We went round asleep a few times. It was really useful. I've linked our discussion, doc in our agenda that you can look at to see kind of the gory details, an FAQ that's coming out of this, which will be helpful for the ecosystem, I think. And the outcome now, I think, is that we have a spec that's pretty solid. So there are two issues in the go mono repo 2787 and 2788 that you can have a look up. That really described the end points that we expect in horizon and the work that we expect to do in the SDKs and anything that's remaining that's unclear, I'm kind of satisfied- is implementation. That all

00:37:00.000 --> 00:37:59.999 align:start position:0%
Problems, how do you put things in, what tables, that kind of stuff. So I'm pretty happy with it. The only other thing to mention- I'm just going to mention this briefly, I know they didn't really want me to- there is a naming question in the CAP 33 whether we should rename these operations. There's something more clear, because one of the things that we ran into in this discussion was that we kept getting confused about what certain operations actually meant, and if we're confused then everybody else is going to be confused. This is relevant to horizon, because we have to name our SDK functions and our own points according to what we decide the actual operations are. So there's a mailing list discussion about that. I'm hoping we'll get an agreement on it. I like the new names. I think we should keep them, but we'll need that in order to actually make the final implementation. What are the new names? And one your news, sure? Yeah, I don't have

00:38:00.000 --> 00:38:59.999 align:start position:0%
An issue. Talk about the sponsoring future, as I think so. The sponsoring future reserves confirm and clear sponsorship and then update sponsorship. They were the original and the new proposed names are begin sponsoring futures as hen's sponsoring future reserves. So it's really clear that that's a sandwich. And then the third operation renamed from update sponsorship to revoke sponsorship, because that third operation is signed by the person letting go of a sponsorship or letting go of paying the reserve for the account. Yeah, I agree with all three of those, particularly the third one. Yeah, that seems nice and clear. I mean there's a lot of letters and some of those names. For super clear, we're gonna hit our 80 character limit. Yeah, on the lines of the

00:39:00.000 --> 00:39:59.999 align:start position:0%
HDR file after like one word. So as far. as you can see right now from your point, of view, and no surprise database migrations. It looks good to me. Yeah, I'm pretty happy with it. Cool. Any other questions about sort of prep for Protocol 14 downstream or about whatever? Just, I guess it's worth mentioning as well that I expect us to begin implementation of this in our next sprint, which will be in about a week in a house type, unless something comes up to dissuade us or ask us to spend more time. So those like pending decisions about CAP 23 think they have an impact on that timetable. That's significant. That's more

00:40:00.000 --> 00:40:59.999 align:start position:0%
Exciting, Eric, hopefully I'll have something decently functional for you guys to test off up by then. Yeah, when you can get me a cool build ok going. That looks like. There's one final small issue, which is started as issue 622: change clothes time, semantics. I think it's now CAP 34 or which is in the draft. You know, you want to just summarize that real quick. Yeah, like the CAP is not yet in a good transform. It's really rough. So I'll just focus on describing at a high level what its CAP it's about, which is actually: yeah, we had like a bunch of ideas going around in the issue itself, and this is the annoyance in the current protocol. So this is not impacting the SDKs or horizon. It's more, in fact, if the only

00:41:00.000 --> 00:41:59.999 align:start position:0%
People that are getting impacted are going to be impacted in a positive way, which are people that write transactions that, in the context of smart contracts that have expiration times and basically closing a net case that nobody is probably aware of, when the right, those smart contracts that today a transaction can fail, drink on Central Time, basically consuming the sequence number even though the time bones that was specified would make this transaction invalid. So basically, like the typical scenario is when it is smart contracts is you have mutually exclusive transactions on a time bound. One is, for example, only valid before a certain date and the other is that it only after, and then those are

00:42:00.000 --> 00:42:59.999 align:start position:0%
Like your two branches of execution basically. And here what we have is it's possible that it's a the first one, which is only valid before a certain time, would be accepted for consensus. Then only you would find it to fail during consensus, because the first time that was picked during consensus is actually incompatible with that conference. Actually, this is very annoying, because now, if you have this one transaction failing in your branch, that means, like normally people, what they do is they change transactions with hashes, right, and now that particular path basically becomes possible because you consume the sequence number, but she didn't actually execute that one transaction. So that smart contract is gonna be in a broken state. So it's

00:43:00.000 --> 00:43:59.999 align:start position:0%
A very edge it. So it's a really an edge, case. And because it's an edge case, yeah, we want to get rid of it anyway. So the fix for it that we came up with David was during Constance is basically this: pick as close time the one that is associated with the transaction set. So normally when nodes nominate a value in general, so the value is made of transaction set, close time and upgrades. Right now, what we do is that, when we get at the end of we do is that when we get at the end of nomination, we combine all those values into some more interesting value, that is, translate a transaction set that is one of the transaction sets that made it to the end of nomination, and then a closed time that is the biggest closed time.

00:44:00.000 --> 00:44:59.999 align:start position:0%
So instead, what we're going to do is going to preserve the opportunity of transaction set to close time and by preserving the affinity, what we can do is actually change the validity criteria for a transaction set. I mean up for the pair transaction set, close time to only allow transactions that are going to not be expired with the that given transaction set. So basically, it's pushing the burden through the nominated value. It sums up like the actual change is that and then will kit will basically not even include those transactions that would expire between two Ledger's in the transaction set start the gist of the update change. So it's not a big change but it potentially will make it

00:45:00.000 --> 00:45:59.999 align:start position:0%
Can be a life changing for those people that may hit that Berg. Do we have actual use cases that are running into this? So we so the thing that we see those transactions fail today on the ledger, so people are running into this, it has definitely happened before it happens we don't know. In the context that people know what that we don't know and we don't even know for sure. Like contracts that you didn't even you know that didn't happen yet. Right, like that's the problem with those things, that they are pre signs, we don't know yet what. So fact, here's my concern. So I agree this is a problem and I think there are a number of ways to get fix this problem, including this, which seems like a plausible way. Another way would be the kind of signed operations proposal that I made just on

00:46:00.000 --> 00:46:59.999 align:start position:0%
The mailing list. But the problem is that all of these things, they eliminate some j and introduce other edge cases, and so I'm just a little apprehensive about doing it sort of in the abstract, because so, for example, this new proposal would definitely would facility Ned case where, like you know, you've got a payment channel and you know you submitted something and it, like, expired and, like you know, you would have submitted something else otherwise, and now you're- sequence numbers are messed up. On the other hand, under the current proposal, there's a danger that if someone is doing like atomic cross chain swaps, that it would work today, and with this proposal, if there's a network outage, you could actually lose money, right, because no, like this is fixing a niche case where you're guaranteed that the transaction states that it will not

00:47:00.000 --> 00:47:59.999 align:start position:0%
Exclude transactions that would succeed. So here's so, ok, so the fact. So either I'm misunderstanding it or you're misunderstanding me. Either way, it's in its. It's an indication that this is an edge case, which is so. Imagine that what we're trying to do is we're going to swap lumens for Bitcoin, right, and so what I need to do is I'm gonna claim my lumens and, in order of my to claim my lumens, I'm gonna use a hash X signature and by disclosing that, someone's gonna be able to like claim their Bitcoin, right, and I have to do my thing by certain deadline, and then the Bitcoin person has an extra hour to like take the preimage that they've found in the Stellar transaction and use out the claim the Bitcoin on the Bitcoin network, right. So under this new proposal, if some, if the Stellar network goes down for an hour, it's possible for an operation to actually execute, even though it was supposed to execute at most one hour ago. Right, and so you know again. So this will require Dawson. The network are getting a

00:48:00.000 --> 00:48:59.999 align:start position:0%
Little bit lucky with the time of a of an outage, but if it's, if you're trading enough Bitcoin for lumens, that's something you'd be concerned with. So again, it's not, I'm not saying it's a bad idea, but I'm saying it causes potentially other problems that people- now I mean not that we're sending what you're describing, because if I don't already exists, David, yeah, this problem already exists. This I, we messaged Justin about this like a very similar problem this morning, like two hours ago, like right now. Imagine this like super terrible thing happened. Imagine that you submitted a bunch of transactions- you know, like I submitted some transactions, Nicola, David, Lee, OrbitLens, Justin- to like we also made a bunch of transactions. And like Eric also submits a transaction, but Eric's name starts with E and that means that he's malicious. In conventional you know crypto stories and Eric knows of some zero day that allows you to crash the network at externalize time. And so what happens is like Eric's transaction gets into the ledger, all of our transactions

00:49:00.000 --> 00:49:59.999 align:start position:0%
Get into the ledger, and now the network is dead, like it crashes during you know ledger closed and nobody externalizes. As a consequence, everybody crashes. Now, like when you restart the network it's gonna crash again because you are committed to this transaction set. So the only thing you can do is update the software. Blah, let's say this takes like 36 to 48 hours probably to get everybody back up and run. It would be like, I think, a reasonable guess, maybe even a conservative guess, but like you should not consider any transaction expired on the Stellar network until you've seen a close time past that time, you can seen a close time, past that time, you can say that transaction is expired. But until then you cannot. Because no matter what model we use, like, it's possible that the difference between like the clock close time when the like ledger actually externalizes and when the like a long time like the Stellar header close time could be like arbitrarily far apart. So this problem exists today. Like if you get into the

00:50:00.000 --> 00:50:59.999 align:start position:0%
Situation like that transaction might execute until that ledger closed timestamps. I think this is a different problem, so this is also a problem. But the problem I was concerned with, is that a transaction with an older timestamp might not get disclosed until long after that timestamp. Right, and if the contents of that transaction unlock something on a different blockchain, then that's a problem. Can you give some more background on this. I'm not sure I understand how that would sure like so. Okay. So basically, we propose a block with a particular time, right, and that time was an hour ago because- and in my case you don't need a software fault- it could be like some botnet attack Stellar

00:51:00.000 --> 00:51:59.999 align:start position:0%
Or something, right? So it takes us an hour to like recover from this thing and now we're going to execute transactions that were like an hour old because, like, it's still the biggest block that's been nominated, right, even though, at this point, like, everybody should be nominating everything. But it could be that the block an hour ago was like the biggest blog- nobody's heard of neuro transactions, right? So, even though other people should be nominating like higher timestamps, we- you know well how it will execute- like an old timestamp, and so people might learn about a transaction with the timestamp of 11 00 a m at like 12 00 p m but like shouldn't you only vote for a transaction set or a Stellar value that has a timestamp that's close to your clock time so like if everybody thinks that transaction is super old nobody should vote for it because it doesn't have a good close time no you

00:52:00.000 --> 00:52:59.999 align:start position:0%
Should vote for anything anyone elses and any one of your leaders is voting for only if and you can take and currently yeah only if it's valid actions should we consider a transaction with a super old closed time valid do we even do that to walk a block with this a value with a super old yeah that's my mentor value I don't think we'd have that even happens today I think that if it's older than like 60 seconds it's dead nickel I would know the best so I'm gonna let me Claude take it can be any clock in the between the lapped ledger and the current time all this that can be introduced as a potential but we pick the highest anyways so Jeff people repetition so I think that what that my point is that no II don't think yeah no change like that like the likely close time to win in that situation is going to be appropriately

00:53:00.000 --> 00:53:59.999 align:start position:0%
Current time oh okay that's confusing actually hold on that's not what I inferred from the proposal no I knew were close time with a worse transaction set no is it so no but like the it's when you have nodes nominating you know a pair transaction set close time the close time that the nominate did you introduce on the network is there local clock time right so that's the so actually if you walked out for like an hour you know during hour you know during the last ledger that new ledger will be an hour later obviously like compared to tie so is it's actually snapping to the current time it doesn't but a malicious node could say that it nominated something with an old time right like is there anything stopping them from doing that these are well there's a race right so like the gos

00:54:00.000 --> 00:54:59.999 align:start position:0%
Can happen at any node can be do s right so any node can introduce a closed time so in this particular situation the change of pick being I guess that's whether the changes you may end up with picking the transaction set a closed time pair from one node that actually decided that it was not going to nominate something that was close to the current time like instead something in the past you know but close to the bigger than the last time I just wanted to say by the way that were fast approaching the end of the hour so I don't necessarily want to cut this discussion off but at some point I think we'll stop the livestream and figure out the best way to have this discussion move forward yeah since people I mean basically what I would like to do is I would like to either have you know

00:55:00.000 --> 00:55:59.999 align:start position:0%
A little bit more data about like sort of smart contracts and stuff just to make sure that we're not sort of solving one problem and creating another and second of all maybe a little bit broader discussion because the point is like these sequence numbers are actually like annoying in more ways than one and so it could be that if we solve the sequence number problem then this issue goes away and we haven't had to also create this potential annoyance for like atomic cross chain swaps so there is already a way to avoid this sequence number problem I actually described it an issue 6 22 like three or four hours ago but the basic concept here is like instead of letting your transactions have sequential sequence numbers they have gapped sequence numbers where like you can choose a gap of one for example and then the transaction just needs to have a bump seek and so if it fails you know that it didn't happen and that would solve so many other it would like solve a whole bunch of other problems

00:56:00.000 --> 00:56:59.999 align:start position:0%
Too so it's like I'd way rather just like kind of address that problem rather than just do this one thing that's targeting this one very specific problem which we don't even know is exactly the problem that people are having in practice we know it running into these four regular infections no but all we know is that some transactions are getting submitted that have a bad close time right but we don't know that that's like messing up people's smart contracts and you know those people may not care that they're losing a you know 100 micro or 10 micro lumen fee or whatever like it just might not be a big deal right way so you want to put a face to those transactions yeah there'd be so much upside to actually allowing the gap sequence numbers like because that would solve all these other problems too so like if issue like here what we are talking about is that there might be smart contracts out there that are

00:57:00.000 --> 00:57:59.999 align:start position:0%
Broken because the way things are actually specified is wrong right and what I'm telling you said if you lock gap sequence numbers so many it will solve so many other understand with including this problem right no you have the same there's only would affect our new one yeah new ones would be fixed but you wouldn't fix old we don't know that there's any smart contracts in use you can't say that we don't know sure but like let's let people complain about a problem before we contract well describing here is the very like this I think in most examples of smart contracts the you know branch on time like you want something but it you know I branch before some time and a different branch on the different best like the like 101 I would

00:58:00.000 --> 00:58:59.999 align:start position:0%
Argue it is I would argue smart contract when I want is the cross chain swap right well I think yeah like you bring up a super good point here which is like anything that we're proposing as a solution here like we better test it to make sure that it like it should be perrito better right like if I'm not happy with the solution that six is this problem but makes you know cross chain swaps worse so like probably like mmm I don't know if it doesn't I think we should do was the thing right we're going to have a conversation on the dev mailing list for this one and David if you if you can show us how are these breaks Atomics I mean across as change swap happy to fix things then break things so Jonathan John if you have another idea for how did you CAP sequence numbers side spices signed I

00:59:00.000 --> 00:59:59.999 align:start position:0%
Had that one frozen for the signed operations but basically something simpler like I think I'd rather just argue if we have something that like I can argue fixes this problem but also fixes other problems I'd rather spend my efforts arguing favor something we still have the same problem that's the problem with any other solution we will keep the cruise time broken comes with respect we don't know if we have gaps sequence numbers then there's no issue because I can basically sir so right now in the back we say if you have but time bounds they've drawn at the bad time bounds the transaction is embedded that's what the spec says and we're actually not doing that feels like it feels like right place to end up to him I think we should yeah I'm right there any of this one 622 thanks everybody for watching that's the end of this week's Open Protocol Meeting see you in two weeks

01:00:00.000 --> 01:00:59.999 align:start position:0%