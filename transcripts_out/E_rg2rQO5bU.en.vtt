WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:59.999 align:start position:0%
Welcome to this week's Stellar well actually Soroban Design Discussion this is where we have public discussions about key decisions about the evolution and development of sorbonne as anyone who is here probably knows Soroban is a new smart contracts platform, that is designed to work well with Stellar we are deep into its Evolution it's been on on futurenet since October there have been I believe seven preview releases of Soroban and we are continuing to iterate a focus to hone in on important changes and decisions, that need to be made and to implement them as we move towards the completion of production ready code. But today we will be continuing to talk about some of the key decisions, that still need to be made and I feel like I have. Now stalled long enough to let people join. So welcome we sort of have a little bit of a loose agenda today. But I believe, that there was something, that we wanted to talk about and I believe, that Garand
00:01:00.000 --> 00:01:59.999 align:start position:0%
no is is gonna start by by introducing the topic is, that true Garen yeah yeah can everyone hear me all right yes yeah cool. So I guess you know for the last couple of weeks we've been talking about the high level archive interface and this is kind of the interface where with Soroban data types we charge a fee for staying live on The Ledger and then. If that entry does not pay the fee. Then they are sent to this archive where you can. Then restore the entry for some fee. And so we've talked about the high level. And so today I'd like to talk a little bit about our implementation timeline for this project. And then go kind of a deep dive into some of the details in the you know first step in the implementation timeline. And so first off I think in the last couple weeks we've been calling this the archival system and we are officially pivoting naming wise to State expiration just to remove any confusion with like history archives or anything like, that
00:02:00.000 --> 00:02:59.999 align:start position:0%
and. So I'll be calling it expiration today. But it's still the same system we've been talking about. So first I'd like to talk about the timeline. So there's a lot of moving Parts here and there's a lot of complexity especially with the structure of the storage itself using potentially like a vertical tree or some new data types, that aren't fleshed out super well yet. And so we are staging this in two parts we have a part of the project, that needs to be done. When we launch Soroban pubnet. And then a second part, that we can kind of finish later on after launch. And so at launch there are two big components, that we want to have ready and done. Now the first is we want to implement the rent system and temporary storage completely, which means, that from day one sarban entries will need to pay rent and also will have rent charged from them. And then secondly we want to have the unique storage and recreable storage interface finalized and exposed in the Soroban SDK. But we won't actually turn on on state
00:03:00.000 --> 00:03:59.999 align:start position:0%
expiration yet. So what this means is on day one you can expect to have all the tools you will need to deal with State expiration even, though entries will not yet expire and be sent to the Deep storage and they won't actually need to be restored kind of our thinking with this is, that actually implementing the storage backend is a very significant problem, that will take some time. But as long as the interface is set and finalized at launch even, though we haven't turned on state expiration yet any smart contracts are deployed on day one we'll have the proper interface and the proper tools to deal with State expiration. When we do eventually turn it on later. And so kind of with, that in mind I'd like to talk about today some of the details between the rent implementation and the temporary storage implementation, that's kind of the first step implementation wise and getting State expiration into sorobot. And so first I'd like to talk a little bit about rent and some of the opening questions we've had there in some of our
00:04:00.000 --> 00:04:59.999 align:start position:0%
findings findings. So we've discussed rent briefly before where essentially every sorbonne data entry will have a rent balance field attached to it and this rent balance field contains some XLM, that is tied to, that specific data entry. And then periodically over time the rent fee is deducted from this rent balance where the rent fee is the fee for being on the network being live on the bucket list for a given Ledger. So the rent fee is variable based on the size of the bucket list kind of in a similar way as to the bucket list write fee in the fee CAP the thinking here being, that we want the rent fee to increase as the size of the bucket list increases the reasoning for this is, that as The Bucket List gets larger the fee for adding the bucket list also increases. And so we don't want this fee to grow exponentially or grow unboundedly. So by also having the archive or the rent fee increase at the same rate what you can have is this
00:05:00.000 --> 00:05:59.999 align:start position:0%
equilibrium where as it gets more expensive to add to the bucket list and as The Bucket List gets bigger the fee increases. So it's more likely, that more entries will be removed and deleted from The Bucket List as they run out of rent and as they expire. And so we kind of have this equilibrium system set up with this variable fee rate. Now in addition to the variable fee rate I think one of the questions, that we haven't really addressed yet is how we actually pay for the rent on these entries. And so initially we wanted this process to be as seamless as possible. And so we wanted a way to automatically bump rent whenever you access items other thinking being, that the developers shouldn't have to worry about manually paying rent for entries, that are used very often and. If an entry is often used it should just automatically have a small rent bump. So it's always live and it never gets sent to the archive archive. However the issue with, that is there didn't seem to be a good default behavior for paying rent primarily. Because different types of contracts
00:06:00.000 --> 00:06:59.999 align:start position:0%
might have to pay rent differently. And so I think the big question here is who is responsible for paying rent is it the user who's invoking the contract, that's responsible or is it the contract maintainer itself who's responsible for paying rent and kind of in our case studies we determined, that there are two separate use cases, that kind of illustrate this example well. So one example is you have a token contract such as usdc where you have users, that have an individual token balance, that they kind of own. So even, though a circle or some third party would be maintained this contract the token balances are tied to users. And so it seems to make the most sense, that the user would have to pay to maintain, that token balance. And so in the token contract example you would want the invoker of the contract to have to pay rent fees. However in the other example you have something like an AMM and say, that we have an AMM, that has a liquid equal or an asset pair now. If you want to access this asset pair this is kind of a public
00:07:00.000 --> 00:07:59.999 align:start position:0%
shared resource of the AMM itself. And so it doesn't make sense for the individual user who's accessing the access pair to have to pay for the rent even. If that entry would be used by many different users of the AMM. And so we kind of have these two separate cases where in the token contract you have this kind of individual owned entry by one user where in the AMM case you have like the shared resource and we wanted to see how we could fit the rent payment into, that paradigm paradigm. And so there didn't seem to be a clear way to default bump rent. Because there's no good default Behavior as to who pays. Because it's very dependent on the contract and the data type, that you're dealing with. And so instead of offering some mechanism to bump the rent by default what we were doing instead is exposing two Primitives, that a smart contract developers can use to define how retinas paid for their entries. And so what these two Primitives are are we're calling them rent bump. And then
00:08:00.000 --> 00:08:59.999 align:start position:0%
rent bump from and these are modeled after the token transfer contract. And so kind of in the native asset contract you have two functions, which is a transfer and transfer from, which is how you are able to transfer tokens. And so essentially the rent bump from functions work in a similar way insofar as you can Define who the from address is from. So who is paying for the rent. And then also with rent bump from you can also pay out of an allowance. So this allows smart contracts to do is to find who can pay. So for instance in the AMM example it might make sense, that for every transaction in the AMM a small fee is collected and put into a central shared pool. And then from this Central shared pool the AMM pays out rent to the shared entries in this way the cost of keeping those entries alive is spread out and amortized among the entire user base and
00:09:00.000 --> 00:09:59.999 align:start position:0%
so you don't have one particular user, that gets unlucky and has to pay to bump a rent entry. If they just. So happen to access it. When it's low on rent. But instead you have this centralized pool, that the contract can pay from. And then in the token example instead of having a centralized pool the user itself would have to bump rent. But we want to give flexibility. And so it might make sense for certain implementations to still want to have a user pay for rent. But instead of for instance for usability purposes the contract would want to pay on the user's behalf. And so using this interface. Because it's similar to the Token interface allowances can also be used for paying rent. So for instance say, that a circle for whatever reason wanted to maintain user accounts on the user's behalf. But didn't want to pay for it what they could do is, that they could the users could give the contract an allowance. And then from, that allowance they could call it rent bump from. And then bump the rent on the user's behalf even without the user themselves
00:10:00.000 --> 00:10:59.999 align:start position:0%
signing or invoking, that operation. And so with these two Primitives we think, that we have a pretty good coverage as to the use cases as to who pays and how you pay and kind of allowing for these individually owned entry types and also these shared resources resources. And so I guess on the rent and rent payment front are there any questions or anything, that we want to talk about there there Karen it looks like there is a question from moots in the chat, which is does this mean contracts are responsible for exposing and defining logic to pay slash bump rent for contract data entries yeah. So the answer to, that is yes. And so looking at I think we were trying to again find a way to do this kind of under the hood without the developers explicitly saying it or explicitly defying it in the contract. But the issue is there is no good default Behavior. Because of the different use cases between something like a token contract in AMM. But looking at kind of the design paradigms, that we're seeing in token
00:11:00.000 --> 00:11:59.999 align:start position:0%
contracts. Now whenever it comes to State a lot of contracts including the the example contracts, that we have in the Soroban samples repo have these helper functions for getting and setting values. And so I think what makes the most sense from a developer perspective is just adding an. If statement to these Getters and Setters, which most contracts already have to find and essentially what this would do is like a say you have like a git token balance function what would probably make sense is, that you have an. If check there and say. If the rent balance of this entry is below say a hundred lumens or whatever value you want. Then bump it by a thousand and so, that's kind of how we're imagining this would work from a contract developer's perspective is you'd have these scattered and Setter functions with this. If statement check. And then this also allows the contract to Define who pays and how you pay within this. If statement, that's another important part of this is, that the current rent balance of the entry is exposed within Soroban. And so the smart contract itself can check the current
00:12:00.000 --> 00:12:59.999 align:start position:0%
rent balance and see. If it wants to bump the rent or not bump the rent based on, that good balance oh I have a question I'm really concerned about the pool Solutions just. Because it seems like too easy to abuse them by creating just a lot of junk entries, that you know contract would bump unconditionally like oh okay think of allergies. So I think this would have to be an implementation detail of the contract itself. But I think a a smart or a wise development strategy for something like an an would be to have this fee pool. But to not pay rent for all entries equally. So for instance one possible implementation would be, that you have a few pool. And then you bump entries on access and this is defined by the AMM contract itself. And so for instance. If you have a junk entry
00:13:00.000 --> 00:13:59.999 align:start position:0%
that's never actually used in the wild. Then its rent would not be bumped from the people. Because at least how I'm imagining a solution would be is whenever a user accesses like an asset pair or something like, that you check the current balance or the current rent balance of the asset pair. And then based on, that balance decide to bump or not. And so in your example. If you have a Spam entry, that someone may charge to game the system or drain the people or something like, that first off I would assume, that the AMM would probably want to have some price to create an entry to deter spam like, that. But also. If the spam entry is never accessed. Then it would never enter, that. If check. And so Sprint would not be eligible for bumping. If that makes sense cool. So I guess God I have a two questions questions okay. So the first one is about a state. So my understanding and please call me
00:14:00.000 --> 00:14:59.999 align:start position:0%
if I'm wrong, that at some point we want to to come to kind of like Get rid of some of the state and basically send it to archiver right and be able to delete it effectively from The Ledger and. If needed restore, that later on my co-workers. So far yes okay and I also assume, that. When we want to restore it right we will have some security guarantees like cryptographic guarantees of some sort like as you mentioned the vehicle 3 or something of, that sort yeah correct okay, that's great. Now I'm wondering what happened. If let's say hypothetically I'm creating a application and. And so forth and my transaction is such, that I don't want
00:15:00.000 --> 00:15:59.999 align:start position:0%
want my my leisure keys to eventually go to the archival I want them to disappear or dissipate into the nothing and and. When sending the next transaction later on on I want as part of, that transaction to send the content of The Ledger key well instead of going in during the execution time network itself would use, that is the source of truth instead of going to the archival right and from security perspective, that should be equal. However it does give me as a developer the power to to let my information not being stored on every node of the network forever it basically moved the power to me
00:16:00.000 --> 00:16:59.999 align:start position:0%
whereas the network is just storing the state state. If that makes sense so. If I understand your statement correctly it's the the network is storing the state. But not the key and the user is responsible for maintaining their own Keys is, that what I'm understanding I'm not quite sure exactly. So basically I'm I'm suggesting, that the archival is fine and I realized, that for me for the classic use case you want to basically keep storing the state for everyone. But for some people it are very sensitive about their information they might want to use the network to store the state with all the cryptographic proof right and everything. But without the data itself itself and let the data be more ephemeral okay I understand I think
00:17:00.000 --> 00:17:59.999 align:start position:0%
I think this is probably possible and correct me. If I'm wrong on this. But just in the current smart contract interface right I don't think it needs to special case this into the archival system or the protocol level. So for instance. If you cared about this what you could do is have a smart contract, that takes a hash payload and Stores a like hash payload has one of its data members and this hash payload could be the checksum with cryptographic hash of data, that the contract developer has off chain somewhere. So I don't think this has to be a archive or protocol specific special use case I think the current Soroban SDK already supports this they're just beyond the onus of the developer to make such a system yeah yeah yes you're saying it would be a already possible to implement it independently yeah. Because what you could do is just have a smart contract, that has like you know just Define some key space. And then
00:18:00.000 --> 00:18:59.999 align:start position:0%
the values of those keys are cryptographic checksum of data, that start off chain I don't think we need to special case, that or should special case, that. Because the tools exist already to build a contract, that does exactly, that let's see interesting okay, that sounds interesting thank you Karen regarding the fact, that fees change based on the size of the bucket list what is the expectation how are users or developers expected to make decisions decisions obviously you know they want to pay rent for a specific amount of time and they don't have access to this information. If I understand correctly yeah. So this is one of the open questions is to do we Define rent in terms of Ledger time. And so I think. When we get to the temporary storage in
00:19:00.000 --> 00:19:59.999 align:start position:0%
a bit I will talk a little bit more about this. But I think from from a market perspective and from like a a system performance perspective it makes sense for the v2b variable based on Buckle the size. So we can have some sort of upper bound on bucket list size via this increasing fee rate rate. But from a user perspective I do see how there's a significant advantage to having a definite kind of Ledger you know estimator as to how long something will live in terms of ledgers instead of this like ephemeral fee or something might last five months Etc. And so I think what we decided in listening to some of the developer feedback on the Discord Channel it looked like, that for temporary entries it was important for temporary entries to have a definite well-defined lifetime in terms of ledgers, that is. If you define a temporary entry, that has a TTL of 128 ledgers it should live exactly 128 ledgers no less no more. So I think, that for temporary entries
00:20:00.000 --> 00:20:59.999 align:start position:0%
especially for anything, that might be a temporary allowance or anything, that has security implementation or implications it is very important to have a definite Ledger Lifetime. And so for temporary entries the plan is to offer a set amount of ledgers. And so how, that will look is in order to keep people from essentially abusing, that power and getting free rent or cheaper rent we would have to have some sort of upper bound as to the amount of time, that a temporary entry can live and so, that could be like three months six months something like, that. And then essentially people would have to do as far as the fee is concerned is, that there's two options here we could either just kind of take a best guess as to what the the fees would be over the lifetime of, that temporary entry and the estimate and say okay like say the current front fee and it's just an arbitrary number I'm throwing out there is two XLM per Ledger. And so we're going to pretend, that that stays constant. And then charge this entry to XLM per Ledger after its entire lifetime and, that's the
00:21:00.000 --> 00:21:59.999 align:start position:0%
fee of the temporary entry, that's one way the other way is potentially is, that we know, that the the upper and lower bound of the fees. Because the bucket list can only grow at a certain rate as the upper bound. And so another possibility is to essentially charge the upper bound rent as. If the bucket list was to grow as much as possible every single Ledger. And then whenever the the temporary entry gets deleted refund the difference. But essentially for temporary entries there will be some sort of fee model or some sort of something to ensure, that it does have a very specific amount of ledgers, that can live. Now for the recreatable and unique storage types, that can be archived I think it matters and again I'm open to developer you know feedback on this I think it matters less, that they exist for a specific number of entries. So essentially. If you have recurable storage in temporary storage. If it say
00:22:00.000 --> 00:22:59.999 align:start position:0%
if you define 128 ledgers worth of rent. And then for some reason it you know rent goes up. And so it dies at Ledger 125. You can still go and recover, that I think it would be annoying from a user perspective and maybe like not not the best ux. But I think it is a recoverable entry. And so there is no long-term long-term permanent side effect for having a ledger, that is archived slightly earlier or slightly later whereas for a temporary entry, that's permanently deleted. If you access something, that has 128 ledgers worth of rent and it's gone on Ledger 100 26 it's permanently deleted and there's no recourse. And so I think. Because temporary storage and recreatable storage isn't being deleted. But it's being sent to the archive, that the bounds don't matter as much and especially since temporary storage and unique storage aren't intended to be used for these ephemeral kind of like
00:23:00.000 --> 00:23:59.999 align:start position:0%
author security purposes there's not a security risk there I think from a user perspective what makes sense is, that from the interface expose paying rent in terms of ledgers. Because I think, that's the language, that developers will understand. And so I think what we'll probably do is say Okay I want to bump this by a thousand measures or 10 000 ledgers or whatever and what we would do is take the current bucket list price do an estimation estimation. And then I think what we could also do is maybe add an optional parameter to the rent bump, that says I want this much wiggle room. So say like I want like 10 000 ledgers worth of you know rent. And then put another 200 XLM in there just in case. And so I think this works pretty well and I think, that you know even, though the rate is variable I don't think it will the growth is bounded and also I don't expect the growth I don't expect it to grow or change quickly. And so I think
00:24:00.000 --> 00:24:59.999 align:start position:0%
if it's an entry, that's being accessed often and you're doing like this. If check on every access, which is kind of the the recommended design Paradigm at this time. Then as long as, that entry is being often used it doesn't really matter. If say your five or six ledgers behind where you thought you were going to be you can still do, that check and. If it's the frequently used entry catch it in time. And then bump the run again. And so I think, that's kind of makes the most sense is, that for temporary entries they have strict time bounds or recreatable and unique entries you pay rent in terms of time they're not strict Karen I was wondering. If I could also mention something or maybe even ask you about this yeah sure well it's just, that you've been talking about these sort of arbitrary numbers of letters and. If my understanding is correct here and there's no real future in, which we're going to be deleting
00:25:00.000 --> 00:25:59.999 align:start position:0%
something at any point other than a bucket merch right I mean we could could factually pretend it had been deleted. But it's not actually going to be deleted until until a letter merge happens or sorry a bucket merge happens right yeah correct okay. So so those there are only you know 10 possible boundaries where, that happens. So like it's it's not like you have arbitrary granularity here to to sort of practically worry about you you basically you have like and and most of those granularities are actually quite small with it the bucket list is a little funny in this respect and a lot of the levels are actually quite short they're they're you know 10 minutes 42 minutes 170 minutes all the way to level six right. So assuming you have any level of permanence to to your problem, that you you have a a thing, that you want to keep alive for any serious amount of time you know, that you're probably only
00:26:00.000 --> 00:26:59.999 align:start position:0%
dealing with level eight eight nine or ten granularity right probably nine or ten granularity, which is you know little non-granularity is basically seven days and level 10 granularity is basically 30 days. So like as far as I can tell the the sort of the the Practical usability of this at a user interface perspective all possible values, that you could set Rent to are practically probably going to collapse into some number of weeks or some number of months and you'll just pick it up a weaker month number and, that's, that's sort of like you can imagine there being some really complicated pricing mechanics in here. But like practically speaking I think you know level 10 merges happen about once a month. And so those are the only times in, which which you're likely to be talking about being expired is, that does, that sort of fit the user interface model, that you have in mind or or am I just sort of missing the point yeah no, that's true. So we only do we
00:27:00.000 --> 00:27:59.999 align:start position:0%
only you know we archive or delete entries during merge events. And then we're also conservative in how we charge rent rent. So this is also detailed and a document, that'll be shared later today it's kind of like the the first CAP on this temporary storage and rent proposal. But the way, that we charge rent during bucket merges but. Because the fee is variable we can't be up to date on charging rent. But we have to retroactively charge rent just. Because buckets are immutable. And then merge result of buckets are produced in advance. And so you can't charge rent until every Ledger's rent is known. And so for, that reason essentially. When charging rent rent you lag behind one level. So for instance. If an entry is live in a current bucket at level four it has only been charged rent up to and including the ledgers app passed to The Bucket List level three it's a a little complicated all let's say we are
00:28:00.000 --> 00:28:59.999 align:start position:0%
conservative. When it comes to archiving and so I think from a user perspective even. If you know the price increases and you're off by a little bit more likely than not. Because of the conservative nature of our rent charging scheme it is significantly more likely, that your entry will live longer than intended instead of shorter than extended. And so all this talking about like it does it get you know archived like a couple hours early this is kind of the most extreme case where you get really unlucky or. If you have like a small amount of rent, that gets archived at like level six or seven. And then you know the bucket list grows the maximum amount possible for every Ledger between creation and archival. And so this is very much kind of worst case circumstances in the average case your entry will most likely live longer than the the rent, that you supplied supplied yeah yeah and I guess what I was getting at is, that you're it's likely to last a month longer all right
00:29:00.000 --> 00:29:59.999 align:start position:0%
like like. If if you make it over the line by a bit you're probably not going to get touched for another month. If yeah. If you're looking at a certain last level of merges yeah it's a little bit I'm trying to understand it's great in suggesting, that we change the interface to rather than be like arbitrary rent deposits you actually point at, which like, which next level do I want to this to die on basically no I'm I'm not suggesting a change of interface I'm suggesting, that that the thought process, that the user is going to be going through to try and calculate rent will realistically probably only have numbers, that are multiples of 30 days worth of rent. Because there's the next lowest multiple, that has any meaning is is only seven days like they're just they're I'm saying, that they're you're you're you've kind of got a like a weird number system where you can Target specific
00:30:00.000 --> 00:30:59.999 align:start position:0%
ledgers. But it doesn't I don't think it's ever gonna I don't know I need to think about this more I guess sorry. But wait you're saying they like don't have to worry about being five minutes late on their rent they'll like have they'll be these big chunks of time it's kind of like paying rent on an apartment it's like every 30 you'll have 30 days of expiration at like this super granular thing. So it'll be easier to deal with is, that kind of what you're saying, that's, that's what I was asking. But I think I think Karen's garen's point is is, that we we are going to be doing it on on every possible level it's just just we'll be one one behind and. And so so to kind of give a concrete example for this say you have a level, that contains like 30 days worth of rent. And then a user pays 31 days with a rent in order to be archived you
00:31:00.000 --> 00:31:59.999 align:start position:0%
have to be at zero. When that merge event happens and so. Because after 30 days a virtual event happens. But the entry still has one day left rent the entry is not archived and goes to the next level. And then say the next level level is like 60 days it will take 60 days for, that bucket to merge and so, that entry will essentially live rent free for 60 days. While it waits for the next merge event and then, that merge event will check and say oh you're zero you can be archived. Now and so, that's what I mean by one level behind and we have a conservative archiving and rent approach I think I think, that's kind of what I was getting at was was this this this idea, that. If it's not like where it's. If something survives a level 30 merge or oh sorry level a level 10 merge, which is once every 10 every 30 days is level 10 merch bottom level of The Bucket List gets merged every every 30 days so. If if an entry survives one of those we're not going to like suddenly notice
00:32:00.000 --> 00:32:59.999 align:start position:0%
you know, that that it's one day late the next day we're only going to notice, that it's overcharged 30 days, that it's past past due, that. If they sort of ran out and doesn't have enough to survive another month 30 days later yeah, that's correct I think, that's going to be almost every entry in this system is going to be in, that circumstance right I think almost everyone who interacts with this system is going to pay at least one month worth of rent and. Therefore they're always going to have like essentially a one month of wiggle room in in being wrong right I think, that's kind of what I was trying to get at yeah yeah and I think from a design perspective that's nice to have some wiggle room. But also from a design perspective I don't think our primary goal is to get rid of these like you know long life entries, that will never be used. And so like. If we like are off by a month or two months like we don't really care it's like we're trying to really like limit Ledger State size and get rid of these entries, that last for years, that don't do anything exactly
00:33:00.000 --> 00:33:59.999 align:start position:0%
exactly the whole point here is just to have some upper bound and it is like having having an entire month of wiggle room is completely fine from the operator's perspective you just don't want to have you know fi like we have entries in there, that have been there in there for years and years and they're never going to be touched and those are the ones we kind of would like to like oh come on can we just can we at least put these on like a cold or storage and I also I think pyro, that's an interesting question as to can a malicious user exploit this this for free rent and the answer is no it's a little weird. But essentially essentially in order to get rid of programmatic exploits where essentially you pay like just enough rent to survive for the next level level. And then like always do, that like in a for Loop over and over again the way, that we service archives is whenever an entry goes to zero it is eligible for archive archive. But we archive in batches. And so essentially what we do is we use bucket
00:34:00.000 --> 00:34:59.999 align:start position:0%
hashes as a source of pseudor Randomness. And then randomly pick batches to Archive. And so to answer your question. While a user could get some free rent kind of like in like the. While they're in like the in the one level below. So say like. Because we have one level behind. If a user pays five levels of rent they'll live until level six. But once their rent hits zero the archive entries are deleted in a pseudo-random order. And so we're we're doing, that to prevent programmatic exploits where you have something like a smart contract, that can just in the for Loop can continually bump the minimum amount rent to live until you get to, that bottom level. And so there is still some room for malicious exploitation but. Because we service in a pseudo-random order I think we're kind of limiting bad taxes related question actually to, that you
00:35:00.000 --> 00:35:59.999 align:start position:0%
know the batching thing, that happens for actually charging rent I mean not charging around sorry for archiving archiving so. When it comes to those ephemeral entries isn't the experience going to be similar where the you know so, that would be in conflict with having a a you know like an exact expiration for a an entry to get it deleted. Because I'm going to actually do, that like you you'll have to basically what we can do. When you. But we can enforce. When you you know create an ephemeral entry you can say okay you know this thing is going to leave leave exactly I mean all yeah some number of Legends right and then, that number has to kind of line up with probably you know the right merge number right in the in in in the bucket list I
00:36:00.000 --> 00:36:59.999 align:start position:0%
mean, that's maybe and, that's a minimum as far as, that is it the maximum I don't think we can actually do a maximum. Because if we do a maximum, that means, that we are. Now creating those big waves of deletes, that will all happen at exactly the same time right and, that becomes kind of a probably like a scalability problem. Because because kind of like the deletes right, that are happening for the or the archive events right it's kind of a similar thing where you don't want to do all the archiving all at once. Because Downstream systems I mean you have to tell them like, that that the thing got deleted and you can't just do like a you know millions of entries getting deleted all at once I actually disagree and I think for two reasons. So I think first off we don't want to have I don't think we should limit users to The Bucket List
00:37:00.000 --> 00:37:59.999 align:start position:0%
time bounds just. Because there's like they I feel like to the outside users it feels some arbitrary like why do you have to pick between 4 000 ledgers of rent and 16 000 rathers of rent, that's a big difference. If I can't go somewhere in between. So at least how I'm imagining temporary entries is, that they have an internal field, that's like a death Ledger. And then after, that death Ledger even, though the entry might still exist in the bucket list they are not accessible. And so even. If you find the entry to look up. But the current Ledger is past the death Ledger. And then it's as. If that ledger doesn't exist. Now as far as the deleting goes I don't actually think there's an issue with deleting very large amounts of temporary entries and batches mostly. Because I don't think you need to admit meta or temporary entry deletion. So for instance the reason why we have to do archiving in batches is. Because archive nodes or state expiration nodes or whatever we want to call them. Now need to ingest meta. So they can store, that information. But for temporary entries
00:38:00.000 --> 00:38:59.999 align:start position:0%
because they have like this TTL value inside of them I think they encapsulate all the information about their death. And so you don't need to admit any meta. So for instance a horizon node right it doesn't and I could be wrong about the Supreme. If I'm wrong. But Horizon node on creation time knows what the TTL of a temporary entry is. And so the Horizon node or any Downstream systems don't need a meta event omitted to say, that the entry has died. Because they know exactly. When it's going to die similarly whenever we delete a temporary entry after it's died you don't need to write a deletion event to the top level bucket what you can do is during the merge say oh. If the current Ledger is past death Ledger just drop the entry and not include it and the merge result bucket. And so I think. Because assuming we have like a death Ledger field inside the temporary entry we won't need to emit meta and we won't need to write any delete or delete events to the bucket list. So I believe we can do this with arbitrary size of
00:39:00.000 --> 00:39:59.999 align:start position:0%
temporary entries and we won't have issues with like a very large bash being deleted at the same time. If that makes sense sense what kind of I mean, that means, that the downstream systems have to maintain the you know and scan the entire Ledger for those expired things right like, that's kind of overhead overhead yes I guess, that's the question is, that we need to admit meta or not even. If the death Ledger is included in The Ledger entry entry why can't it be just like a logical thing like right like it's an entry. And then basically cost knows how to treat it properly right or whatever yes we can do, that it's more like. If you think of like servant or PC or you know Horizon Horizon they would have kind of manage with, that stuff like either they do it on access. So like delete they see the thing is deleted or you know like past the expiration date. So they kind of did it lazily or they do
00:40:00.000 --> 00:40:59.999 align:start position:0%
have to delete like do a background you know a thing of thoughts right to kind of discover the things, that that, that are actually expired I mean I don't know how much overhead, that would be to have like a debate on access. If it's out of date. And then also just like keep a auxiliary table, that's like a list of temporary like pointers to Temporary entries sorted by death Ledger. And then just have a background garbage collection thread, that runs every. Now and again just to you know go down, that list in order. And then delete the entries, that have died you know I don't know how much overhead, that would be. But I feel like you know at least, that was like I was like trying. But my thought was, that would be like edema kind of like logic bound operation and not require meta events I feel like, that should be reasonably lightweight from an advantage of standpoint yeah it depends. If we think, that people are going to use a lot those temporary entries and basically like you know like you you
00:41:00.000 --> 00:41:59.999 align:start position:0%
you create those things. And then they they expire. And then you know, that basically you can do, that. Because nobody is going to try to access them I think for Downstream system, that implication is, that you have I mean the more likely scenario is, that yeah you have to do some sort of garage collection. Because delete on on access is is not going to cover a lot of the cases where you know you actually would delete stuff yeah. So yeah this can be potentially quite a bit of of shown to I mean all stuff to do. But like maybe maybe I would like to hear what you know people on the platform side think about this or like OrbitLens I don't think it's around unfortune unfortune taking a step back for a second I do think think I'm very concerned about this
00:42:00.000 --> 00:42:59.999 align:start position:0%
this bifurcation of how rents rent is measured in the dues between the temporary storage and the recoverable storage storage rent is already a pretty novel concept and I think we're treading unfamiliar territory. So having on top of, that different mechanisms whereas temporary storage is measured in number of ledgers. And then the the recoverable ones are kind of like Dynamic I think, that's weird I understand why you want to do, that. But I think from a user interface perspective from the developer perspective it's going to be pretty pretty weird and you know not only, that. But I do think, that. When a user pays for rent they want to know you know conceptually they want to know exactly how many ledgers they're paying for and and this idea, that that you know things vary based on the size of the
00:43:00.000 --> 00:43:59.999 align:start position:0%
bucket list, which is an implementation detail from their perspective I'm very concerned about, that. So one possible solution to this is to essentially have the rate be variable. But whenever you bump an entries rent you lock in the rent fee for, that entry until the next bump. And so I was kind of imagining this as like a a subscription model where. If you pay monthly it might be 15 bucks a month but. If you pay yearly. Then it like amortizes to like 12 bucks a month. So you get a small discount. And so I think this might work both to provide better guarantees around the expiration date date for the the recreatable and the unique storage types and also still have kind of like a variable game three aspect to it. Because my concern is. If you have a fixed rate. Then you can have people, that like essentially like say I'm going to like lock in this entry for 10 years put up 10 years of rent and then. If it increases like. If the rent fee increases
00:44:00.000 --> 00:44:59.999 align:start position:0%
like five or six x in, that time you've got a ton of free rent. But I think there's. If you like reset the the fee every time you rebump it kind of makes sense from a fairness standpoint I feel. Because yes you might be getting a better deal on rent. But you're locking up more funds. And so I still feel like the discount might be warranted. If you're willing to lock up a Year's worth of rent all at once once to have like this fixed rate, which I think, that's one solution to provide a better user experience and this would be very easy to implement as well I just don't know. If that could be games or be detrimental to the health of the network having these like locked fees and having entries, that are essentially like charged different fee rates based on the last time of their bumped. If that makes sense. But what are the some thoughts on, that particular idea in, that particular fee proposal proposal yeah I think, that the more you create like this type of discount systems the
00:45:00.000 --> 00:45:59.999 align:start position:0%
more you create an incentive for people to be like meta aggregate you know like like some sort of middleman contract, that that you know buys a bunch of of space. When it's cheap. And then you know you can use it you know like you can basically resell it to other people or something like I guess. If it's. So for this would be the read-only. So maybe this yeah for stuff, that's read only maybe I mean this is maybe fine maybe this works like this wouldn't work. If you allow people to basically yeah like like and okay allocate you know with a bunch of zeros right like stuff. And then later later there's like a better deal. Because it's you know an update. But in the current model we don't actually distinguish a create from an update I think it might work actually I don't think there is a good way to sell with
00:46:00.000 --> 00:46:59.999 align:start position:0%
your speed just. Because it's owned by the contracts and yeah using other contracts storage and highly problematic and probably more expensive than for sun ran savings what I wanted to ask in this thing is how much do we actually expect rent cost to function. Because I I'm kind of thinking about the model, that we say hey there more entries are in the back at least the more expensive with the rent rent. But then you know his friend goes up we should evict entries from the bucket based and suddenly becomes smaller or yeah I'm not sure. If it is a good reason or not. Because like we have just evicted a bunch of entries right to make it
00:47:00.000 --> 00:47:59.999 align:start position:0%
smaller smaller. So so basically is it true concerns those questions here I like how much do we actually expect, that us to block trade at all and whatever we think it is higher level awake in a way, that you know some brand can play like you may happen this happy 10 period. When a bunch of entries were evicted and suddenly rent is cheaper for you. So it costs someone inhibited. So I think there's two things here well first it's like you know again back to napkin, that math I don't expect it to grow very fast. But also one other thing is, that there is. Because we are evicting in batches The Bucket List kind of shrinks at a fixed slow rate. And so like for instance. Because of the batching system there is no way
00:48:00.000 --> 00:48:59.999 align:start position:0%
for like say like a hundred thousand or like a million entries to be batched in one Ledger. And then all of a sudden the Buckle is price dramatically decreases and you saved a ton of money. If you would just like put your or create your entry or paid rent like one Ledger later, that's not possible. So I think generally speaking the way, that the fee structure is set up you have a slow growth and slow Decline and you shouldn't have ever have like any of these big jumps either like a big jump up or a big jump down it's more like over time you can see significant increase or decrease. But you know between individual Ledger or on a short time frame you should only see gradual declines and gradual increases you know of those Temporaries you know like. If we depending. If we allow Temporaries to go all the way to let's say level nine you would you could actually see a big drop in in natural space in larger size you know
00:49:00.000 --> 00:49:59.999 align:start position:0%
with basically the. When you adopt the the bucket, that has all those things actually deleted and yeah I'm just trying to think about it from the perspective of one create entries and you know I'm I'm thinking about like how big is, that downside of like doing the entry lifetime basically time based and not fan page so, that you know. Because we have discussed in the Summers right with your pain for a certain time period beforehand right. When you're pumping the rent and we would edit the central based on this claim period and not based on the variable Fury. So even you know the fluctuations and the price and the the soil grows I wonder how how big is the impact of this approach
00:50:00.000 --> 00:50:59.999 align:start position:0%
would be compared to the doing completely Dynamic Grant, which pronouncement in the end and upon average being the same as you have paid at the current rate before and for the whole period I think, that. If you go and I think this is probably a number, that makes sense right well. If we say okay let's yeah fix you know rent in in granity or like I don't know like six let's say six months yeah I don't know some number right right what happens with, that is the you end up with basically biasing Grant so, that the newer countries like rights basically to The Ledger become a lot more expensive than than existing things like you have like this you know things get
00:51:00.000 --> 00:51:59.999 align:start position:0%
grandfather a little bit right in the system system so, that's where like you know. If you pick, that number let's say you say like okay you know you can you get fixed run for like five years right as a way to kind of think about what happens right like you basically are locking people, that create entries. Now right. When the Ledger is small to have like a really good deal and let's say in four years The Ledger is much bigger and storage is much more expensive at, that point those entries, that prepaid like you know have a very big Advantage compared to entries, that that we try you know, that try to get added to the Ledger at, that time. If you make, that number like depending on how big, that number is you create
00:52:00.000 --> 00:52:59.999 align:start position:0%
potentially this big bias right yeah, that's, that's yeah exact location I understand we have I'm just wondering like. If you bounce or later size the rent costs have this has has some bound as well right and let's say the reaches Bound in a year theoretically, that means, that you know your five years of rent the growth should be only during this first year. And then I mean four years would be it about constant rate I mean look at me like basically kind of a bit concerned about the mask going into this Ledger bounding. Because at some point you are going to reach the touch over you know you would be leaking entries and then, that's it's more or less constant. And then you don't expect much changes. So yeah I mean it's kind of weird like I I'm not sure I understand the mechanisms, that would cause the like let's say they
00:53:00.000 --> 00:53:59.999 align:start position:0%
are very close to the bound what will be the rent increase mechanisms, that pushes the entries out of the ratio basically. Because you know like they are near the bound already do we have it or not understand yeah I'm not sure actually you're saying you're asking. If so basically you want to rent you need to be a function of the ledger size right yeah. But we also want the virtual size to be bounded it's some upper bound right yeah. So essentially like the the idea being, that the the cost of writing a new entry and the fee rate as you approach the upper bound is asymptotic towards Infinity is kind of the intention
00:54:00.000 --> 00:54:59.999 align:start position:0%
yes. But it's ensuring. But how does this work practice like what happens. When we are near zapper bound like can we not create any entries at all I mean, that's kind of it's not, that you cannot create entries it's just, that they become very expensive. So in practice you kind of stall metal isn't, that the same transfer an issue you have basically instead of like saying, that yeah interests were just created for cheaper here we say, that answers will just wait people were just able to get entries Into The Ledger. Then is prohibitively expensive to get new entries to The Ledger Ledger until the older entries are evicted yeah there's definitely an issue. If we have like like I guess we'll call it rent control
00:55:00.000 --> 00:55:59.999 align:start position:0%
I feel like there's definitely an issue. If you have like long life rank controlled items. Because essentially like kind of at the most extreme. If you had a lot of buy-in for like five or ten year entries. Then essentially your network would help. Because there could be no other additional entries created. And so you'd have to wait until these rent controlled entries default on their event, which would take 10 years at the most extreme. And so I think. If we go this rent control approach we'd have to make sure there's a very reasonable upper bound as to how much rent you could pay. And so like 10 years would definitely be too much I mean maybe one year. But I think we definitely have to Upper bound it it to kind of avoid this this network being flooded with cheap entries and not allowing any other entries to join. Because it's prohibitively expensive right. And then basically. If we need some kind of bond anyway like can we. Then consider, that time-based option. Because like it seems like even the current
00:56:00.000 --> 00:56:59.999 align:start position:0%
approach we have issues with very long-lived entries ready to be what the interest is super long leads to entries like we get people's basically needs to learn, that exponential increase in rate. And then we get all of them evicted. And then we get them all or create deployment rates, that were created for very cheap. So it seems like it is problematic no matter what I want to say we are at time. Now it's an interesting discussion. But I think we gotta pause it Garen do you have what you need to move forward do you know what the next steps are is there any crucial thing, that's blocking you, that we need to address are you good yeah I think from my end I'm I'm pretty good I have a timeline. And then this CAP proposal for rent and temporary interest I want to release. And then we can talk about more on the Google Docs I think this this time-bound versus variable rate is still an open question, that needs to be solved
00:57:00.000 --> 00:57:59.999 align:start position:0%
but I think you know there's still plenty to to you know get done outside of, that and is your intention. When you complete the next iteration or the next draft to to share it here so, that people can can review it again what's the story with, that yeah yeah. So this will be a public document kind of the ideas like we have the timeline. And then we'll be linking CAPs off the timeline. And so this is just the the initial CAP of, that timeline. And so both the timeline and the the draft CAPs will be publicly available awesome cool thank you so much well good discussion super interesting thanks everybody everybody we will likely have one of these next week and stay tuned keep keep your eyes peeled for the the drafts, that Garand will share obviously async feedback is also super helpful just to keep these discussions moving forward see you all soon