the changes that we're discussing today
and what we're focused on now is relate
to project jump cannon so it's a future
protocol upgrade these changes would
be included in it and project canon
is aims to bring smart contracts to
Stellar we've actually modularized a lot
of these changes and so there's a whole
slew of caps that are related to jump
cannon caps 46 through 53.
since this is a pretty technical
discussion if you want to follow along i
urge you to take a look at those caps if
you're interested in joining the
discussion I urge you to join the
Stellar dev mailing list and if you want
to also follow along with jump cannon
development more generally
you can do so here
in the jump cannon
channel and also in the jump canon dev
channel and so today again we're
focused on on jump cannon related caps
there's a pretty there's there's a
lot on the agenda a lot of small stuff
but there may also be some bigger issues
that we're talking about if as you're
listening if you have questions
the best thing to do is to put them in
live chat in text i'll do my best to
monitor it I mean the goal here is to
actually have substantive discussion
that moves forward some of these changes
and that answers questions and allows
continued development so we may or
may not have time to address the the
issues in live chat but if we don't do
it now during this meeting we'll
definitely take a look at that channel
afterwards too so feel free to put your
questions or thoughts there and that's
the end of the intro
everybody here it looks like
looks like we got a full house
okay cool
so I guess to start off with we we have
an agenda that has
like
and I guess we can just like sort of
start with what's at the top of the
agenda
I also know that there's some questions
about interoperability that we may
want to address
I think maybe we start with
46
removal of box agenda item I put a
bunch of I put a bunch of agenda items
on here you can hear me
everyone hear me yeah we can hear you at
least I can hear you yes okay
yeah I put a bunch of agenda items on
here but they're all really
straightforward so I can just
grease them really quickly
boxes in cat46 it's a it's an object
that contains a value I think this is
actually just an artifact of the notion
that we might have had mutable objects
because I think as far as I can tell
it's it's basically indistinguishable as
long as we have immutable objects and we
haven't ratified pointers there's
no way to differentiate an object that
contains a value from just the value
so lee suggested that we get rid of this
and I'm happy to get rid of it until we
discover or some reason to bring it back
in the future
go on once
go on twice I guess I have a maybe a
question yep
so is that does does that mean if if
later we decide to have mutable host
objects
they would just have to be boxed like
that that's right that's right that's it
we'll just bring back so it's actually
completely back I mean forward
compatible but yeah we're just bringing
we're just bringing the object like back
in the future it's just that since we
don't have any reason for it right now
then we might not delete it
yeah makes sense
okay
so
yeah I just
as a part of deleting this I want to get
rid of the cycle this gets rid of our
only cycle click reference in the
structure when I get I want to get rid
of the option on the box so we
definitely can bring this back later on
but if we do bring this later on
we should put a little bit of effort
into making sure that the xdrpp the c
plus xdlib
can do non-option cycling references
which there is already a plan for but
yeah just calling that out
yeah it's implemented in c plus plus 20
so either
we can move Stellar coordinates equals
plus 20 or we can back port it to c plus
17.
yeah that's a so somewhat bigger kettle
of fish but I mean we have a
workaround anyway if we really really
need it we really need to bring it back
we can move to an optional box like this
but this there this is motivated by
getting rid of
so that'll actually make a lot of the on
the wire stuff four bytes smaller
okay second issue which is very very
minor we went with positive i-64 as
the we renamed u-63 like two weeks ago
into positive i-64 to be a little bit
clearer because 63 is a weird number and
everyone who sees it is like what is
what is that why should there be a
63-bit number and it's actually just
like a 64-bit number that happens to be
positive and john pointed out that you
know zero is in there and depending on
which mathematical tradition you come
from zero is either both positive and
negative or neither positive and
negative and some people believe
non-negative is the correct word to use
when you're including zero and a set of
numbers that include zero and all the
positive numbers
I don't personally care I'm perfectly
happy to have the word pause in there i
think it's reasonably easy for people to
understand I could also put in non-neg
or n n or something like that but i
figure terminology wise i've got you all
here
we're gonna we're basically gonna merge
this right now so please commit to a
terminology does anyone have a
preference
I think non-nag is confined if that's
more accurate but I don't really care i
personally I think u63 was fine but yeah
not like is fine too I did too I don't
care
I like u63 personally it's short and it
says what it means

literally everyone who sees it has like
this weird sour note in their mind and
is like why is that 63 what is wrong
with you 63 is not a computer number 64
is a computer but that is that is
actually the correct and that is
actually the correct reaction because it
is a weird type
so like except except it projects it
projects to and from i-64 so so the the
the type that you can convert to and
from is i-64 actually
why i-64 is not u64
that's the symptom of the language we're
using too like you know if we were
writing contracts in zig u63 would
actually make sense it'd actually be a
thing
I mean the thing is like I don't think
the weird reaction is to the name i
think the weird reaction is to the
concept but then in context it makes
sense so why not just pick the more
accurate name but
this seems like a mega bike shed thing
it is a megabyte shed
i'll go back to u63 if everyone wants
you 63 but I will not entertain another
comment on this after this meeting so
this is it yes thank you I mean it's
like boolean right like boolean is not
one bit in most like if you have a
variable like that right it's already
the same thing so I'm fine with I'm
actually I prefer u63 as well because it
actually tells you what it is
everyone wants you 63 okay we're going
back to u63
next issue was cap 47 and cat 53 we
noticed part way through last week that

assuming that we want some kind of
mutability of contracts which apparently
we kind of do or even if we don't want
mutability of contract we still want a
way to load contract from the middle
of execution
because we want to be able to call them
and so at a representation level
the xdr that represents ledger entries
with separate ledger entries for code
and data
seemed possibly to be overkill and so we
talked about it and came to the
conclusion that it would probably be
tidier we actually had like like in the
implementation we had pages and pages
of sql code for both of these types and
they're pretty much identical cedric
and I worked through this stuff and then
they really only differ on a you know
one field which is whether there's an
additional sub key
so we thought that it might be nice to
just merge those two and there's a
single type of contract related entry
that still has a contract id they all
have a contract id
and has a sub key and the sub key has
one magic value carved out we have lots
of places to carve magic values and we
can just carve them out of the sc static
value set and we just have a designated
key and all it means is the current
contracts or the the owning contracts
own wasm code and then we just do our
binary and sc binary type
and so we implemented that it seems to
work fine I have not updated the cap
yet I want to run that by everyone make
sure everyone's okay with it it it leans
us a little bit towards mutable
contracts but I believe a lot of our
design discussion has been drifting in
that direction anyway it does not wet us
to that we do not have to we could also
special case it and just prohibit rights
to that key
but it sort of
has that tendency of treating code and
data as the same thing
which at some level they are
so I spoke to siddharth about this
yesterday quite a bit in the afternoon
but one of the one of my main concerns
around
mutable code and this is much more about
the mutable code aspect of it than about
the merging them the merging it I care
less
about other than the fact that it like
makes them like default mutable and we
now need to opt back out of that which
I'm about to explain
like
you can't just say the code is mutable
without having some rules around what
that means
and we have not successfully agreed on
what those rules are
what happens if you mutate a code
mutated contract that's currently
running what happens if you delete a
contract that's currently running
what happens if you
delete a contract that is running then
call another contract that called back
into the first contract which contract
runs the second time
like
these things need to be well defined
so we should like start from the fact
that we can
store code as data but you can't mutate
it and then figure out how to mutate it
but like we don't have answers to
those questions yet or at least i
haven't heard answers to those kinds of
questions yet
no I agree we don't we we did however
have in cat 47 a function for writing

a contract code entry so whatever that
host function semantics are they're the
same semantics here
well the the thing is that yeah it's
like what john is saying like currently
right like when you write a letter entry
the this is observable by anything after
like immediately after whereas here i
think we we have to decide and we
probably cannot make this actually
this cannot be true I think
because this is going to be
probably scoped with the tied up to
the lifetime of the

of the wasm runtime that's actually
executing the code so if you have like
if you call yourself type of thing
we're certainly not going to we're not
going to hot patch the the running one
exactly yeah so this is
but this is like a place where this is
actually deviating from what we do for
data
so we have to really
you know specify this and think about it
very hard that's exactly what I was
saying nico you just said yeah
no I know like it's it's kind of scary
in a way that
I don't know what the right answer is on
i
know you see I don't I don't actually
think this is this is particularly scary
I think there are really only two
possible options and they're both fine
and you know one of them is you do
what unix does which is that you
the executing process is essentially
a disjoint as soon as it starts
executing and so if you rewrite the file
that's fine the next exec to that to
that we'll get the new code
but like
so did we did we actually decide on
reentrancy for example like what you can
or cannot do
well actually you get you busy in unix
no you can write a file while it's
running you get you get busy on
windows
the file's locked on windows while it's
executing on unix you can rewrite the
file
as far as I know
because I do upgrades of running
programs all the time and it works
like if I if I upgrade chrome while it's
running if I if I do apt-get install
bash it works in my backup I'm telling
you I literally just tested this and
I get e busy I mean this is kind of a
side note but I think what you're doing
when you upgrade is you're unlinking the
file and creating a new file but you
can't you can't like write to an inode
that's currently executing okay sure
unlike you can re-link that's
fine well unlike and create a different
I know my point is it's it's totally
doable in some contexts and in other
contexts you block it and those are the
only two options here so
and I think they're both fine there are
other options okay there's the only two
reasonable options the other one is what
hot patch your existing running program
which you're not going to do no there's
at least one other option which is like
you can't update something while it's
running you have to delegate that's
blocked that's what I just said that's
the other option block or allow
what what exactly do you mean by block i
guess it fails you try to make the right
and the right fails it's just the
special case we just don't know that's
what right right right to the running
the right to the running code fail
because we decided
but then how do you actually do the
update I guess like you're just saying
you can't mutate it you can't take your
own you can you can mutate someone
else's
okay but like that needs a lot of
specification in and of itself
and I was providing an example of how
you can do that you can't just like i
can't just modify your contract right
like there's obvious that's obviously
not acceptable

so
but we have a we have a we have like
manage contract transactions right that
that's that's the out-of-band technique
but like that doesn't work
like it works in a very like very tight
sense but like what if you're a dow
that's managing a smart contract you'd
like to be able to manage it from small
right okay then we
there's like a whole bunch of space here
that I'm like
it's like sure maybe you have two
high-level options allow or block but
like block has many sub-options
okay I don't I don't see this is
I don't see this is relating to the
question which is do we store this as a
ledger entry or not I agree that
individual host functions need to have
semantics defined for them but okay i
guess what I'm getting at is
I would accept this change if we make it
so that you can't mutate the code while
it's running right now
and we can figure it out later okay
but if you're going to allow it right
now then we need to do a lot more work
and it's not a good idea
sorry if we're if we
allow rights to the currently running
contract right we need to do more work
okay so
what I'm going to specify that agent
files are currently immutable
even if it's stored as data no the
currently running contract is immutable
but we as I just said we have no
mechanism to write to a not running
contract or not a good mechanism we
should just make it immutable if it's
okay sure
like what I'm saying is let's separate
the mutability problem from the
representation problem okay
then we can make progress because like i
I don't want to approve this if we don't
have like I don't want to prove it in
the mutable case if we don't have a good
story about me to build and we don't
right now gotcha okay so only only
reading only the read path works for
this key right now and the right path
just fails
I have a question about not about the
mutability but the representation if
we're making it a ledger key that you
have to write
and in the future we do decide to
support mutability
will it mean that the only way to update
the contract is to
write the entire binary every time
or
so like I'm just wondering about if
somebody if we support mutability and
somebody wants to write a contract where
they
swap back and forth between multiple
implementations like rolling back or
something like that
and
just the cost of
writing an entire contract which might
be a couple of kilobytes
versus
store if this is just data storing this
data
under you know just like regular data
and then having a point into that data
does that make any sense
yeah it gets into what we talked about a
little bit in yet another one of the
threads this week which is like is there
any kind of delegation mechanism

I I think it's a little bit awkward
because

well first of all we actually come up
with a delegation mechanism that we can
all agree on which is
going to be
weeks of conversation but also you
you wind up needing to pre-flight every
single transaction in that case because
you need to resolve the
current delegate well
maybe you don't need to pre-flight them
if you can guess where the delegate is
currently pointing but anyway
i
I feel like
it sounds like it increases the
complexity of this and that's like I'm
not interested in increasing the
complexity I'm just curious if we're
just
any sort of future
limiting something we can do in the
future
I don't think so because again I think i
think

47 already has a function called write
contract and it takes a binary like
that's that's the point here is to just
absorb the two representation questions
not not necessarily to solve
do we have
proxy or delegation or whatever which
we might have but you know
when we had that conversation this week

john was really
adamant about like let's let's ship
without and see what happens and
you know
I can I can live with that because we
it's true like we could we could make
the wrong
delegation mechanism and then we'd be
stuck supporting it forever so
make sense
zoomed in focused on the representation
question nobody has any real objections
okay I think it's really not contentious
okay so the final thing I had on the
agenda which is the footprint type
which is like even less contentious
i'll just be extending cat53 with a new
data type which is called footprint and
it just contains two lists of ledger
keys the only really possibly
contentious aspect of this I think is
whether ledger keys full keys should be
there or whether they should be
restricted to only contract data
values or
or value contract id pairs or something
like that something that is a little bit
tighter than a ledger key but if we do
that it means that we are essentially
fixing
the impossibility of interacting with
other ledger entries into the protocol
going forward and I think the
interoperability question
still leaves that open so I was assuming
that they would be a full electric key
at least that in conversation with john
he again
fairly clearly suggested that he would
prefer to keep that door open and I'm
happy to go with that so
does anyone feel strongly
what do you mean by footprint here you
just mean the like
sorry like the footprint is a term that
was introduced in cap
oh the other one the data yeah it's what
we have been calling up up until
recently the read write set i
found that actually the paper that
introduces this concept of deterministic
execution uses the word footprint and i
think footprint is actually a great word
to use here so i've decided to start
using this one
because otherwise you wind up with the
read-only part of the read-write set and
the read-write part of the read-write
set and honestly linguistically it's a
little bit clumsy
nobody cares about the footprint okay
cool i'll just make it a lighter
keystone
that is the end of my agenda items i
yield the floor to discussion of
interoperability or whatever else you
want to talk about
thank you
john is this a discussion that that you
want to kick off
have questions

are we switching now on onto like acid
and drop stuff is that that where we are
yeah yeah yeah so I think that all we've
sort of gone through all of the existing
stuff on the agenda and the only thing
that was a big question mark was the
asset interoperability stuff and I think
that that's where we are at this point
yeah I mean I think the only real thing
to talk about here which like
we have not
been able to come to agreement on is
just like what are even the requirements
what are we trying to achieve
me nico tomer lee talk about this prop
like this problem I don't know like
three times a week right now
and I don't even think we're all talking
about the same thing so I think we just
need to talk about
our feelings
so anybody can take before from that
yeah I love talking about my feelings so
i'll start
yeah so I think you know the basic
requirement
from asset interop in my opinion is so
let's
maybe it's worth thinking about like the
full spectrum of of interop or about the
edges and where we are in the middle
so
you know I think like on one
extreme interop
thing we just do nothing right and
this is you can look for example at
like aurora on on near which is you know
a whole blockchain running inside of the
blockchain that has like no interrupt
whatsoever and if you want to interrupt
with the parent chain you need to go
through
you know various bridging solutions
so I think that's a very extreme
version which is no interop at all
and it basically means that we're not
taking advantage of the existing Stellar
ecosystem at all but it's extremely
simple we just don't need to think about
legacy interop at all
I think on the other extreme side of
interop you have full interop with every
primitive
on the current Stellar network so you
can do things like interrupt between
smart contracts and amms and the order
book and
sponsorships and and like the wide
everything that Stellar
proposes and that
you know is great for like supporting
legacy but it's also terrible because it
means that we're bringing a lot of the
you know technical debt and the
idiosyncrasies and in the classic
protocol to the new world so
I think we need to find somewhere in
between
and I would say that even though
there are a lot of disagreements in this
in this room I think the basic thing
that we agree on is that
assets are the main point of
interoperability like we're not trying
to bring the order books we're not
trying to bring amms
we just want to make sure that classic
assets will operate in in smartland
and


you know basically like asset issuers
still have their
infrastructure intact and and they
don't need to make changes
and so we have
you know service providers like you know
fire blocks and bitcoin all these folks
you know their services are still
you know viable in working even
in this world without
without a change
does that make sense to people
oh maybe i'll i'll pick it up
because yeah like with the without a
change it's kind of like that's
the part that's right that is kind of
reloaded I would say
like the
like
as soon as you as we say
there's basically like
there are two parts to it right there is
the
do I expect
on day one
as soon as we have like
smart cr smart contract capabilities
can I use
any classic asset on the network kind of
automatically right
or not
like using smart and that
to me
is like one version of that extreme
inside this box that you described where
you know no change is needed
and
I'm I'm I'm we've been kind of trying to
and john probably can expand on that but
like it it seems to me that
if we try to make it
that extreme

we we are kind of
really over constraining
what type of things you can do in smart
in terms of
those assets right because
you expect those assets to be
represented by trust lines and and
you have like all those things right
that comes with that and you have like
the semantics that are really
specific right to classic
so that there is like that version i
think there is a
maybe a more
nuanced you know version of this that is
yeah like what

like what what do you mean when you say
like no change does it mean

that
yeah you want to have people that issue
tokens on stella
they want to make sure that
they contin we don't break their
compliance story or whatever they they
have right in terms of like what they
are
what they sign up for basically with the
network right like we're expanding the
the set of
capabilities
and
and this one is it sounds more to me
like
like there's like some room there where
you can say well maybe

maybe people need to like issue us in
this context of classic assets need to
have like a
kind of
opt into smart capabilities and maybe
they have like a way to specify which
subset of the capabilities they are
interested in and
when you do that
then you have like maybe a
a different
way to represent those assets kind of
like when we introduce claimable
balances like claimable balances are
actually a a good example of
where we
kind of introduced this this way to kind
of go in a way like that was
actually breaking a little bit in terms
of compliance but at the same time
we try to be
for tokens that don't have a lot of
restrictions
claimable balances are kind of can
flow freely right
and to me like
trying to do a similar thing with smart
is probably like a
would be probably a good middle ground
but for that it's an opt-in so that
means you don't get automatically like
everybody you know every classic asset
kind of shows up on day one
yeah so I think cable balances are a
really good
example
you know they're a fairly novel
concept and for the most part aside from
you know a small set of like super
specific Stellar wallets it we we
haven't even seen support for them
and with major service providers
so it's worth you know when I'm when
I'm talking about minimal change I think
it's worth
dividing this into the different
stakeholders that we're talking about
so
I think on one end you have
the more kind of like institutional
cross-chain services things like
exchanges things like you know things
like fire blocks and bitco things like

you know even like circle as an issuer
like these folks
you know take the path of least
resistance it's been even difficult to
get muxed accounts implemented with
these folks so I would say that from
their perspective
we
like zero change is preferable
now
for the actual touch points for these
smart contracts obviously it's okay
to introduce change right like if a
wallet wants to interact with with
some crypto primitive some smart
contract and then obviously they need to
introduce changes and it's okay you know
so you know on the wallet side itself
and from a user perspective that's
trying to use the smart side it's
definitely okay to introduce some
some changes and can I have actually
have a question on exchanges like when
you say like exchanges don't need to
make sure well like exchanges today
don't most many exchanges don't support
any
Stellar assets other than lumen
so like why is that relevant in that
conversation it's relevant because of
usdc it's relevant because there is a
group of exchanges that support usdc and
don't right
it's growing you know and it's growing
but like over time do you I mean
wouldn't you expect
people like if they are like any good
assets being issued on the
smart side that they would be supported
by those exchanges
so it's not like they are going to like
a phone exchange it's a bit of a
different story right they have existing
things
they're not issuing tokens right they
are it's more like they have a wallet in
classic and you want their water to
continue to work
right and I mean I think at some point
if they decide that smart assets are
interesting and they want to opt in to
make the changes great but they they're
probably not going to be the first
people to do it's probably going to take
them a while and it sounds like we just
don't want to break them
yeah that's fine but like I don't think
we we ne
none of the proposals so far are saying
we would break classic wallets
no but we are saying for example you
know if we're going to recommend issuing
on smart going forward then the issuer
has like this tough decision
where they need to make a decision
whether the issue
on the old path which maybe is not
recommended anymore but is what the
exchanges actually know how to support
or issuing on the classic side
and you know based on our previous
experience it's going to take
you know a whole lot of time for service
providers to start enabling something
new
I get that I'm just kind of a bit
skeptical about
like the
for exchanges in particular that
they won't do like basically I think
there are two types of exchanges the
exchanges that are going to be
supporting whatever the latest set of
functions I mean they are going to kind
of keep up maybe like you know with some
delay but they are kind of keeping up
and then you have others that are very
conservative and going to be slow
and I think that's why for example i
think we don't have still
usdc on coinbase I think right Stellar
usdc
coinbase
according to foreign sources doesn't
have any multi-chain assets right now
because of extensive technical and
product debt that coinbase is a bit
of a special case
because they don't even support they
don't support any like usd any non erc20
usdc but we do have
and like it's a
it's a pickle it's difficult because
exchanges you know there's a bit of a
chicken and egg that you know they want
to see demand
and then it's hard to create that
demand without you know these assets
supporting supported domain exchanges

but I think like the main thing I'm
trying to together here is that like
it's hard to get exchanges to to do
changes and the service providers as
well like folks like bitcoin fire blocks
right and right now
is you know the way that you issue
assets on Stellar
you know the actual distribution is
just regular payments right
so
you know you can do it on all these
platforms
if you introduce a new way to do it then
you basically tell issuers you can't use
these service providers
I mean that's not really what you're
telling them what you're telling them is
you can't use those service providers if
you want to do it the new way
right
right so what you're suggesting is
having like this
like a split thing in the ecosystem
where you say hey you can issue an asset
in one of both ways

this way will give you like you know
like a shorter path to exchanges and you
can work with
you know various service providers
and the
other path will give you
will give you what john
I don't know what it'll give you it'll
give you the power to do whatever you
want the question is what do you want
right
if they don't want those things you
probably shouldn't do it right
yeah like
like if you think of what we have
right now for the network right we are
kind of optimizing for payments
if the token that you're issuing is not
meant to be used for
directly supporting payments
then there's no reason to issue it
as a classic asset
like think of like you know nfts or all
sorts of random things like that
yeah
so as I said like if you if you if you
issue on classic then you have the
entire breadth of like classic tooling
available at your disposal right now
like every wallet every exchange
everything that supports on classic
you have at your disposal it's so yes
it's about payments but it's just about
like the ecosystem support
I think
like payments are also just transfers so
I'm it's also not clear to me why why we
would even say that nfts don't care
about payments because people do care
about transferring nfts
yeah but we're not going to have
that is actually kind of broken if
you're modeling
like that's kind of what we see today on
the network right like the way your
model nft is on the network is extremely
poor the experience that you get
I guess one question is like
do do we think that kind of the the
value of the smart contracts is going to
come from people implementing new assets
or do we think the value value's going
to come from like taking high quality
assets that are issued by people who are
you know
not
you know that are that are not
particularly
you know experimental
and then innovators are going to come
and like make new use of those assets so
my
suspicion is that maybe this the latter
is is is better and so that that kind of
it's more important to interoperate well
with existing assets that might be
issued
by somebody else and to be able to like
program those assets than to be able to
create some new ecosystem that's not
that's more divorced from the existing
one
so I think there are
it's probably both david because
you're gonna have yes you're gonna have
you know the the stable coins usdc and
such that are going to be used heavily
in these smart contracts but you also
are going to have things like governance
tokens uni style
tokens and dao style tokens
and these are going to be issued on
the smart side
you know we might say hey you know what
we don't actually care about
about these assets being
transferable as regular payment on
the classic side and maybe that helps
with
with implementation but we will
see these assets but but I mean I guess
I mean put another way like when I talk
to people who are using Stellar right
it's it's it's often kind of two things
that draw them Stellar like sort of the
the perception of like high quality
assets and low transaction fees
and so if like those are the strengths
then we want to kind of
make sure that those strengths are
we don't want to kind of like sacrifice
those strengths and create a completely
new ecosystem right we want to be able
to kind of
maybe for higher transaction fees add
more flexibility but where like you can
still do things with like low
transaction fees and do things with like
existing legacy assets right like that
that seems to me like the
the
the thing that we want to optimize for
of course it's going to be like whatever
turn complete in general but but the
thing we want to optimize for that's
going to make this special is the
ability to
also leverage these high quality assets
and low transaction fees for people who
are just doing simple payments and
that's not going to work for everything
but

but there are probably a lot of cases
where like you know
people are going to want to use usdc for
example right and and maybe we don't
want to get circled to like write some
whole new smart contract to implement
this we just want somehow
like unilaterally people can write
contracts that do things with usdc
yeah I think we're getting into a lot of
speculation and somewhat like religious
discussions here
john can you help us like fine tune
like where where do things get hairy
in terms of interop and what kind of
like
you know decisions we can make to
simplify that
I mean there's a couple
axes of decisions
one axis is like wrapping verse not
wrapping
wrapping generally makes everything
easier implementation-wise like
significantly so
but like the ux might or might not be
better
that's up to your interpretation
if you don't have a wrapping
interface so that's one axis
a second axis of is like
should a
classic asset
when used from the smart perspective
look exactly like a smart asset used
from the smart perspective should they
look identical
should they behave identically
and the third main access is like should
you be able to take a smart asset and
easily send it back to the
classic side

that access is more speculative I think
but those are kind of like the three
angles that one might look at this
problem
one thing that is noticeable in other
ecosystems is that there's definitely
the canonical way of doing assets right
on on the ethereum ecosystem even though
you can write your own contract everyone
just
you know copy paste the the or imports
the
the OpenZeppelin one
you know solana has like the spl
other ecosystems have like their
baked in contracts for for assets
like people don't
actually innovate all that much with
assets
and like I guess my question to you
is like can we make those like canonical
assets on Stellar be the existing
assets
maybe
I mean I think you'd be making a lot of
sacrifices to do so
are they sacrifices worth making making
not to me
what are the sacrifices
I mean I think the biggest sacrifice is
just like do we really want to have
a 64-bit balance for everything

the next sacrifice is like
do you want it to literally be exactly
what exists today
or do you want to build on top of that
more because like you would need like to
do the stuff that's common
in
you know d5 you would need an allowances
system on top of that anyway so it's not
what we have right now

we have all this compliance stuff baked
in it's pretty unwieldy for a variety of
reasons
do we want to be married to that for the
rest of eternity I don't so
I guess what I'm getting at is
you can shoehorn anything into anything
send you
I have a really strong opinion about the
should you question but I do have
I participated briefly the last time
around and I just want to do ads since
you're already doing requirements
gathering here a somewhat
narrow version of of what feel like
the requirements I would want to add to
this question I don't actually have very
strong opinions about the assets I do
have fairly strong opinions about two
minor points and I think they I think
there's a wide variety of ways to
achieve these but if we're writing
things down if possible I would like
to request that users not be in charge
of non-management unless they really
really want to I think
if we're in a situation where the user
has to figure out how to operate a
cryptography api safely and correctly
themselves we're putting them in a very
dangerous position and
whether we accomplish that by by
completely baking in a standardized path
or just having a very easy to delegate
standardized path or
even just
there's a host function that has very
simple signature that's fairly
impossible to misuse I'm kind of okay
with most of those approaches but
cryptography apis become error-prone
really really quickly and I don't want
to surface a lot of that to users unless
they ask for it unless they're going out
of their way to say I personally want to
do some some fancy cryptography for the
average person who's just creating an
asset I really want them to not be
forced to copy paste and possibly get
wrong the use of a cryptography api

that's requirement slash desire number
one and requirement desire number two is

ideally if that code is gonna be in
every single contract and it's the only
thing that differs from one contract to
another
or or if it's if it's a if it's
standardized preamble in every single
contract on every single path it
would be nice just from a code size and
execution performance perspective to
factor it out as well so I'm just
I know the authorization point is not
the only part of interrupt but to me
it's the only part that I actually care
about I do not care about the other
aspects
right so I think that what you just
described I think is that's kind of what
is touched on in all this

yeah in cap 52
the authorization model though for for

for payments
is
and going back to that right is it is is
different it's different and that's why
they are like things done in a certain
way in cap 52 but I do agree that
I know as we try to figure out like the
actual
interrupt story with classic it would be
we can
avoid having I mean having like a
yeah like good
solid
base implementation that people can just
you know import in their in their
thing and then just works
mostly without
having to implement those things
and but like the the
key part of that the absolute most
important part of that from my
perspective is the authorization aspect
of it
you want to if you want to allow or
require people to fiddle other parts it
doesn't matter quite so much but
and user writing your own authorization
group is just a disaster
we have too many crickets
can somebody make it
I don't like well I do have a
question so returning to to what
tomorrow
sort of started this threat this
head where he started it which was
just other networks have
a canonical way like economical
representation of assets that people
just use
his question was can you know the the
current or classic asset just be that
canonical representation
on says
you know
he's not a fan of that approach
the question is
is it worth trying to think about
other models that we could use for the
canonical representation of an asset
that we could discuss or is it premature
to just to get into that right now

I mean in a way you know you know like
in cap 49 for example the the wrapped
asset is a canonical
implementation
you know of the classic asset
but it's actually something that is
modeled as
a smart asset so
so it's not like people would have to
reinvent a bunch of things there you can
actually standardize on exactly that
thing and that's actually what is
interesting about this this approach is
that you the way you do it is you
actually
write a standard
you know like erc20 type of equivalent
you design it
as a as thinking about the semantics
as smart semantics first
and then you you make it yeah
interrupt with
with classic assets and there's only one
way to do it but yeah you do have
standardization happening in that world
I'm not so so getting back to that like
I feel like I'm the only one talking
like it seems to me that the
standardization is not necessarily the
sticky point
because
in all those proposals so far there
is actually a standard
that includes classic assets
so what else is
is
missing
right
got it
well are there other questions that
people want to bring up now in the last
nine minutes that would help sort of
move the conversation forward or should
we just call it I mean we got through a
lot today
i'll let people think for a minute
okay I think that's a wrap then
so thanks again everybody for joining
the discussion anyone who's watching
obviously we're going to post this you
know to archive it on youtube later so
if you want to re re-watch this which i
mean who doesn't right I watch these
things six or seven times you can
watch them there on youtube and
also if you want to participate in the
discussion or you want to follow along
please make sure to read the caps please
join the jump cannon channels here in
the Stellar discord and also sign up for
the Stellar dev mailing list where a lot
of these discussions will continue
asynchronously
and we will see you back here next week
for another open protocol meeting thanks
everybody
