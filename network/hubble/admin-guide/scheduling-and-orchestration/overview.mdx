---
title: "Overview"
sidebar_position: 0
---

Hubble uses [stellar-etl-airflow](https://github.com/stellar/stellar-etl-airflow) to schedule and orchestrate all its workflows. This includes the scheduling and running of stellar-etl and stellar-dbt.

It is worth noting that most users will not need to standup and run their own Hubble. The Stellar Development Foundation provides public access to the data through the public datasets and tables in GCP BigQuery. Instructions on how to access this data can be found in the [Connecting](https://developers.stellar.org/network/hubble/connecting) section.

## Why Run stellar-etl-ariflow?

Running stellar-etl-airflow within your own infrastructure provides a number of benefits. You can:

- Have full operational control without dependency on the Stellar Development Foundation for network data
- Run modified ETL/ELT pipelines that fit your individual business needs