---
title: "Soroban Library Releases Plus Fixed-Point Math, Fee Abstraction, and Timelock Proposals"
description: "The OpenZeppelin team recaps their Q4 Soroban library releases and how they improve financial math, transaction UX, and on-chain governance. The session also covers current protocol governance discussions, including proposals for emergency protections and network resource changes."
authors: [carsten-jacobsen, dmytro-kozhevin]
tags:
  - developer
  - spotlight
  - CAP-77
  - CAP-78
  - CAP-79
---

import YouTube from "@site/src/components/YouTube";

## OpenZeppelin Q4 Releases: WAD Math, Fee Abstraction, and Timelock Governance {#part-1}

<YouTube ID="pq4xrdRzfIs" />

OpenZeppelin reviews three major Soroban releases—Smart Accounts, Vault, and RWA—showing how programmable authorization, standardized yield vaults, and compliant real-world asset tokens extend Stellar with better UX, composability, and regulatory tooling.

### Key Topics

- New `WAD` fixed-point decimal type (18 decimals) for deterministic, high-precision arithmetic in Soroban smart contracts
- Ergonomic Rust API: operator overloading, safe conversions (token amounts/prices), and checked math variants for overflow/div-by-zero
- Fee Abstraction module: lets users pay transaction fees in non-XLM tokens via a relay + fee-forwarder contract flow (useful for classic accounts; “missing piece” for smart accounts)
- Two fee-forwarder flavors: permissionless (trustless) and permissioned (owner-controlled allowed tokens/relayers)
- Governance package kickoff with a timelock contract to enforce execution delays for safer upgrades and exits

### Resources

- [OpenZeppelin Soroban Contracts](https://github.com/OpenZeppelin/openzeppelin-contracts-soroban)

<details>
  <summary>Video Transcript</summary>

[00:00] Hello and welcome to this week's Stella. developer meeting Today. We have we developer meeting Today. we have the open Rubin team here or at least a part of it, to go through some least a part of it to go through some least a part of it. To go through some of the releases, the library releases from Q4. 2025 was a really exciting year for, for 2025 was a really exciting year for the-the open see and stellar, collaboration. A lot of new great tooling a lot of great libraries and we even had the opportunity to. participate in in in some events with with you two guys, Meridian. And Istanbul Blockchain Week. It was Istanbul Blockchain Week. Furthermore, it was great to see you and have your support. at our events. So, yeah, lets at our events. So, yeah, let's, let's get into it. Maybe, Brian, you can start telling us a bit about what, was released in Q4 and have a look back was released in Q4 and have a look back was released in Q4 and have a look back at, at, at the initiatives, Yeah, thank you, Kirsten. Yeah, it's, always a pleasure to participate at. those dev calls. Yeah, 25 was a busy.

[01:00] Those dev calls. Yeah, 25 was a busy year. Like we shipped a lot of a busy year. Like we shipped a lot of a busy year. Like we shipped a lot of features, to the. features. A lot of features to the library. Yeah, expect that we keep the same, momentum in 26. And, yeah, we're going to present you today three new features that three, three new modules that we added to the library that is the, W A W, the W addition to the M fix W A W, the W addition to the M fix point M, library That will be presented in a short by. Os gun and fee abstraction, the fee abstraction, module, which is something also very important and the beginning of the governance package. That is for the time lock. So, yeah, I am going to pass it time lock. So, yeah, I am going to pass it time lock. So, yeah, I am going to pass it to Os gun.

[02:00] To Os gun, AT&T. Thank you, I'm going to immediately start, So let's say entire screen, and, and, and. I think it is visible right. Furthermore, I think it is visible right. AT&T. Yep, it is AT&T, Great, Great, So today it's the first topic is w a. So today it's the first topic is w a. So today it's the first topic is w a. it's a high precision decimal arithmetic. For Saroyan smart contracts: The reason for or the need for it is like: why for? Or the need for it is like why for? Or the need for. It is like: why are we not going with integers? Or floating points for integers? we're floating points for integers. We don't have decimals. So, for example, this doesn't have decimals. So, for example, this computation will result in zero. Instead, of 0.5 and for plotting floating points there are quite reasonable. things that we are not using them in blockchain, because in blockchain it needs to run on every computer, right.

[03:00] Needs to run on every computer right, like, and some people have macOS, some people have Linux, some people have Windows and across platform, the behavior for floating points is changing. and we need something deterministic in, blockchain setting for safety, and and and, yeah, general blockchain. So, what is what it is a fixed point decimal? What is what it is a fixed point decimal? What is what it is a fixed point decimal system that uses 18 decimals? So for example, one will be represented as this like there are 18 amounts of 18 zeros. here. Similarly, you can see the other representations, representations, representations. So the need for this is this. decimal point system, so that financial systems or whatever your use case that will utilize decimals, can work in.

[04:00] That will utilize decimals can work in, blockchain system, with a deterministic behavior: behavior, behavior. I'm going to dive a little bit, only little bit, into technical details, a little bit into technical details. Since this representation can fit in I, 128 in Rust type, we could use it for 128 in Rust type. We could use it for 128 in Rust type. We could use it for type allies, but we prefer, preferred to go with the new type pattern instead. So we wrapped this internal native type. into our custom type. This allowed us to have the following, For example: we could do custom operator overload for, this type, and we could do conversions from into a from and into other, from into an from and into other types. And we could also write some custom functions for this custom type, So if you went with type allies it. would just be the methods available on, I 128, which would be limiting and in fact,

[05:00] 128, which would be limiting, and in fact maybe misleading, So let's go with operator overloading. first. So if you, say this price and fee are w a you can just do price and fee are w a you can just do. Price and fee are w a you can just do multiplication, multiplication, multiplication or multi- sorry yeah, addition multiplication and division on them. So you don't need to call specific, functions. This is like for your developer experience. You can just write regular Ra's code and it will work. And we also have operator overloading for cross types, like you can multiply a regular number with w a and vice, versa. And you can also do division. So, since this is a fixed point math, library, there is a limit for the precision. And if you go beyond this precision, as in every fixed point math,

[06:00] Precision. As in every fixed point math library, we need to do either truncation or rounding, So we went with truncation, And the reason for that is to be, predictable. So what? Whatever method you are going to use, it will truncate, And this will be conservative in terms, of the smart contract. So the benefit will be on the smart contract end, not on, will be on the smart contract end, not on, will be on the smart contract end, not on the user end, which is what we want in the user end, which is what we want in the user end, which is what we want in blockchain setting, and there is no further additional logic going on It, is fast, So this is how we did the operator, overloading for some cases, For example. for addition, this is just regular. in addition. This is just regular for addition. This is just regular addition. So we didn't do much, But for multiplication, multiplication, multiplication. We need to divide the result by what. scale? So we need to scale it down The scale. So we need to scale it down The scale. So we need to scale it down. The reason is the first and the second multiplicands, like the left-hand side.

[07:00] Multiplicands like the left-hand side, and the right-hand side, both have these. 10 to the power of 18, kind of decimals. So when you multiply them, you actually have 10 to the power of 36. So need to, you need to scale it of 36. So need to, you need to scale it of 36. So need to. You need to scale it down, down, down. And for division, the same goes, we. need to scale it properly. So you don't have to think about this library already has it, and you can just do multiplication and division and you don't have to think about scaling, They don't have to think about scaling. The reason I'm explaining it is to explain this is already handled, so you don't. have to think about it. We also covered. Exponential for it. This is basic, exponent, So the exponent part needs to be integer, So the base part can be decimal and w, So the base part can be decimal and w, So the base part can be decimal and w. this is fine, And let me also type in this is fine, And let me also type in: this is fine. And let me also type in here: in Sloan SDK. You can already have Sorry, you already have this, So you

[08:00] Sorry, you already have this. So you are sorry, you already have this. So you can take power: integer to integer. This is working already. What we achieved by what representation and power function, is. you can do decimal to the power of is. you can do decimal to the power of is. you can do decimal to the power of integer. Right now. We didn't do decimal to the power of decimal. This is for later milestones, but right now, this is achieved and this covers from what I research more than 90% of the use cases, even for financial setting, And we can also touch a little bit on, and we can also touch a little bit on, and we can also touch a little bit on phantom overflow. So you remember from here we are multiplication two wads. together And there can be a potential scenario. This multiplication will overflow out of I 128 type, So it will overflow out of I 128 type. So it will overflow out of I 128 type, So it will be larger than I 128. In these cases we be larger than I 128. In these cases, we be larger than I 128. In these cases, we automatically scale up to I 256.

[09:00] Automatically scale up to I 256. Then we do the division. Then, if it's, fitting, we convert it back to I 128. If fitting, we convert it back to I 128. If fitting, we convert it back to I 128. If not, we result with an overflow. So this, phantom overflow is also handled for both power and multiplication. And you won't see confusing, conversions, conversions, conversions like, for example, let's say you want to convert five to what, but what should this representation mean? Is it the row value five? Like you will get this. The smaller it's the smallest amount, possible. Possible. Possible five. Or you should get the scaled version five. Like this is unclear from this representation right. So that's why we didn't do ambiguous from and into. default conversions. Because the intention is not clear here. Instead,

[10:00] Intention is not clear here. Instead, we have from integer and from row and we also have from token amount and to token amount. So I'm going to go with this amount. So I'm going to go with these examples right now. So let's say you have a token, you have an USDA amount of that much and this corresponds to 1.5 because in USDA you have six decimal, points. So this part is on the decimal part. So if you say from token amount and you provide this amount and you also, provide the decimal point. It will correctly, correctly, correctly scale your version to W A and you will scale your version to W A and you will scale your version to W A and you will get an accurate representation in W A, and similarly the vice versa conversion. is also safe and accurate. You will. If it is also safe and accurate, You will. If it is also safe and accurate, You will. If you convert WAD to token amount, you will. get the corresponding token amount, correctly, correctly, correctly. So I'm going to shortly touch base on. the API reference. Here are the. constructors we have from integer, from ratio, from token amount, from price and

[11:00] Ratio from token amount from price and from row. So let's say you convert a from row. So let's say you convert an integer five, then you will get five sad like full, Pi five, not.0000 five. But you will get the actual five, But if you go from row u, then what you. But if you go from row u, then what you. But if you go from row u, then what you provide will be the scaled down. So in order to get one, you need to provide 10 order. To get one, you need to provide 10 order. To get one, you need to provide 10 to the^ of 18 for the row Representation, representation, representation- We have also converters to integer to. token, amount and row. We have arithmetic operators, like addition, subtraction, multiplication, what by what? And multiplication, what by integer? And multiplication, integer by what are all covered in operator, Overloading: We also have division and division by integer, and we have negation, negation, negation. Ah, one point to say about this: these

[12:00] Ah, one point to say about this. These, are behaving exactly as in the rust, operators. So if you get an overflow, you will get an overflow, and it will panic, as in base rust operations. So we try to, as in base rust operations, So we try to as in base rust operations. So we try to follow the rust convention com, Conventions here to eliminate confusion. If you want to be safe, these are the. If you want to be safe, these are the If you want to be safe. These are the checked variants. Again, as in native rust, rust, rust. We also have utility methods, the. Furthermore, we also have utility methods: the absolute minimum maximum and power. And for these checked versions, and errors, you have the following errors, defined which is overflow, or division by zero, zero, zero. So, if there are any questions, I can. take them, but right now, since I take them. But right now, since I'm sharing the screen, I can't see the screen. So I'm going to wait for a minute, minute, minute. And yeah, based on the input, I can stop. And yeah, based on the input, I can stop. And yeah, based on the input, I can stop. Sharing, sharing, sharing, AT&T. Yeah, it doesn't seem like we have any AT&T. Yeah, it doesn't seem like we have any AT&T. Yeah, it doesn't seem like we have any questions at this point.

[13:00] Questions at this point. AT&T. Okay, thank you, and I can hand it over to boy. Thank you, and I can hand it over to boy. Then was good, yeah, yeah, yeah. So yeah, I'm going to present you the. fee abstraction module. First, what is fee abstraction? This is a mechanism that enables users to pay for, transactions with some tokens, that are are are instead of native XLM. So for, transactions you pay in XLM, which is the regular way of doing it, and this module fee abstraction is allowing users to pay. for transaction cost with other, tokens, tokens, tokens. What are the benefits for? We can see it from different. perspectives depending on who is.

[14:00] Perspectives, depending on who is transacting. So for classic accounts this provides another option to paying fees. So it's just a better user experience for classic accounts. But for smart accounts. This is something like a. a game changing The missing piece. So smart accounts, Maybe, if you are not familiar with smart, accounts, we, at the beginning of November, when we attended another dev call, we presented smart accounts. So I invite you to watch this. presentation if you want to get familiar with smart accounts and the framework we are proposing So framework we, we are proposing So, basically, smart accounts are smart, are contracts and contracts. They cannot initiate,

[15:00] Initiate. They cannot initiate, transactions. Right, they need assistance of another account to do so, And if we call this account a relayed, So smart accounts, they and delayers, they need somehow to understand each other, They, they need a protocol, some framework through which they framework through, through which they, they communicate and settle on, paying fees, and yeah, this is what u the fee Abstraction provides here in this case. What are the core elements of this? module, module, or of the abstraction as a like a general like mental model. So we generally like mental model. So we have a user here behind user. I mean both. Have a user here behind user. I mean both have a user here behind user. I mean both. Any kind of u accounts. It could be smart accounts or a classic account, the user that has some USDA in their

[16:00] User that has some USDA in their holding, some USDA, and they want to hold some USDA, and they want to call a function on a target contract. We call a function on a target contract. Furthermore, we have the relayed that holds XLM, There are some a component of off chain. interaction between them. So the user request makes a request and the relayed responds with some quotes and if they respond with some quotes and if they agree, so the settlement happens. Unchain on a contract that we are going to call fee forwarder contract, What is, the user flow? So, first the user. This is the unchain. component of the of this, model, The user sends to the relayed, assuming there is sending to the relayed, assuming there is an API that relayed uses the relay. The user sends to this,

[17:00] Relay. The user sends to this, relayed request. containing the address they want to, invoke the target function. The arguments and the token that they, in which they are willing to pay the transaction, are willing to pay the, the transaction fee, fee, fee. Then the relayed returns back. Then the relayed returns some max amount that they are meaning the, the price they are willing to pay for this transaction and the two to pay for this transaction, and the XDR to that that needs to be sent by XDR, to that that needs to be sent by XDR to that that needs to be sent by the user, Then the user receives this and if they're, if they are okay, they sign they are. If they are okay, they sign this invocation, but also they, they, they, sign an approval, the fungible approval. that we are going to see in a moment how this play out. So they sign it and return it to the relayed And now we go on the unchain.

[18:00] Relayed. And now we go on the unchain on unchain flow with this signed XDR. The relayed also signs it as a source. account submits to, submits unchain to the fee forwarder contract. And we'll pay the, the, the native XLM as a transaction fee, within the fee forwarder contract. We, transfer the token, is a fee from the user to the token is a fee from the user to the token is a fee from the user to the relayed. This is the that, this fee that will cover the transaction fee, but it might also contain some profit for to contain, some profit for the relayed that are like doing some useful that is doing some useful job, Then, after this is paid the fee,

[19:00] Then, after this is paid, the fee, forwarder contract. Invoke the target contract with the signed authorization, and this produces the the desired effect for the, end user, This part is like the a single. transaction. So it happens in an atomic way, way, way, Then in the library, we propose two flavors of this fee, forwarder contract, Of course, like anyone can write their own fee forwarder, contract. But like we are proposing two two versions of it- permissionless and permissioned. Permissioned, permissioned. The permissionless, is a trustless contract. Meaning that once we deploy it there is no owner. That once we deploy it there is no owner. That once we deploy it there is no owner. That can change some. Some settings Anyone can be a relayed, meaning

[20:00] This can create some dynamic, some interesting dynamics for some secondary market for u delayers, And the permissioned fee forwarder is, on the contrary, a node contract. Meaning, that there is a clear owner that can, Can specify what are the allowed tokens that users can use to pay for, transaction fees, who can act as a relayed. So it is, of course, like a depending on, it, I can see it very well for some it I can see it very well for some it I can see it very well for some applications for some dabs. That are willing to have more control, on who can who. Who can serve. Who cans on. Who can who. Who can serve. Who cans on. Who can who, who can serve, who can be a relay and what tokens they are being a relay and what tokens they are allowing they to are willing to take.

[21:00] Allowing, they are willing to take, as a payment, So what are the key takeaways? for classic accounts, this model is just another option. So maybe we can call it also a better. User experience: But for smart accounts it's a very important addition because it defines how the relayed and the smart account, should interact with each other in order, to, to make transaction happen, And u something that we'll see later this year. This, this model, will integrate with our relayed service. So yeah, this is about the Fe. abstraction module. If there are any abstraction modules, If there are any questions, questions, questions, I can take them.

[22:00] I can take them. It doesn't seem like there's any. Furthermore, it doesn't seem like there are any questions at this point. AT&T. Okay, then I will go then to the next AT&T. Okay, then I will go then to the next AT&T. Okay, then I will go then to the next module, which is the first, module from the governance package. What is a time lock? This is a. smart contract that enforces time, delays on transaction, execute ex execution with the goal to allow for safe exit. If there's some disagreement with a certain governance, decision, decision, decision How this works. Maybe I mean there are different use cases for using, time lock, but the most obvious is in a time lock. But the most obvious is in a time lock, but the most obvious is in a like a very simple setup on owner, Owner based setup meaning we have an owner based setup, meaning we have a contract that many users interact, with and there is an owner that can change certain settings on this contract.

[23:00] Change certain settings on this contract, and usually this is some account right, and if the owner wants to make some change on the contract, they just call the, the functions that are permission that they are callable, only by this owner, and they change it immediately. And the users don't have time to react to this. Okay, So they trust the owner like the. The good fate of the owner, but also like the This, this bear, this bears many risks. I mean not only the good faith of the I mean not only the good faith of the I mean not only the good faith of the owner. But if what? What if the keys' owner? But if what, what if the, the keys of the owner get compromised and some hacker takes control over the, the, contract. So to minimize those risks, we are introducing the time lock, which is a contract, and we designate this.

[24:00] Is a contract, and we designate this time lock contract as the owner of our initial contract, And so, in order, like for, this to work, we need also another layer. of u of accounts that are serving different roles. Here we have a proposer and an executor, and we'll see how like how this, works, So yeah to. To recap in the: classical in the left-hand side: we have the. The setup where account they have the. The setup where account. The account is directly the owner and the. The intent, the intention to do a. change and the execution of this intention through a transaction is like tied is very close, it's tied. together. So they happen immediately and

[25:00] Together, So they happen immediately. And in with the time lock. There is the intention to make a change. That is expressed by the proposer, This happens at some moment. There's some time that elapses some. period, and then we execute the intention. So we the time Between the intention and the execution, is split is get separated, So the unit of this whole flow is an. So the unit of this whole flow is an. So the unit of this whole flow is an operation that is simply a target, the target address. So the contract that we want to act upon a function, the arguments for this function and the predecessor meaning that we are chaining operations, one to each other and imposing some sequence.

[26:00] Some sequence, on the sequentially on the EXE, execution. Meaning the newer operation cannot be executed before we execute the predecessor, to execute the predecessor, the previous one, What is the life cycle of this? operation? So first the sh, the proposer schedules such operation, meaning they, they invoke a proposed function on the time contract, Then there is some delay that we wait for. it to, to pass The executor once the operation, this is The executor, once the operation. This, this time passes. The operation is marked. as ready and the executor will call an execute function on the time block and which will provoke the, the desired Effect on the target contract and we are done, the operation is done.

[27:00] We are done, the operation is done. What are the benefits? So, first, as we mentioned in the classical like the, the most obvious benefit is that it allows investors to exit in time if, if necessary. It also exits in time if, if necessary. It also forces the admins of the contracts to be, more transparent with the other, users. Meaning they need to communicate in advance about what, change they. They mean to, to change them. They mean to, to, to do on the target contract: U. so it is does on the target contract: U. so it. It does on the target contract U. so it is. It promotes transparency. Also in the past we've seen in how. Besides in the past we've seen in how, for example, this separation between the intention and the execution provides some time to react on errors, because it is transparent. So everyone from the community can spot, can.

[28:00] Community can spot, if their errors and prevent them. from happening And, as we mentioned, this also prevents some malicious. takeover of the, the owners or the, the owner's accounts on at the end, this is this whole system provides more. guarantees to the community, So, as I mentioned, this is the first. module from the governance in the next milestone, which is in Q1, we are going to ship the. fungible and the non fungible vault extensions. These are extensions that will allow counting to to to will allow counting to. To attribute some voting power to tokens and the. The governor with all the features about quorum, about counting.

[29:00] Features about quorum, about counting votes and so on, So that's it for the time lock. AT&T. It's fascinating, it doesn't? seem like we have any questions. AT&T. Yeah, if I mean we, if there are. AT&T. Yeah, if I mean we. If there are any questions, we also are presenting. in discord. So, yeah, feel free to ping us in discord. So, yeah, feel free to ping us in discord. So, yeah, feel free to ping us. If you want to learn more, there is. also the documentation. docsopenscom. opening, opening, opening, where these modules and their, functioning is explained in more details. So, yeah, looking forward to see people using those modules and tweaking them and making them for like, useful for their use cases.

[30:00] Like useful for their use cases. AT&T- Great Well, thank you so much for presenting these, these great new. additions and these new concepts, I think the governance is going to be thought the governance is going to be, think the governance is going to be fascinating to see how that develops this year. I think there's a develops this year. Furthermore, I think there's a lot of very interesting, interesting, u things lined up here. Yeah, AT&T. Thank you both for joining. And yeah, it's actually been its last year. Was itbeen actually been its last year? Was it's actually been its last year was AT&T. It was fascinating because I think that's where we really started to see, especially towards the. The last half of last year, where we really saw at half of last year, where we really saw at half of last year, where we really saw at hackathons and builders around the world. started to include and use the The open seven libraries and really started to to to implement it and it's been. great to see how much value this is bringing to, the community and and and how excited the community is about all the work. the great work you're doing So. so thank you, so much for joining and AT&T, thank you. for hosting us once, again, Looking forward to the next time.

[31:00] Again, Looking forward to the next time. AT&T. Yeah, we definitely do another one when. AT&T. Yeah, we definitely do another one when-when we have more updates. So thank when we have more updates. So thank you for joining everyone and u glad to be here. AT&T. See you later. Bye, bye, All right.

</details>

## CAP-77 Ledger Key Freezing, CAP-78 TTL Policies, and CAP-79 StrKey/Address Conversions {#part-2}

<YouTube ID="CetcWbsdRdE" />

We had three CAPs prepared for this meeting. CAP-77 introduces a way to make ledger keys inaccessible via a network configuration upgrade voted on by validators. CAP-78 proposes an interface that lets developers specify TTL extension policies (for example, "if an entry TTL is less than 29 days, extend it to a 30-day TTL"). CAP-79 adds host functions for converting Stellar StrKey strings to and from Address/MuxedAddress objects.

### Key Topics

- CAP-77: Proposes a validator-voted network upgrade mechanism to make specific ledger keys inaccessible (an emergency tool motivated by past corruption and incident response needs)
- CAP-77 (edge cases): Discusses tricky edge cases for classic entries and DEX behavior, with a goal of being “surgical” (minimizing broader network disruption)
- CAP-78: Proposes a contract interface for TTL extension policies (e.g., “if TTL < N days, extend to N days”) to standardize and simplify rent/TTL management
- CAP-79: Adds host functions to convert StrKey strings to/from `Address` and `MuxedAddress` (including support for muxed/max-address-style identifiers)
- Closing note: Reminder/discussion of SLP-4 to raise network resource limits and lower non-refundable fees to enable more on-chain work at lower cost

### Resources

- [CAP-77: Ability to freeze ledger keys via network configuration](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0077.md) · [Discussion](https://github.com/orgs/stellar/discussions/1811)
- [CAP-78: Host functions for performing limited TTL extensions](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0078.md) · [Discussion](https://github.com/orgs/stellar/discussions/1825)
- [CAP-79: Host functions for muxed address strkey conversions](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0079.md) · [Discussion](https://github.com/orgs/stellar/discussions/1840)

<details>
  <summary>Video Transcript</summary>

[00:00] Another case is just a bit better. extension strategy for general purpose. contract, so that you can spread out the extension feeds among users, more evenly by limiting max extension, And the way we achieve this is, described in the gap. We provide a new interface for the tail extension, function. Or rather, two functions, One for the contract data, another is for contract instance in code And instead of the old threshold parameters, that defined min extension, we define just the range of min extension and max extension. That tells that extension will be only performed if it is at least, will be only performed if it is at least, will be only performed if it is at least minion, and then it will be clamped by max extension. So can set up more.

[01:00] Max extension. So can set up more complex detail management strategies, I don't think there is a need to go. I don't think there is a need to go. Furthermore, I don't think there is a need to go into into into math more deeply, Basically, there is some edge case there. There is some edge case handling. But the gist of it is really that, besides limiting the minimum, extension necessary to actually extend to DL, you can now have the max extension as well, Please take a look at the cup for more. Please take a look at the cup for more. Please take a look at the cup for more details and if there are any questions regarding, this cup right now. Please feel free to ask someone. I guess the only kind of tricky part, Okay, So the question is, for example: current detail is 10 extend to 20 mean.

[02:00] Current detail is 10. Extend to 20 mean. Five max 8. extend would work with current. Okay, so it is important to distinguish. between TTL and leave until ledger TTL, is basically how long will entry live? from this moment, For example, we are on ledger n and even till ledger. We are on ledger n and even till ledger. We are on ledger n and even till ledger is like n plus th00and that means that GPL is a thousand lectures. Because the entry will live for a thousand lectures. from now. So let's say your current TTL, not wedder is 1,000 wedges. and then you can say I want to extend. And then you can say I want to extend, and then you can say I want to extend the TTL to be 10,000 wedges, but only allow extending by. Let's say,

[03:00] but only allow extending by, let's say, 500 wedges at a time. So, for example, if you're on thousand welders now your, target is 10,000. Every user that calls it will extend the entry just by 500. wedges. And that's limiting the fees Every individual color between, and, on the other hand, again the same. scenario: you want your TL to be 10,000. but it's already 9,999, You know the extension will be just one. additional ledger. And if your main extension is, for example, 100 ledgers and you want to pass the check and TL, extension will not happen at all. Which is basically similar to what threshold does, but just is a like the math is a bit different, but the end result is exactly the same, I believe.

[04:00] I think is a topic that is easier to. I think is a topic that is easier to digest like a piece of paper than trying to digest like a piece of paper, than trying to digest like a piece of paper, than trying to clean it but yeah, yeah, yeah, has all the equations, so can plug in. some numbers and see what comes out of it. It. Yeah. So the other consideration I wanted, to add-is that for temporary entries to add, is that, for temporary entries, max extension will work in the same way. Which may or may not be a bit of a foot, which may or may not be a bit of a foot, which may or may not be a bit of a foot, gun because, if you miss the extension of a temporary, entry, it will be gone forever. And this may not be desirable for a lot of use, may not be desirable for a lot of use, may not be desirable for a lot of use. Cases of temporary entries. So generally speaking, this min extension.

[05:00] Generally speaking, this min extension, parameters, So the threshold parameter in the existing functions is really more for the fee management, for the, persistent entries and for the temples you generally want the extension to. always happen and to always happen in precise fashion. Or else you're risking to just lose your temporary entry, because hasn't happened. And yeah, protocol allows that, but probably at this DK level. We'll try to make sure this the default is reasonable and this is the default is reasonable and this, the default, is reasonable, and it is hard to do something weird. For you with extension, because we, misconfigured your Mina extension, Okay, wait for like few more moments if I want. Wait for like few more moments if I want to type in.

[06:00] A second. Well, I apologize for that, but not sure. if I can do anything. Okay, yeah, it may be discord acting up on. Okay, yeah, it may be discord acting up on people. Yeah, sure, what can you do about it? Right, if you have any further. questions or suggestions regarding this? CAP. The discussion has been linked. above. So please feel free to comment asynchronously, asynchronously, asynchronously and visit. Let's proceed to cat 79. Let me link it. Okay, LY, this one is a simple CAP as well, and

[07:00] this one is a simple CAP as well. And this one is a simple CAP as well, and it just adds host functions for the max. address string to conversions, and it basically closes a bit of, feature gap or an oversight. We've introduced in Protocol 23. In per code 23, we've introduced a new type of address: max address, which allows users to specify an additional it to 64bit, 64bit, 64bit. I am sorry, 3 to 64 bits doesn't really. I am sorry, 3 to 64 bits doesn't really. I am sorry, 3 to 64 bits doesn't really matter. But basically it allows users to specify an additional, memo, together with their click key, and then this memo can be consumed by the exchanges, to distinguish between multiple users, that

[08:00] distinguish between multiple users, that have the same address on chain. So that we can have a federal account. that has multiple users but only a single sure entry. Holding the balance on chain. Okay, okay, try to actually disable noise. Suppression: I, I know that did introduce some artifacts before hope. It's better now. So, yeah, anyway, coming back to zap u m addresses has have been added in Protocol 23. You can pass them in as contract, arguments, but what has been missed is the St key format conversions, that exist for regular addresses and sorry use cases for keys.

[09:00] And sorry use cases for keys Mainly, mainly, mainly, bridge protocols, protocols that generally do anything. Cross chain and ST key is common format to use for. messaging, like if you need to specify storage destination from desert chain store key is a preferred format and not being able to handle key for max, addresses kind of limits, the protocols, I guess. the C is very straightforward. It just does the conversions. The only thing about it is that well potentially, not potentially, but we we have already implemented this, functionality in the SDK. So there is potentially an argument of: well, why do we even have it in host? And I think in we even have it in host and I think in we even have it in host and I think in this case it is mostly for the sake.

[10:00] This case it is mostly for the sake. of the, full feature set, like we already have the key conversions which was possible, to get away without the host functions, before, and, of course, doing things on the old side is just cheaper and with more future-proof, hopefully because the implementation can be for, example, fixed without updating any contract, in case there are some set issues which we hope won't be the case, case, case, so, so, so, yeah, that's the CAP and I guess in this, yeah, that's the CAP. And I guess in this, yeah, that's the CAP. And I guess in this case, yeah, it's just cheap enough to implement to have it have a consistent host function coverage for all the address kind, instead of this weird feature gaps that we have right now.

[11:00] Exactly NS feature part. I think is an Exactly NS feature part. I think is a main driver here, Okay again, I will not okay. Keep max address. no, the CAP. Okay, Maybe I'm not the CAP. Okay, Maybe I should have answered the cup Specification. Specification: specification: the gap returns either address object. for the regular keys, or or or. well, yeah, I guess it's a semantics. Question, what? What do we even call address? Because we have this two different object types address object. max address object. And the function can return either one.

[12:00] And the function can return either one of them. So I guess it's kind very philosophical question. It should be philosophical question. Furthermore, it should be called too much to address or just to address, address, address. Yeah, I'll give it a thought, probably. but doesn't seem very important in the end. I think I guess my intention end. Furthermore, I think I guess my intention here is that V2 would be used. Going forward for all the use cases. So that you don't, you can just safely stop using V1 in the SDK and won't be any semantic V1 in the SDK and won't be any semantic V1 in the SDK and won't be any semantic weirdness. All right, we'll spend a few more. moments before typing.

[13:00] That's a good question. Yeah, I think. If address is using the old one, then you can name this more specifically for max, services. Because like, yeah, you could use a new function, but then you will need to a new function, but then you will need to a new function, but then you will need to distinguish between different object, types and fail, and that's unnecessary work. I agree that old function is still work. Furthermore, I agree that old function is still useful for the case of like normal address, conversions. Actually, you kind of do care if it is an M or G address, because some addresses are like bit gain. We try to limit the scope, for where you can use them, For example, you cannot require an m address. You need, you cannot require an m address. Furthermore, you need to convert it to a normal address first, And, yeah, not every contract can deal.

[14:00] And, yeah, not every contract can deal with M address correctly, which is why it's completely its own thing. So, basically, max address is a super set. of address. If you can deal with max address, you can deal with address but not vice versa, Yeah, I think that's a good. suggestion. Yeah, I think, after reconsidering this. Yeah, I agree, that two maxed address and max, address. 230 sounds more in line with how we use them, Thank you for the suggestion. I will thank you for the suggestion. Furthermore, I will update the accordingly.

[15:00] Right as usual. Any questions or comments can be left on the discussion. thread. And let us move to CAP 77 Right Boston, And this CAP is much more. straightforward than the previous two, And to give a bit of background of why this came up, as some, all of you, why this came up, as some, all of you, why this came up, as some, all of you may know, we had an incident in Protocol 23, caused by data corruption bug, And the initial response when the incident has been discovered, was to make it so the corrupted data.

[16:00] Was to make it so. The corrupted data cannot be accessed to prevent and for their corruption before we understand better, better, better. And that was especially relevant for, the entries that have been corrupted, but not yet restored. So like for these entries, we definitely have prevented further breakages and corruption, And the way this has been achieved was, via an emergency release of tower core, that basically just hardcoded some, hardcoded, they affected contract, data keys and rejected any transaction that accessed any of this Bad keys in the footprint.

[17:00] Yes and yeah, I will. talk about this. Yes, and this has been achieved without, any protocol changes, right, yeah, this, Captors will have to agree. I'm just captors will have to agree. Furthermore, I'm just talking about like to, to provide some background like what auditors can do, today without any protocol changes, or anything. Is that they can just exclude transactions from the man pool? They can do this for whatever arbitrary malicious and unmalicious reasons, But it's an important thing to, understand when thinking about this CAP. because it's doing something like. very uniquely different from what, lawyers can do today, So yeah for the for this. Corruption issue: custom core build. would reject the transactions that try. to access bad keys at the male level.

[18:00] To access bad keys at the male level, and, and, and. Corruption could only be prevented at. the moment when every tier one valuator, has updated to this new core build, such that there is no way that a transaction would end up in a transaction set that accesses corrupted data. And it is a very fragile and time-consuming procedure. Right because, first, a new release has to be, pushed and second, you need like a 100% consensus on this, so to speak, like consensus at the level of build and its consensus at the level of build, and it is not providing any guarantees, even because can fall back the build, or whatever intention or unintentional, reason, reason:

[19:00] which motivated the gap that would, allow doing something like this at to allow, doing something like this at the protocol level, and the benefit of this at least conceptually doing this at protocol level as well, an explicit consensus of all data is required. which is both good from the transparency, standpoint right because it is possible to observe what validators have voted for, but also from the emergency response standpoint. We actually need lower percentage than 100 to agree on applying a network upgrade. So even if not every validator but just say five out of seven is the but, just say five out of seven is the. But just say five out of seven is the current network config right now. Are the upgrades that would freeze the ledger keys. Then the upgrade will go.

[20:00] Keys, then the upgrade will go. through. And also it is not easily reversible without votes. So there is no concern that: oh what if someone changes. their build and what not Obviously This is the case, Like this scenario is something that we'd like to avoid in the future, because we, I guess one of the arguments, maybe against this camp is: well, probably don't want to have any similar data, Corruption issues in the future, But of course it is never possible to say that the system is 100% formally, valid and will never ever result in any bugs. So that's a bit of trade-off between like making protocol more, complicated for the off chains. If data gets corrupted again, for whatever reason, and freezing the keys would be.

[21:00] Reason and freezing the keys would be that right remediation for this, And another potential motivation for, this would be: if there is like known, hack, a vulnerability that affects some contracts for users, for example, there is a theoretical possibility for freezing the balances, But I think this case is much less clear. But I think this case is much less clear, but I think this case is much less clear. If it is relevant or not, because if you're talking about like high-profile, hacks, hacks, hacks might be really tricky to chase right by. your entries. Some exact cases of bugs, were you know they're likely not being, did you know they're likely not being exploited actively, and the impact is more or less limited to some set, of entries, somehow, but you know it's still a consideration. Okay, let me read the

[22:00] consideration. Okay, let me read the question from chat. Yes, so, now, in terms of the actual ways the cup now, in terms of the actual ways the cup now, in terms of the actual ways the cup works, works, works, there are like it pro it covers three. types. Three kinds of entries. Oh, I guess yeah, on high level, just two kinds. Urban entries and nonurban entries. And for non-stop bind entries, we are. And for non-stop bind entries, we're only considering account and trust line, entries, because this seems to be like if we bother implementing this logic, for classic entries, this two seem like the most obvious candidates, everything else on classic does not actually hold value usually and the risk of like, even if corruption happens there, the consequences are probably pretty, tame and, yeah, it's more of a

[23:00] tame, and yeah, it's more of a complexity: trade-off, And Saroyan- only entries, of course can, and Saroyan, only entries, of course-can only be accessed from Saroyan, which makes the freeze process much easier. And now to answer the material's question. yes, if network votes to freeze, contract code key, for example, then any transaction that accesses this contract, will be rejected, It will not even fail till, not even be. It will not even fail till, not even be. Furthermore, it will not even fail till, not even be included into a charge. So I don't know, for example, if a contract, gets corrupted for whatever reason and skips authorization check, somehow Right, freezing the contract is actually a good remediation, because you know the user will not be able to interact with vulnerable contract.

[24:00] Yeah, basically what is the use cases? Yeah, basically what the use cases that will die? Are this fitting the that will die? is this fitting the CAP? But the idea is that any interaction- either read only or write interaction with the entry is prohibited. with like one small exception. We said with like one small exception. Furthermore, we said, there again for the sake of simplicity, But the idea is that the entry cannot, be accessed. It's not only that you cannot, for example, modify balance. It cannot, for example, modify balance. Furthermore, it's also that you cannot even read it. Right. If you try to read this balance you will fail as well, because if balanced, you will fail as well, because if balance is corrupted, for example, then you may arrive at bad results, which happened. for example, with Protocol 23: corruption, bug where liquidity.

[25:00] Bug where liquidity pool got incorrect balances, That's actually don't recall. If the data inside the pool was corrupted, further. But there is definitely a risk of this happening, like if you have any mass based on just reading the corrupted entry this mass may go wrong and then you may end up in bad state in an you may end up in bad state in an you may end up in bad state in an unrelated contract, so, yeah, let me continue with this pack. That may answer some more questions. So yeah, basically, as I mentioned the. intention is to not include, the transactions into lure at all. If we

[26:00] transactions into lure at all, If we get into dealing with account and trust, entries. That's unfortunately not always possible. Because, like Sora ban, no footprints for classic operations, and and and it is not always possible to know if a. it is not always possible to know if a. it is not always possible to know if a frozen entry is even being accessed. which is why a fraction of transactions, would fail at apply time, and it's also some separate logic for handling decks? U described in the CAP that I will talk. about in more detail later, But yeah, the intent is really. just to prevent the interactions with, the entries and, unfortunately, the way of doing this is kind of complicated. because, like, if we include classic, if we don't include classics, then it is as simple as filtering based on footprint.

[27:00] Simple as filtering based on footprint, So let me talk a bit more detail about, So let me talk a bit more detail about, So let me talk a bit more detail about the semantics first is the upgrade. process itself. It needs to be customized a little bit compared to the normal network upgrades as well, because the maximum size of the network, upgrade is limited by the contract data size, and it may be a limiting factor if we need to increase many, keys, which is why we key, which is why we the proposes a structure where delta of the changes since frozen entries, is voted for, so that the total amount of is voted for, so that the total amount of is voted for, so that the total amount of frozen keys can exceed the contract data. entry size and can be updated incrementally, incrementally, incrementally. That's a bit of an extension on the.

[28:00] That's a bit of an extension on the current upgrade process, which rather straightforward, but again it's like a bit of additional complexity of this CAP. And now to the fun part of how. actually this would be implemented at. the protocol level, So, as I mentioned for Robbin, transactions, things are very simple. If we see a frozen key in the footprint, If we see a frozen key in the footprint, If we see a frozen key in the footprint, we recheck the transaction and that's. it. We don't need to do anything else. We can also like if an account is. frozen, and it's a source account of the transaction operation. Again, you just reject the transaction. That's simple as well, well. Well, Then the CAP lists operations. Where, it is easy to say what is a source trust?

[29:00] It is easy to say what is a source trust. It is easy to say what is a source trust line, destination account or trust line, by just looking at the operation which, is good chunk of the operation, So basically again, if we inform that a frozen account and trust line is accessed, we reject the transaction and everything is good Now to the non-trivial operations. First, cable balance operations: claim balance and liquidity pool. deposit and withdrawals, or using opaque identifiers. And without doing some logic, it's not possible to tell what the destination is unless we do some additional type of indexing, which I'm not sure if you want to do which, I'm not sure if you want to do which, I'm not sure if you want to do, but the suggestion here is just to, fail at the applied time if a frozen key.

[30:00] Fail at the applied time, if a frozen key fails at the applied time, if a frozen key is being accessed after we have actually determined what are the actual trust lines participating in the operation And I believe for KAL balances it's even, more tricky because a balance can have multiple. Please never mind that I said something. incorrect, incorrect, incorrect. Anyway, This is like a bit ugly, but still straightforward. What is ugly, and kind of complicated is DEX operations. So again, if you wanted to support free prison and trust lines and accounts, then we need to care about decks-classic store decks and decks, classic store decks- and of course it is not possible to tell, beforehand if a frozen balance is being affected by deck separation.

[31:00] Being affected by deck separation, It will only be known, known at the. apply time and then at the apply time, we apply time and then, at the apply time, we apply time and then, at the apply time, we could also just fail if we encounter an offer that would result in modifying a bad balance, frozen balance. But that would have frozen balance. But that would effectively, effectively, effectively freeze a whole asset pair for trading, which is a bit of, AT&T. An unexpected impact. for the change week. We want to be for the change week. Furthermore, we want to be pretty surgical about this. Like we want to prevent operations that depend on, corrupted entries. But we don't corrupt entries. But we don't really want to disrupt network activity, more than necessary. Beyond that and freezing all trading pair and deep, may be problematic, Of course, chances of that happening, are not very high, but still we want to are not very high, but still we want to are not very high, but still we want to prevent this in the protocol. So the prevention this in the protocol. So the proposal in the CAP is instead of:

[32:00] proposal in the CAP is instead of freezing the pair, is to emulate crossing this offer without modifying any balances, and just remove it, which is not great. Remove an offer, But it kind of gets around the issue, of of of freezing the whole trading painter And of course we could add some more. complex logic to just skip it. But we would need to skip it every time. we encounter it And yeah, it would require some pretty. invasive changes to classic decks for a very limited use case, that we don't. even know if it happens. So the proposed solution is basically a trade-off between complexity, and and and usability of not freezing the whole trading pair. Kind of agree, it's not.

[33:00] Trading pair, kind of agree, it's not pretty, but it's the best you could come up with that seem relatively non-intrusive. And the last but not least, exception to, all this mess is well if an account is all this mess is well if an account is all this mess is well if an account is frozen. What happens if someone removes an entry sponsored by this, account? And again it would kind of be weird to fail everyone that has this interact, Sponsorship, dependency on a frozen account, which is suggestion, is to allow modification of nonsponsoring, Field, field, field, which is a bit of, a leak of the free semantics, a bit of a leak of the free semantics, a bit of a leak of the free semantics, but it seems acceptable as we not really, but it seems acceptable as we're not really touching the balance or anything like that. It's just sponsorship field.

[34:00] That it's just sponsorship field, and, and it's very unlikely to be corrupted, and even if it is corrupted, they can. just, yeah, they should be relatively easy to fix if necessary. Product. So, so, so it seems like again it is a trade-off. between like complexity because tracing the sponsorships to free frozen, entries is much more complex and probably needs to happen at runtime for, every operation which seems like a lot, of overhead. So this, this is basically a small compromise between complexity and limiting impact to only what is hopefully relevant.

[35:00] Contracts do not. I see question from John: What? What other challenges exist in having contracts call to exist in having contracts call the decks? Congress cannot call the classic decks at the moment, and I'm not sure if they will ever be able to precisely because of their reasons, for why you have all this nice cure It, for why you have all this nice cure It, for why you have all this nice cure. It is not possible to know beforehand, What is the data that will be modified? by any traction involving text? We, just buy any traction involving text. We're just going against this San data model, where we define everything. That is going to be accessed in the footprint. Yeah, contracts cannot call DEX. But, for the purpose, like if you wanted to, freeze accounts and trust lines, you would need to deal with this deck, somehow, somehow. So, yeah, that's more or less it for the. So, yeah, that's more or less it for the semantics. It's again, there's a lot of semantics. Furthermore, it's again, there's a lot of complexity in handling the classic entries. And an argument could be made to

[36:00] entries and an argument could be made to maybe limiting this CAP to only sol, entries, because this only appear in the footprints and it is very simple, Check so seems weak and much simpler. Change than what is described here. But of course the impact is much more, limited. And if an account gets corrupted for whatever reason, then of course we won't be able to do anything, about it, Yeah, that's pretty much it for the. semantics And I guess I've touched this a little bit. before. But yeah, and I want to emphasize that. Well, this CAP may look controversial, like, already have censorship powers and really what this proposes is basically an emergency mechanism. That is also.

[37:00] An emergency mechanism that is also transparent. So it seems quite unlikely that it can be abused meaningfully, And you know if our leaders conspire, to do something bad anyway, then probably will not learn about it, unlike, this protocol mechanism that is at least observable. But yeah, I, I think the bigger downside, to this CAP is really all the technical complexities this comes with and the fact that we kind of do not know if fact that we kind of do not know if fact that we kind of do not know if this is ever going to be used like of this is ever going to be used like of this is ever going to be used like of our response to potential things like to do, if something like risk, Archival corruption bug happens again. but of course we don't know what is.

[38:00] But of course we don't know what is, that probably, what is that happening? So yeah guys, that's kind of the main. thing. Initial this camp and to summarize the implications it's. really like, in Canada, access entry and depending on the number of contexts, entry can appear in a number of operations will not be possible, so, yeah, any questions or thoughts on why, this is a good idea or bad idea, or we this is a good idea or bad idea, or we this is a good idea or bad idea, or we should do something else, are welcome.

[40:00] Right, well, I will then pop here and again same. for the other CAP's. Please feel free to comment on the discussion thread. If you have any thoughts, questions, concerns or anything but. but I, I don't know, I think that's pretty, much it for today's presentation, I guess, while everyone is here, I just, want to remind everyone about SOP4. Which is a proposal to basically increase, the limits for pretty much every, resource, and so about two times, and also decrease non-refundable fees, like four times, which means basically more stuff to do on chain for cheaper which is- And please feel free to.

[41:00] Which is. And please feel free to chime in the discussion. If you have any thoughts on this as well, And yeah, that thanks everyone. and see you on the next protocol meeting.

</details>
