---
title: "Payment Channels on Stellar: Generalized Transaction Preconditions and Multisig"
description: "This discussion examined two protocol proposals that enable payment channels on Stellar: generalized transaction preconditions and a new multisig mechanism for safely exchanging bundled transactions. The conversation focused on design tradeoffs, implementation details, and how these changes support scalable off-chain payments."
authors:
  - david-mazieres
  - eric-saunders
  - jed-mccaleb
  - jonathan-jove
  - justin-rice
  - leigh-mcculloch
  - nicolas-barry
  - siddharth-suresh
  - tomer-weller
tags: [legacy, CAP-21, CAP-40]
---

import YouTube from "@site/src/components/YouTube";

<YouTube ID="YhtaZ3f_p4o" />

This session focused on two closely related protocol changes that together lay the foundation for payment channels on Stellar. Participants explored how more expressive transaction preconditions and a new multisignature construct can enable secure off-chain state updates with periodic on-chain settlement.

The discussion emphasized practical implementation concerns, backward compatibility, and long-term extensibility. Much of the conversation centered on how these CAPs interact with existing ledger structures, SDKs, and signing workflows, with the goal of supporting high-volume use cases without introducing unnecessary complexity.

### Key Topics

- CAP-21: generalizing transaction preconditions beyond simple time bounds
  - Support for relative time locks, ledger bounds, and additional signer requirements
  - Design tradeoffs around account extension nesting vs. flattening
  - How preconditions are validated versus applied during transaction processing
  - Implications for SDKs, signing safety, and backward compatibility
  - Payment channels as a scaling mechanism through off-chain transactions
- CAP-40: enabling safe exchange of signatures for multiple related transactions
  - Single-step authorization of up to three linked transactions
  - Reducing round trips and coordination complexity in payment channels
  - Relationship to existing multisig and hash-based signers
  - Considerations around scalability, signature limits, and future extensions

### Outcomes

- Agreement to revise CAP-21 to address account extension structure and validation semantics
- Consensus on a clear path toward accepting CAP-21 after targeted updates
- General alignment that CAP-40 is valuable, with a request to add a standalone use case
- Plan to revisit both proposals together for acceptance after revisions

### Resources

- [CAP-21 – Generalized Transaction Preconditions (Proposal)](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0021.md)
- [CAP-21 – Generalized Transaction Preconditions (Discussion Thread)](https://groups.google.com/g/stellar-dev/c/N8vzP2Mi89U)
- [CAP-40 – Payment Channel Multisig (Proposal)](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0040.md)
- [CAP-40 – Payment Channel Multisig (Discussion Thread)](https://groups.google.com/g/stellar-dev/c/Wp7gNaJvt40)

<details>
  <summary>Video Transcript</summary>

[00:00] Hello everyone and welcome to the Stellar Open Protocol Discussion. So in these meetings we discuss Core Advancement Proposal, aka CAPs. These are technical specs that suggest changes to the Stellar protocol necessary to allow the protocol to continue to evolve to meet the needs of the ecosystem, and we live stream these meetings so that anyone who's interested in watching they can follow along, although I do want to know it is a technical discussion. So if you are watching, you may want to take a look at the CAPs themselves and they're linked to in the show description.

[01:00] Also, we do keep an eye on the discussion box and your comments there. They do help us inform our decisions going forward. Today's discussion will focus on two CAPs and our goal is really, as it is generally in these meetings, to try to resolve some outstanding questions about them. So we may not address questions that you ask directly, but if some relevant ones come in, I may actually try to incorporate them into the conversation. So, as I said, we are focusing on CAPs and this meeting is just part of the CAP life cycle. So generally CAPs are discussed on the Stellar depth mailing list. There's a link to that mailing list in the event description for anyone who's interested in joining the discussion. Then CAPs are drafted and iterated on based on feedback and suggestions and they end up here in this protocol meeting and based on what happens in this meeting they may be put up for a vote by the CAP. They may be put up for a vote by the CAP committee who decides whether or not to accept a rejected CAP, which point they move into Final Comment Period. So there's, everyone has a last chance to raise questions on the Stellar debt mailing list and if it makes it through Final Comment Period, a CAP is implemented into a major Stellar Core release.

[02:00] Then there's still one final step, which is that every major release, every protocol upgrade, is voted on by the validators and has to be accepted before it's applied to the network. And so all of that is to say this is a and so all of that is to say this is a long process where there's a lot of public participation and ultimately the network decides to accept major protocol changes. So enough preamble. Today we are discussing [CAP-21](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0021.md) and [CAP-40](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0040.md). Both of these lay the groundwork for building payment channels on Stellar. So payment channels. They allow multiple parties to securely transact off-chain and periodically settle on chain and, among other things, that could make it easier to build high volume use cases on Stellar. So if today's discussion seems dense at any point, keep that in mind. These CAPs make technical changes geared towards payment channels and payment channels are important for scaling network throughput. So without further ado, we will look at the actual CAPs. We're going to start by talking about [CAP-21](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0021.md). This proposal generalizes the time balance field in transaction to support other conditions, including conditions that relax sequence, number

[03:00] Checking and provide relative time locks, and since we last discussed this, there were some small technical changes. There was also the addition of extra signers and I think we should start there. The new precondition- extra signers- has been added. Lee, can you just explain what that, why that edition happened, and sort of talk us through any questions that you have about it? Yes, so extra signers was initially added to support stateless htlc's. So the ability to just to say that this transaction needs to be signed by, or a hash needs to be included with this transaction to make it valid without having to store that hash as a signer on the account. So right now you can use the hashtag signer to say that you need this. You need a hash included with transactions to be able to transact with an account and, instead of needing to store that

[04:00] On the account, it can now just be stored within the transaction and then, second, it's also being used for [CAP-40](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0040.md), which we'll talk about later. Would help for me to like overview the other changes to [CAP-21](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0021.md). Just because you know, I think it was already, people were kind of generally okay with it the last time we discussed it, and so a lot of these changes are kind of in response to leads, like specific implementation and experience, like things that just came up because of implementing it. I think that would be super helpful. Yeah, great when you're working, so, yeah, so one of the changes is that the previous version didn't really talk about the results, and there's new failure modes now because you've got these multiple preconditions and so you might have sort of multiple preconditions failing and in particular you know you could have preconditions failing because it's too late or both, and so what we basically said is if a

[05:00] Transaction can never be valid again, then even if there's other things that are too early, we'll still call it too late and we'll give the result code tx2 early, only in the case that there is the possibility that the transaction can be valid again if resubmitted at some later time. So basically, if you have said a thing that's too early and a thing that's too late, that gets combined to a too late error and so that fits it into like the existing error codes, and I think you know preserves the sort of the intuition: if you're too late you can never resubmit and if you're too early there might be a chance of resubmitting at some later point. So other things that we changed. There's some clarifications. Oh yeah, the we kind of rearranged the stuff that's dangling off the account of the account entry in the ledger, because it turns out that

[06:00] Kind of the sponsorship information is only there if you're actually sponsoring things and so otherwise it's currently null or it's a v1 extension instead of v2. So we changed that into a pointer and we just kept the v2 data structure as a thing that dangles off the v3 now optionally if you're actually using it. And then the final change is that we didn't talk about we previously I hadn't mentioned what to do to an account that didn't have an account entry extension v3. And so the answer was: just now we just say: pretend, all the fields are zero, right? So that means like it's as if, like the last time it was mod the last ledger was modified in time and stuff are zero, and that's okay because even though that means anything can anything that's like a relative delay will execute any time you would use these things. It would be on some new account in some new protocol,

[07:00] And so therefore there would be some other transaction on the account. Knew that zero wouldn't matter. So again, it's just to be precise, I don't think it really matters, but it's important to like say that it's something, just to make sure you know, everything is deterministic and fully specified. So I think that's pretty much all we needed to change right? Forget anything, lee. No, I think that was everything that we listed and I think specifically to do with, you know, the extension, like I'm really interested to hear what Nico, Siddharth, John, what you folks think of this and how this might impact core. Well, the first thing I'll say is you were the one who kind of just prototyped out this implementation, so what was your experience doing it? So I haven't tried the new change, so the diff. The difficulty that I definitely

[08:00] Hit with the initial proposal was that there are assumptions made in core that the sponsors, the v2 extension is only present when the account's involved in sponsorship and that shows up a lot in the tests, more than the actual application code. So I guess, if call makes that assumption in tests, are there any other products or anything else that makes that assumption, that might be interpreting XDR comes to mind. I think. Please continue. I think the new proposal which says that you know, the v2 is still only there when the sponsorship. I think that works from my perspective here, like I don't think it really matters that much. I don't think it's really worth fighting about much honestly, in the grand scheme of things, like I

[09:00] Could see some merits to this. Now that we have all these dangling things, maybe it would be nice to, every once in a while, you know, smash them all down into one single dangling thing, then dangle some more stuff off of it for a while, and then smush them all down again at a later date. Again. I can see merit to that, I think, in terms of like how core treats these things. Core, basically like the process that we've used for upgrading these extensions- is basically like there's like two parts to it, like one thing is like, once it comes to existence, will never unwind that. So like, if you sponsor an account and then remove the sponsorship, you'll still have the v2 extension. So the tests, most of them, have these assumptions about when will these things appear, and that's what you were running into, not about whether they will be there or not, period. The other thing is that we are kind, we already kind of made this executive decision when we added the sponsorship stuff, that like

[10:00] Imagine that you didn't have any native liabilities so you shouldn't have had a v1 extension, but then you participated in the sponsorship. Now you have a v2 extension and we just said like, okay, well in that case, we'll just inject the v1 extension and set it to zero, and it's no different from the case where you would add liabilities and then subsequently remove them. So from my perspective, like core is designed in such a way that, like, either solution is completely reasonable. I think, like in terms of the total net implementation changes, it would probably be less if we dangled it, but the size of the extension would be less if we didn't so like. So, just to be clear, you're okay with the current state. is like a right hybrid, right, where v3 includes v1 but dangles off v2, so that's kind of that, that's. There's basically this thing called sponsor info. That is a pointer to an account extension v2, but that's inside the account entry. Extension v3.

[11:00] Yeah, that would be fine. I mean again, like it doesn't really matter, but like if you're gonna do that, then the marginal additional cost of dangling the v3 extension off the v2 extension is even smaller because the four extra bytes are appearing in either case. So you're saying that there's no situation where it's important that the v2 be null, correct, okay, so well, anyway, I guess I don't. Really I don't care. What I really want is for [CAP-21](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0021.md) to make it in, so, like, what's the best structure to like make this happen, or is the current one? I mean, I think it's like I'm the one that always brings this back up, you know as soon as you. So you know, the current proposal, in a way, is kind of this weird hybrid thing. Like that is neither of the nested one neither the you know the fully like represented one. So I say like either we consider one or the other, but

[12:00] Not this kind of half broken one, because you get basically like the reason why you want nesting in the first place. That's kind of the whole rationale that we have in the repo actually, and why we are doing nesting is because it makes it easier for people to they don't have to change their code, right, like if you depend on, let's say, sponsorship, you keep referring to sponsorship. The same way, you don't have to add the non. You know conditions, like, oh, if it's a v3, I need to go look for sponsorship over there instead of over here, right, and so there's never, it's never going to be useful to take something that has sponsorship info and then delete the sponsorship info because, or to kind of create new accounts that just don't have any sponsorship info because they've never sponsored anything. That's the question. It sounded like lee kind of wanted this in order to make a lot of the tests easier to port. Oh well, does it act? There's not going to be easier. Hold on,

[13:00] Wait. Let me clarify something there. The v3 extension will always exist for a newly created account, right, that's right. But the sponsorship info might not, whereas like and it. So it sounded like currently there's a cal like in a lot of tests. There's like accounts that don't have sponsorship info and they think they never get upgraded to v2, and I don't know that this is somehow I don't know. Lee, do you want to? This is primarily. I did this primarily in response to your feedback, lee. So I don't know if you want to jump in, and yeah, so that there's two. So I think so far we've only really talked about the impact on core and it sounded like, from what John was saying, like there's not really a big impact on core and I think the concern that I had around the impact on tests is maybe misplaced, but the second impact is the impact on the ecosystem, which I think is what Niko was highlighting to- and that is, you know, everyone who passes this xtr will need to look for fields in the v1 and the v2, In two places they'll need to look for it either in the v1 or v2 or in v3 if we move it, and I think

[14:00] In V3, if we move it, and I think that's maybe something that eric well, like the Horizon team, would you know that's something that they would be having to deal with. Basically, anyone who passes the xtr has to know to look for it in all these different places, which can also be a little bit of a foot gun for people who are upgrading because they may not realize that this field has been duplicated into a new place. Yeah, although we can mechanically fix it with, like any place that gets translated to json, for example, we can just mechanically always move the sponsorship info out. Yeah, I don't think we should be making- any decisions based on the effects of downstream applications consuming ledger entries. Realistically, we're talking about one, maybe two consumers. So you know we can talk to them, okay. So I think that I mean, to my mind, the two things that make the most sense are to either keep the [CAP-21](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0021.md) draft exactly as is, or to flatten

[15:00] Out the sponsorship info the way it was in the previous revision of the draft. So it's just all one big like v3 structure. Wait, well, you're saying that. So I'm looking at the current master. Is that what you call the latest draft? Because this one is the hybrid one that has, like this half flattened version exactly, and so I'm saying either we just keep that or we should fully flatten it, just like, instead of having so no, but that's actually the one that doesn't make sense, the one that's half flattened. Either you're doing a nesting, fully nested right where you extend d3 inside v2- okay, or you're doing the full flattening- okay, and then let's do that. How about the full flattening? How about I just, instead of making that up, instead of making is having sponsor info be a pointer to like an account entry or account extension v2? How about I just take the fields of account entry v2 and make, put them in line inside the county account entry v3 or

[16:00] Just put the whole v2 structure in there? Yeah, I know I don't really care, honestly, flatten it or fully nest it, but yeah, the hybrid thing, I think is kind of like the worst of all the worlds. I propose that I will. So I propose to just basically revert to what it was before, if lee is okay with that, what was it before? Yesterday? It was nested before. No, it was flattened before. It was just the fields at the fields of v1 and v2 structures were just inside the v3 structure. Yeah, the things that I do think that flatten- every time we flatten structures it involves changes in a bunch of places that we may or may not understand, and I'd rather not do it if we can avoid it. So are you advocating for the nested version, foodie? Nested is kind of the as a default is safe

[17:00] Because we don't definitely require the fewest changes to core because we already have, well, not just score, but like, yeah, it's not just core, it's also right like the. You know anything out there that is actually using sponsor, like looking up sponsorship, let's say, so what about having them, not as pointers, but just putting the v1 and v2 structures into v3, so then any xtr library can just kind of extract those things by type. No, but it's the same problem. You have to switch, like you have to change your code that still compiles and still looks like it's working, but it will just fail miserably when you actually run into that like existing code. It's always the same problem. Right, kind of like the problem. We, you know, we created with the. What was it? The next accounts, right, like, but I would argue that like mux accounts is precisely because it's way worse. Mexican was way worse because

[18:00] Of course people use accounts a lot more right, but here we make it even more french. So that's kind of why, you know, if you're looking at like the edge case of the edge case and you hope that people are going to do the right thing, I think it's actually less likely, because I mean the problem is that the nested is just like much harder to program, to right. It's like you're literally like fighting with, like the right hand margin of your text editor all the time where it's like you have to put like line breaks in the middle of, like you know, expressions that contain dots and arrows to access fields. So it's just like you know we're getting the point that we're now we're gonna access fields that are, like you know, four or five or six deep in structures. It's just kind of like painful for the programmers. So what? So like yes, there might be like a little bit more stuff to do in transitional, though I would argue that actually, if, like, we do our xcr stuff right, it's actually not

[19:00] That hard because you can automate a lot of this stuff, and so I'd rather just have a little bit of pain up front and just have something that's like much nicer to program to in the long run. So when I wrote the prototype, I actually used the nested version. I didn't use the flattened version because it was easier to do an essence. I mean you put the account entry v3. You didn't use the security, put the account entry v3 inside the country v2. Yeah, I'm pretty sure that's what I did and it was. It wasn't that bad how wide. What's your? What's the width of your text editor? I mean I use softwrap. The thing is that, David, like the, if you want to have a helper function to avoid typing all this stuff, you can right like it's it. That helpful function is optional in the nested world. It's mandatory in the non nested world and we already have. All right, okay, whatever, I'm overruled like no, but

[20:00] That's gonna vote. You guys are all wrong, but I'll do it this way. I'll rewrite the CAP to do this. You know, generations of, like poor Stellar programmers are gonna have to be typing structures six nested deep because, like whatever, you guys are worried about a non existent problem. But fine, it's more important to get [CAP-21](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0021.md) accepted. So fine, it sounds like a reasonable concession. There we are going with the nested version in order to get [CAP-21](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0021.md) done. I like it. I think this raises interesting points, though, for the preconditions type that we're introducing, because the precondition type is setting itself up to be like a flattened version, or at least that's that was my understanding of the proposal- it would definitely work better. I mean like in the like. Five years from now, there will be no benefit, you know, there will be only disadvantages to doing what we're doing now, but like, yes, in the short run, it will be slightly smoother

[21:00] To do it with like a fully nested thing It's just like just how, when they were choosing, you know, not to fix the precedence of the bitwise and or operators, when they went from bcpl to c and introduced, like the logical double and double r, and they're like, well, you know, yeah, this is broken, but there's like hundreds of c programmers in the world like we don't want to, you know, break backwards compatibility and you know, then we got to the point that even java adopted those broken. Let's get back like I don't know I understand what you're saying, but at the same time, there is this like, there is this need to sort of get something out there that people can adopt and start using in order to well, I think there's really there's use cases that [CAP-21](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0021.md) allows. There's two problems here, I think one is I think people are like massively mistaken about. You know how hard it is to adapt to something where you have like multiple versions of the structure, right, and we already have an existence proof that we did it with something which much harder, which was the accounts, in order

[22:00] To get the most accounts right. So if we survive that, we can definitely survive this. The second thing is: I think people don't appreciate how much should be automated, because currently in our SDK we're doing too much sort of manual stuff. Right, and if you use sort of like more meta programming, friendly XDR libraries, like, say, you know, goxster, the one that I wrote, or the xdrpp that we're using for Stellar, you can actually automate a lot of this stuff. And so what would be great is that, since there's like the places where people actually care about this- probably, if they do it all- is when they're manipulating the json, and it's not- it would be easy to write just like a few simple rules to like make the json look the same, or to understand the json both ways. But you know what? I'm? Just beating a dead horse we'll. I'll just, you know, maybe a thing to do is like introduce a CAP, that's like a meta CAP, but like this is how we should do upgrades and show some evidence for why, in the future,

[23:00] It's better to actually version structures and put the versions at the top instead of putting these ext things at the bottom. But whatever. So general preconditions. I think that's what was it? Lee, it was yeah, asking about that. Yeah, sorry, I think in general, a, it's a misleading name. Yeah, I'm not really too fussed on the name, but I, I'm just not the. No, it's not the name but the. You know, right now it's hardcoded, not general. That's what I mean by. It's a lie. So I thought it was habit. You wanted to become like pre conditioned v1 or something like: what do you want? No, I would like make it an array of you know, static array or something. But we've already let's not relitigate that, I know we do. We already discussed this already. only introduced because. So actually they have a more of a question related to the CAP,

[24:00] Because what have been the time I spent, actually in the past few days was looking at the step that is, the payment channel protocol, trying to see, okay, like how is that set related really to the cap? And it doesn't look like the set is using all of the functionalities that are in the CAP. So that's kind of what you know where I'm coming from. It's like I feel like it's trying to guess on use cases that maybe don't exist and at the same time, I would prefer to grab something that's that can be extended easily as opposed to right now, because we can just version it right now. If you mention it, you break everybody. Even if we're doing the fully nested. There's no reason why we can't version the v3 thing that's dangling off the v2 right, like if you want to add a new condition, you would break all the all consumers. No, because you would just

[25:00] Have a data structure that includes: yeah, now you need to add access also, every single condition. No, you just need a function that always converts to the latest version. But that can be done in a, in an automated way. Could we just add a v2? Can we just add an extension on the end of the general precondition so that we can v2 it dangling? I mean we're going to have to if this thing is like we're totally bike shedding this thing, like and did someone else wanna make a pass at this? And then, like I'll clean up the mess, so that, like, because otherwise I'm gonna do something that, like you guys aren't going to like. I think it's worth just responding to Nico, what you said about. You know, the prototype channel protocol doesn't use all of the fields, the only field it doesn't use right now is ledger bounds. It uses everything else,

[26:00] And I think that was a comment or something that David and I talked about very briefly was it doesn't make sense to keep ledger bounds because of that. Why what is the argument for keeping electric bounds? The argument for keeping the ledger bounds is that the current payment channels are kind of probably safe enough, but they're not safe if there's, like you know, something happens and there's, like you know, an hour of downtime on the network or something which you know does actually happen periodically. So somebody who's paranoid and wants to make create a payment channel that is actually robust to downtime of the network would also need the ledger bounds to be safe. If right, because it never goes down, all your timers expire, but if you have this ledger bound thing, then you have. Since the network wasn't creating you ledgers while it was down,

[27:00] You still have some opportunity to, you know, get in there and prevent someone from incorrectly closing the channel. Personally, I'm like not really that concerned about changing the like. However, we struck for the preconditions like we could make it an array of you know, of whatever, of unions, and that would be fine, or we could make it a, it doesn't really matter honestly to me. I think, like, at the end of the day, like people are caring much more about writing these than reading them, like the only thing that really should be reading these at the end of the day is, you know, like, if you for some reason want to inspect something to make sure that you're signing the thing that you mean to be signing, which I think is like a very small subset of the code, because a lot of times you're assigning the transactions that you're creating yourself, in which case you kind of know what you're doing

[28:00] And core, and since, like this stuff is super isolated down to just like one code, path and core, and if you read the wrong branch and you're you know signing code, and then you're just not going to sign that transaction because you didn't know what it meant or your code didn't understand it. So like, I don't feel like the risk of blowing yourself up with edge cases here is particularly high. So like, let's not fight about it that much. Like we have unions on all sorts of stuff everywhere and we just kind of you know transactions for like, for example, I could send you a v0 transaction. If your code only knows how to handle v1 transactions, you're going to blow up. So like we already serious problems is, John, is your comment about whether or not we need ledger bounds? No, it's about like the whole, like Nico saying like these aren't really general. It's about that part. I personally. I think my point is kind of like the ludger band seemed reasonable to me. The structure is reasonable to me. We could do a different structure and it would also be reasonable to me. I don't see a lot of reason to hash it.

[29:00] I don't see a lot of reason to hash it out for 20 minutes. So I is just it. Could you, could we just change the name from general preconditions to something else? Yeah, I mean like if you named it like preconditions v1 or something that would map up with the names that we normally use. But like that sounds good, doesn't really matter to me, because if you didn't change it I would just stick. Like if you called in general preconditions, I would just like if I needed to change it later, I would just call it general preconditions of v2 and call today. So you know, can we add an extension as well? So that we just follow the same dangling pattern. I just don't see a lot of reason to is kind of my point here. Like if you can't handle the types of transactions you're trying to sign, you won't sign them and like, great, if you didn't sign something, then you didn't agree to something you didn't understand. So that's not that I mean The point is it's already in union, we've already got like no preconditions and time bounds right. So

[30:00] There's like, if it turns out that we need a different kind of preconditions, we can just add a you know a preconditions v2. Nobody can handle the v like the what is? It's the extension to like number two, like case number two, right now anyway, without modifying their code. So, like it's more about thinking about what happens when you change, when you make a v2 of that thing. Right, yeah, that's what you're saying. Though, like if let's say that I make, let's say that, like I add a new feature, which is, like I don't know, like time times ledger bound some super crazy stupid condition that nobody, no, how about number of ledgers that aren't completely flawless- number one, that's actually plausible- number of ledgers that aren't completely full. But like, if you want to sign this, you're only going to sign transaction. Like, if you want to sign stuff and you want to understand what you're signing, so you're checking for some condition. You're not going to sign stuff that you don't understand. So like your code might barf, but like you won't have signed something that you didn't understand, so it's fine.

[31:00] Like I don't understand what the bad, case if you don't understand something is, you're just not going to agree to something that, like I don't know, I don't. I don't think there's a bad case there. I think the case that I'm concerned with is the same case with that we were talking to about with the account extensions, and that is that every SDK, every application that pauses the XDR, now needs to look for time. Or now let's take a ledger bounce, so, say, ledger amount stays in the v1, then we add v2, ledger bounds is now going to be in two places, so it needs to look for it in both places. So there's the parsing case and then there's also the creation case for the transaction. So SDKs need to make a decision about you know what's the general best practice for creating a transaction that has ledger bounds. Do they use the new v2 that has ledger bounds, or do they use the new v1 or do they only use the v2 when they're using one of the new fields? And for the most part in a lot of cases, that probably won't matter. But in the cases where somebody builds a transaction and then they want to build that exact

[32:00] Same transaction and they want to expect the SDK to build it the same way, that does matter, because if an sk SDK developer decides they're just always going to use the latest version structure, then the transaction is going to change every time they build that same transaction. So we're actually in some ways we're actually introducing it backwards incompatibility, because we're saying, like you conceptually build the same transaction, but you know SDKs may make it so that you're actually building a different transaction. I see what you're getting at here and like that's a concern. I don't totally think that concern is necessarily exactly relevant here in the sense that like I don't know what promises SDKs are making, but like if an SDK is promising to have that property, that we're not going to retroactively change your stuff and that's really a property of the SDK. Because, like, if you're creating like a semantic transaction, I feel like the SDK just has a promise to do what it's

[33:00] What you asked it to do. But if you want to have a stronger constraint like an exact transaction, you probably need a different vocabulary in the SDK for that. But putting that all aside, like the thing that makes me scared about like doing the nesting in this context is like you really don't want to sign something that you don't understand. Like, imagine that you're a guy and you're like I'm looking for this ledger bound structure right, which I know to be in the case 2 extension, also known as general preconditions- but like, imagine we're dangling a v3 off of it. You have to actually like you can't just call a function to look up the v2 one and look out, look up the ledger numbers, because you actually have to check to make sure that the v3 stuff isn't there, because if it is there in nested, you're going to sign something that you didn't mean to sign. This is what I wrote in the code, example in the agenda. This is why it kind of explodes and becomes pretty awful. So as versions increment, you're going to get more and more of these to go

[34:00] Down the rabbit hole of checking. So I really think like the much safer thing- is to just fail to like, fail to sign things you don't understand and then update your code to understand them, instead of having to handle all these cases of like, oh like. What if the? What I need something that's in the v4 but the v3 doesn't like but the v3 exists, but I don't care about anything there. Maybe the v5 like. That gets really confusing and your code can change out from under you just as the extensions grow. Basically, and I think that there's another thing too, which is that if we were really trying to build this like little language of like, you know, have an array of little precondition operations that can be sort of like arbitrary or, you know, it can be constantly extended. Honestly, we then we should try to unify that with like the claimable balances- right, because we have like two different little languages for like preconditions, right? Or if we do have two different ones, then it just seems like really needlessly complex for people to like learn how to use this. So what we have is

[35:00] Simple. It is not, it doesn't have to be the last word because we can change it by again using these unions and it, you know it covers like all the things that we need to do: payment channels, plus the thing that we need if we want to do like super safe payment channels, which like there's, you know, some people like might want to be able like people could potentially object that you know well, on Ethereum, I can make it safer by counting ledgers or something that like this is like a good set, and that we shouldn't let the perfect be the enemy of the good. We just do this and if it turns out that it's like so successful that we want like 12 different other slight variations on the preconditions, then we can do a an array of a programmable thing. Or maybe we can update the claimable balances and have like a general language for describing preconditions. I'm pretty in sync with David on this one. Personally, I think the argument is basically just a lot different than the

[36:00] Ledger entry stuff where we, than the something established that we're already doing. So what would that mean? The next step is for [CAP-21](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0021.md), like what is the revision and who's sort of taking it on? I think the only thing we said we might change is to change general precondition to precondition v1 and that was it. That's it. And we would keep ledger bounds- wait. I thought we were also. We had to move to the extensions, these like multiple extensions. I think what John counted. I thought what John and you were advocating for was no extensions. I thought we were just talking about the preconditions, not the legendary extension. There's two questions, right. One is: should our preconditions be how to do future accessibility for the preconditions that are embedded in the transaction? And the other is

[37:00] What to do about the ledger entry extension part or the count entry extension part, right? So, John, I believe you and I were talking about just what goes in an actual transaction. The preconditions, right? Yeah, that's the thing that I think is really dangerous to have these accessor functions for that. Just like, look that don't necessarily look all the way down to the bottom, right and so, of course, while I'm happy to leave [CAP-21](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0021.md) and this is it sounded like we wanted, like it sounded like the everybody else wanted me to make, like these, to dangle accounting extension v3 off of account extension v2. Yes, yeah, sorry, I left that out at least. So I guess I can just do that. Fine, I'll change my stomach, but I'll do it and so that after that change we'll sort of reevaluate [CAP-21](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0021.md). Are there any other questions that we want to talk about [CAP-21](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0021.md) right now, or should we move on to [CAP-40](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0040.md).? I did have one other question about this.

[38:00] I did have one other question about this. There was like something that struck me as kind of strange: yeah, so there, actually I had there like three lines I pulled out and like all of them were basically about the exact same thing and I kept thinking that this was really weird. There's a sentence in the proposal that reads: all transactions are validated, sequence numbers increased and fees deducted before any operations are executed. One consequence is that bump sequence operations, though they update an account, seek time and seek ledger, do not affect the validity of other transactions in the same block. But that's actually not how things work at all right now. So this is like either a very profound change to the way that things work. That we'd have to recognize is a really big change, even though I don't think people are using bump seek a lot or it's a misunderstanding of the current situation. Sorry, the audio is breaking up,

[39:00] Sorry, what's the line number or what can I search for, because you broke up when you're saying which, yeah, let me just tell you what to search for. If you search for, one consequence is that'll probably work. Let me see if that works. Okay, yeah, I often find myself searching for one consequences, right, but that actually is what happens currently. Right, bump sequence happens when you're executing operations. It doesn't happen when you're validating operations, correct, but, like, let's imagine that you have one source account. You submit transactions t1 and t2 at sequence numbers. You know n plus one and n plus two. You get the point and the behavior: like both of them are no ops, they contain like zero. Sorry, I don't know if David can hear me at all. Right now, no, I can't. But

[40:00] Oh crap, hopefully I'm on summer when, like, I can't, I couldn't do this meeting, but I want to. move forward. So you have, okay, where's the chat? Let's take this one to the mailing list. I think, yeah, and I want to point something out that doesn't actually impact the behavior of the bump sequence. The payment channels are not actually

[41:00] Dependent on that. So I think that what that breaks is that it breaks that right now you can have transactions that fail later because of that sequence number, exactly like, as you can imagine, you have to go on the mainland list. At this point, you're bound from this call. There's no chat, David, not a new chat. That I see at least. So, yeah, there's not a ch, there's not a chat in this interface. One does not simply chat during the protocol committee meeting. Yeah, it sounds like he can hear it. So, yeah, the concern is that you have two transactions, first transaction and sequence number, you know nn plus one, and then the first one does a bump sec to n plus ten, this invalidates the second one that will fail with a bad sequence number. But that will only happen at applied, you know, like when you actually

[42:00] Apply transactions. And the proposed change would actually break that if you are changing, because it would allow both transactions to execute exactly if the second one has like some funny, you know, side effects in the proposal. Now those side effects can actually happen and there are like some pretty important consequences to another sentence in the proposal, which is that earlier in the proposal there's a two sentences that read: a transaction whose preconditions are not satisfied is invalid and must not execute, even to fail, meaning it cannot change the source, account sequence number or charge a fee. But basically the example we just gave, you could imagine a like a seek gap thing- min c, mint c gap and seek age, whatever you guys know what I'm talking about-

[43:00] And that would be broken by the current bump seek semantics because it would actually write it during the apply time and then the later one would be invalid at apply time and therefore fail. So yeah, there's probably some like edge cases here that we have to iron out either we have to say that these work in a different way from other stuff, or, yeah, I'm not super sure you'll not allow. I think I thought what we talked about before was maybe not allowing more than one, so like that source account can only be in one transaction. But that's not necessarily easy. Well, I know it's not, but that's the only way you can make this work, I think. But you know, maybe there's a better. I'm that's, I think, the only way, but that might be other one, another one, not that people can figure out, but it sounds like this is something that will bear further thought,

[44:00] Like it will require further thought to sort of figure out what's the best solution here, and so I think this is something that someone- maybe John, if you should raise on the mailing list. Yeah, I'll send me an email about it, or something. Call me, by any chance. I don't actually. No, David, you have solar flares or something like I'm on a amount of crap you might find out, but like this is like super important. Or can we have this meeting next week or something. I knew this was like a bad week, for this is like the week that I wasn't gonna have a wired interest. David didn't predict that. It's true. Did yes, I apologize for trying to force it forward, but I mean we can. Certainly this is super important stuff that we're talking about now. So there's no way. Zoom usually allows you to like call and how and get in by phone, but when I click the thing, it doesn't give me a

[45:00] Phone number. The crazy thing is I can hear everything you're saying now. So maybe just tell us what you want to say. Okay, what I was gonna say is: if you have transaction n plus one, and n is a bump sequence to like, say, n plus two, both can currently execute. Yes, they will both execute, but no, currently, yeah, guarantee, the second one fails exactly. How does it feel? So you've actually executed the bump sequence when you're validating transactions sequence. Suppose transaction n like changes the signer or something, right, you're still charging a fee for transaction two, right, but it fails exactly. Yeah, it fails. So what I'm like what kind of ends up happening is like any check that we run during validity checking also gets run during

[46:00] Transaction application. So basically, you get all your validity checks get done twice, once kind of speculatively and once for real, for real- and if it fails the validity check that it does again during application, it fails at application, it's on the ledger, it's charged a fee and the sequence number is consumed. Yeah, okay. So what about this? What about saying like: these preconditions always get checked twice. If it passes the first time, you get charged the fee. If you get, if it passes a second time, you then can execute. That that's fine. That would basically map up what we're saying. But the question is like: does that break your stuff? No, I mean it's a little more expensive, but it's like, well, the age thing. That's what John was talking about, right? Yeah, I don't know if you were able to hear me at that point. But, like this, would this potentially messes up the seek age or seek gap? I can't remember. So maybe we check the age things only

[47:00] Once in the other fields twice and we like rearrange the data structure if it needs to be such that it's very obvious which section is the stuff that gets checked once and which section gets checked twice. In all honesty, like there could be some sanity to basically saying like hey, like these, preconcept, precondition things, we only need to check them once. But you're saying that this would currently allow things to succeed where currently they fail. Well, right now the preconditions aren't anything that can be that can change. State like: time is time, it's all checked against the close time, so it shouldn't matter. But yeah, they can't. Yeah, the thing is that right now we don't have a concept of checks that are done at apply time, before, like while we do, like the fee processing, for example, like we don't

[48:00] Have that kind of concept- which is, I think, what we're talking about- like a phase, that is, like let's do all those checks that are like on the you know, the, only done once per block before anything else happens. That would actually be really easy to implement, like a bed, that would be easy, but that doesn't exist today. Right, agreed, yeah, and I think I wonder if it would do something funny also in terms of like results. Oh yeah, there'd probably be some annoying cases to handle there, but like, because we don't have a place right now to express that there would be a failure in that phase for like, for Horizon. I'm thinking like the mirror doesn't let you fail early, like that hold on, wait. Do we really not like early, like it doesn't there's, like it

[49:00] Applies at apply time, you get the results, but you don't. You wouldn't know that it's a failure that happened because of a, an early check. There's something kind of interesting going on here, though, like I guess the real point would be: like these precondition checks are something that should be done at validation time but not at apply time, because if they succeeded at validation time, I guess you're right, yeah, that could also be the. That could be the change, right? The new, like the updated thing, is that we have certain checks that are only done at validation time. Yeah, I bet that could be useful for other reasons. So I mean the problem. The annoying thing is that, okay, well, one thing I mean it wouldn't be. I mean, like, arguably, the behavior that I'm describing here is not like terrible, it's just, unfortunately, like a slightly more permissive than what we currently do. It might not

[50:00] Be inherently fatal, so David, one of the things that's actually annoying to do those checks at validation time only is that we're supposed to have a. as I don't. We're supposed to have a as more or less as an invariant that those checks don't depend on. Let's just state, I mean, like they only depend on sequence number. I guess, right, but you're still, literally, you're loading the account entry, right. Yeah, that's the only thing. But, like, if we wanted to have, like maybe other dependencies there, like in terms of checks, I guess you could. Everything depends on either the ledger header or the ledger entry. There's nothing. You don't need to fetch any, you know right, cross lines or any other kind of state. So I think that we should still be okay in terms of no extra database accesses.

[51:00] I don't think that's a big issue. I think this is something we can handle in a sane way. I think it's just something I think I just think about, let me just like address it like I can make a pass of this and I can propose something that is both compatible with what we're doing today and has kind of the least overhead, like avoids double checking. If it's sane to do so, I have to think it. If it's sane to do so. I have to think it through a little bit more, but I could have you know something by next week or next week. I could do something, but I mean that feels like the logical next step to capturing one to me. Yeah, okay, so I have to address this and I have to address the nested ext structures and I think, yeah, like with this new condition, like one of the like I guess that paragraph or whatever section in the CAP will be where you can talk about

[52:00] If we have, like specific rules around multiple transactions that maybe you want to like, where you want to allow, you know, like certain combinations, like what I'm thinking here is that if you have two transactions with this min age requirement, because otherwise you're going to break the payment channel, like the you know the assumption that you have a grace period every time you process a transaction for the payment channel protocol, that's a good point also, well, okay, I will, I think that's good, that's a good change. I think we're going to highlight this specific environment that we're going to go after here. That's the same environment that we need for the transaction queue policy, exactly, okay, so I think I need. Is there anything?

[53:00] Okay, so I think I need. Is there anything else? Because I want to make sure we discuss [CAP-40](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0040.md). No, I think we should move on to count 40. I mean, there's only four minutes left. So let's jump to [CAP-40](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0040.md), because I feel like there's a clear path. With [CAP-21](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0021.md), [CAP-40](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0040.md). What is the? Let me see that, So [CAP-40](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0040.md). Just trying to find myself. So, for anyone who's watching, this proposal allows participants in a payment channel to safely exchange signatures for a set of up to three transactions in a single step. It looks like there are some open questions- several, but we don't have time, that much time. So what is the most important question that you need answered here, lee? So I think I guess the question I've been most interested in is Nico raised. You know, is this the right structure? Are there other things, like local trees, that we could be using? And then maybe I

[54:00] Can add a little more detail on: I mean, I have that on the mailing list, right, like that the question there is really. So I looked at so the proposal. I think makes sense with the current proposal of payment channels, because you only have like a very small set of participants. If you are looking at what you would need, if you have more participants, or maybe it's like those multi hop things or whatever, would that make this like insufficient? And then you need at that point, like some way of expressing a bigger set, like a miracle tree, maybe I don't know something else. I mean I think that what we have now is so general, like, yes, you can't do merkel trees, but you can like interoperate with, like Ethereum or like other blockchains, like it's. So not only does it like save entire round trips and like eliminate a whole bunch of foot

[55:00] Guns on these payment channel protocols. But it also, like in such a straightforward way, adds support for essentially we can basically do htlc's with other blockchains without even the hash part right, like you can literally like just kind of tie transactions together across blockchains. So from my point of view, this is just like completely obvious in retrospect. Except, you know, obviously it's brilliant because, like nobody thought of it until now. But like this, like it's just, it's so straightforwardly, like exactly what you want in so many situations where it's like I want this texture only if this executes. Fine, if you execute this, then sign the other thing right and it's like we're done right. So it's so simple and so useful. I also had like a very similar reaction to this when we suggested I was like oh, that's very clever. No, like no, I mean I agree. Like I think it makes total sense for the, for what we're trying to do right now is it's more the question for me: is that going to be durable

[56:00] For, in terms of design for the payment channel, because I know, for example, in lightning, oh, I think it didn't go that far because, no, but like for in the context of payment channels, they didn't do that with lightning. In lightning, for example, because they need a lot more to unlock a lot more transactions with one transaction. No, I think, honestly, I think they just didn't think of it right, because you could just say, if you have a three hop, like lightning payment, you could just like have to sign, you know all three hops in order to cash it in, yeah, but so you need three. Yeah, you need. This transaction needs to have three additional payloads, right, sure, so that's why this doesn't scale. That's the part where it doesn't scale. So that's my question. Let me ask you a question, Nico. Like sometimes there exists a world where it makes sense to have something that's like simple and easy to use but not necessarily scalable, and something that's harder to use but highly scalable, I feel.

[57:00] Harder to use but highly scalable. I feel like the merkle tree falls into that category of like. It's obviously much more scalable, but it's also not as easy, friend, user friendly and not as easy to fit into like the current Stellar model. So like, well, maybe a miracle tree of one element, is the same thing, right, that's kind of what. Maybe, I don't know, that's a. It's more like a if the design relies heavily on such a construct. I'm more questioning the design of the payment channel. But, honestly, you could do the merkle tree. It's just the merkle tree would have to be on the Ethereum side, right, but like. But you know, obviously we don't have like logic to interpret merkle trees. But the point is like, because you're signing arbitrary data, right, you could do something such that, like a single payment on Stellar, could like unlock like 20, you know, USDC payments on Ethereum, right, and do some kind of complicated multi way exchange that way,

[58:00] David, if we like, let's. So your point is well taken that if the merkle tree part was on the Ethereum side. Perhaps this would work there. So is the argument you're making that the construct that lee proposes is sufficient for the merkle tree case, assuming that Stellar could also handle the merkle trees, or is the payload not big enough? or you know whatever I mean. You know, to be honest, the things that the cases that I think come to mind involve multiple signers rather than signatures on multiple transactions. Right, because you could always on Stellar, you know we have a different way of unlocking transactions, which is like twiddle sequence numbers and use like the or the and use preconditions. So from my point of view, the real bottleneck here is that, just like, I don't want to add like

[59:00] A gazillion signatures just because verification is expensive, right, so if we somehow change the transaction fees to like also include the number of signature verifications or something like, I could see like there's a very obvious way to extend this to have like more than two, more than one or two signatures, well, actually. So actually that's related to, yeah, that question on number of signature verifications. Actually, that's sorry, I missed that as part of the capturing in one conversation because you know, you guys added this: the extra sign at the same time, then kat von d and I didn't d, was not sure on which CAP was tracking, I know what one thing we could do, because in the context of [CAP-40](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0040.md), it's just another sign. I mean the x ray signature. It doesn't matter actually, because it's being processed like any other signature, right, but we don't charge for signatures, do? We thought we just charged for operation but for so, yeah. So now, going back,

[01:00:00] Though on to [CAP-21](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0021.md), but how it's being, used in a new way, right, that is, you can have, like those, is it two or three additional signature checks. I would argue that those should be counted towards the 20 signatures limit that we have on a transaction. Okay, that's fine, right, because that way we don't have to change the model in terms of like fees or anything, because right now it's, I mean, if we are going with the. Did you see what I mean? Like I think it gets too complicated. Done right, and that's a quick [CAP-21](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0021.md) change, because [CAP-40](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0040.md) just introduces the concept of this new type of- yeah, of cyano. I also want to say we're over time. So I think we're going to have to cut this, but I do. I mean I feel like with [CAP-21](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0021.md), there's a clear path forward and it's that David is going to make those two revisions with [CAP-40](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0040.md). Is there an easy next step that we can take here

[01:01:00] Just to keep this moving, keep pushing? Is there a discussion that we need to have, either synchronously later or async, on the Stellar dev list about this question? I think we should move to accept [CAP-40](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0040.md) today. Yeah, I feel like the argument about you know, would it be better if it's a merkle tree. This is a little bit like one or both. You know this is very simple and it does. It's, you know, only really useful in specific constrained cases, like the payload has to be below a certain size, that there's a lot of constraints. And so if the constraints are a match, this is a great use. And then if the constraints aren't, and we have use cases that need that are outside those constraints, then maybe we need some other type of signer, like a mogul tree signer. And then you know, with that sign, like comes a whole lot of costs and things we have to figure out bigger problems to solve.

[01:02:00] I mean like the only reason I would say it should not be accepted yet is because we don't like it doesn't make sense to have kept fully in the abstract. It's actually in the context of [CAP-21](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0021.md). Actually it does make sense in the abstract. The same way we have hashtag signers. It's just like a better baby, like who is going to use that. Anybody who wants to like tie multiple. But who is this? Anybody? My point is that CAPs- what we have in the- you know, in the description of a cap- is that you have to have the use case before we actually go and spend the work on implementing those things. So you're advocating for holding off on accepting count 40 until yeah, I mean it looks fine, right, like from what we're saying, it's fine. It's more of a like we're not going to spend time implementing it, if you know, if we don't have the full story, but so we could just make a soft sort of promise. Okay, we're planning to accept, yeah, this one is like right after we

[01:03:00] Accept [CAP-21](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0021.md). We're looking good, yeah, so ideally, our next protocol meeting, whatever that is, we can accept both [CAP-21](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0021.md), exactly. Yeah, I'd rather do that than try to do this piecemeal thing, because the point of all this is like to get something that makes sense for payment channels? Yeah, sure, but I do think [CAP-40](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0040.md) is just. It's so simple and it has so many additional uses. It's just like a fantastic thing in and of itself. But actually, one thing I would love to see in the [CAP-40](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0040.md) proposal would be a use case for [CAP-40](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0040.md) that doesn't depend on [CAP-21](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0021.md). That would be cool. I would like that. Lee, can you add like an Ethereum, like swap, sure, okay, so that's all that [CAP-40](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0040.md) will. That's like, basically, the requirement for [CAP-40](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0040.md). Is lee's going to add a use case that doesn't reply, require [CAP-21](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0021.md)? Rely on caption one? The goal for next time is to review the changes that David makes to

[01:04:00] [CAP-21](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0021.md), ideally to get [CAP-21](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0021.md) shortly followed by [CAP-40](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0040.md) accepted. Cool, I think. Anything else we'll just look to the Stellar dead mailing list and everyone here. Thank you so much for joining, thanks for your time, thanks for thinking this through. Anyone out there who's watching. Thank you so much. You know it's always great to have you here and feel free to join that dev mailing list if you want to see these discussions and participate in them yourselves. There's a link to it in the show description. All right, sorry we ran over everybody, but thanks again for your time.

</details>
