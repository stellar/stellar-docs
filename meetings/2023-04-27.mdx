---
title: "Soroban Design Discussion"
authors: [kalepail]
tags: [soroban]
---

import YouTube from "@site/src/components/YouTube";

<YouTube ID="Mgx3CM0X8dk" />

Soroban is a smart contracts platform designed with purpose and built to perform.

<details>
  <summary>Video Transcript</summary>

[00:00] Good morning everyone or good afternoon or evening wherever you are this is the Soroban Design Discussion in, which we discuss topics related to the Stellar protocol and specifically Soroban Soroban and today we're going to keep talking about State expiration. So without further Ado I'm just going to hand it over to Garand yeah. So last time we talked about temporary entries. And so today I'd like to continue, that conversation kind of the two biggest topics last time were these temporary entries of these are entries, that have some sort of Lifetime and are automatically deleted after, that lifetime previously we're talking about well in this lifetime should be an arbitrary Ledger and. If we should allow users to Define an arbitrary Ledger or TTL. And then the second issue was whether we should allow users to extend this TTL and correct me. If I'm wrong. But at least my takeaways from, that conversation last week with

[01:00] that extending TTL was definitely a required feature and, that there seem to be some confusion around the interface whereas like the temporary entries how like this TTL you know Ledger sort of talk or as the restorable entries have this you know rent balance rent fee sort of interface. And so today I'd like to talk about addressing those two issues. And then be working the temporary entry interface to hopefully combine the interfaces and to have like a unified front-on storage. And so as far as ttls, that are specific in the arbitrary ledgers I think we decided to go against, that I think the use case for, that was primarily for security reasons say. If you have like a temporary allowance, that you want to exist for only 10 ledgers no more no less I've been an exact TTL to accomplish, that I think. However from a protocol standpoint, that's probably a little bit of an over specification to a specific security use case and also having those specific ttls definitely

[02:00] degrades Downstream system performance. When it comes to things like Horizon and RPC. And so I think for, that particular use case it's very easy to implement on the e-smart contacts themselves just to include an exploration Ledger and the strength to actually store. Then the entry. But as far as like a specific guaranteed TTL expiration Ledger, that seems to be outside the scope of the storage protocol. But with, that in mind I think it seemed, that just based on the community comments, that temporary entries required a lower bound, that was strict strict. But the upper bound didn't really matter, that much. And so and. Because the lower ground, that is like the minimum lifetime is kind of what's more important here what I've tried to do is to unify the two interfaces and have both temporary entries and restorable entries have the same type of fee structure and have the same type of rent balance structure. And so essentially what this interface would do is both

[03:00] temporary entries and restorable entries you must pay rent now, that works from a user perspective is, that whenever you create either a temporary entry or a restorable entry you can Define the starting Lifetime. And so what we'll do is in the SDK will expose these as flags. And so you could have like short medium and long lifetime or a short lifetime is very short on the scale of like you know 50 events for less than an hour medium lifetime is like you know on the scale of several days less than a week and the long lifetime is about 30 days. And so this time gives a flexibility for the temporary entries as to. If you have like Oracle data, that's very short-lived you can use short lifetime or. If you have something longer lived, that you don't care. If it's still needed and you don't care. If it goes to the archive. When it runs out of rent. Then you can do the meat for long term rent payments. Now what this does is the short medium and long term gives you a

[04:00] stripped lower bound. And so we can offer the guarantee, that. If the short lifetime says it'll last 15 minutes, that entry will last at least 15 minutes or you know The Ledger equivalent now. Because the Run feed is variable it's possible, that the entry will live exactly as long as we guarantee it will or it could also live longer than, that. And so I think for temporary entries. If there's a security use case where you want to expire after some amount of time and not a cost saving use case then, that needs to be implemented on the smart contract side. Now in addition to this initial rent balance, that you can specify via these Flags temporary entries are identical to restorable entries with terms of rent bumps and the rent payment interface what, that means is, that temporary entries receive a small incremental red bump on every access, which means, that. If a temporary entry is frequently accessed. Then it will live for longer than slower bound and so. If you can imagine like the

[05:00] most extreme example you could create a temporary entry with the minimum you know balance or the minimum rent balance of say like 15 minutes worth of rent but. If that ledger for, that entry is very very frequently accessed in those 15 minutes and it could last for hours days possibly even months. And so this is one of the other side effects of this rent balance feature. But just based on community feedback it's seen, that the lower bound was important to the upper bound less. So this also unifies the interfaces additionally in addition to the automatic Grant bumps on temporary entries you can also do manual wrap bumps on the same way you can storeable entries so. If a user is motivated to have a specific temporary entry last for a long time they can pay you the rent fees and do, that manually via an operation. If they want. But now as far as any cost structure. Because temporary entries are self-deliving we want to incentivize them. And so there seem to be issues with

[06:00] kind of a archivable fee or like a of a some sort of Base fee for restorable entries. And so I think with this unified interface since both are subject to rent both restorable and temporary entries what makes the most sense is, that for temporary entries to be charged at a slightly lower rate. So for instance you know these aren't the real numbers. But just. If a restorable entry would be charged one excellent per Ledger the exact same size entry, that is a temporary entry would only be charged 0.8 XLM per Ledger or something like, that. And so in this way. Because we essentially have a lower rent fee or we can incentivize using temporary entries and kind of put all as much traffic towards the temporary entries as possible. And so I think generally speaking just you know first thoughts on this unified interface and having this sort of like rent balance feature built into the temporary entries

[07:00] yeah there's one thing, that I find a bit weird about bumping temporary entries I feel like the the product story doesn't really add up in a lot of ways. So let's say for example, that an oracle is creating like a one hour you know like a price, that's like available for one hour like why should cons and and from their perspective it is in fact only relevant for one hour. But now consumers are actually going to bump, that ledger entry to live beyond its intended lifetime yes. So this is one of the open questions I wanted to discuss is, that for I think like. If you're going to do like a Oracle for instance where the information is only valid

[08:00] for five minutes and useless beyond, that. Then temporary rent bumps don't make sense sense. But then there are other use cases I think someone gave an example like a CK snark snark used to verify some value, that. If you're continually using, that CK snark it does seem advantageous for, that proof information to remain unchain as long as you're using it. And so I guess the question here is you know do we want to have a universal policy for either temporary entries are always bumped or never bumped or who have some sort of conditional policy like we have an additional flag on the temporary entry, that says this entry type is subject to automatic Bunch or this entry type is not subject to automatic bumps you know, that provides some granularity. But it may also you know complicate the interface a little bit more yeah I still didn't quite understand this example maybe, that's. Because I haven't attended the previous design discussion discussion. But I really don't quite understand

[09:00] why the temperature should be used for this use case in the first place. If you are interested in certain behavior and. If it is expensive to recreate this entry from scratch. Then the question is why is this not a restorable entry in the first place and in general in weeks away you've been describing it would it be a correct statement to say, that with this proposal temp entries and the only difference between temp entries and recoverable entries as well whether they go to the archive or see tone. So it kind of seems like a bit redundant to have to very similar things, that have only some first first maybe we should try to either consolidate this or have a more well-defined use cases. Because like the reason I was always advocating for no bumps on the temperatures. Because they use skates for them is kind of different

[10:00] and it's something, that you know you want to persist for a short period of time and you don't really care about being kived or pumped and you. If you need more complex behaviors and you probably are interested in interested archived and can be restored yeah I think they disagree just. Because I think, that there's kind of like two use cases we're targeting here I think like in the Oracle case you have very short-term data like five minutes, that's kind of what we were targeting the initial temporary entry Proposal with like a you know details, that never change change. But beyond the Oracle use case I think there is a strong motivation or at least the network should have a strong motivation two prioritive times using storage, that's self-deleting just. Because the archive is not a black hole, that we can just throw entries into right like. If you know every single entry type, that's beyond you know the most basic Oracle data needs to be a restorable

[11:00] entry, that gets to be archived you know having entries thrown the archive as soon as fast having them store on The Ledger but, that's still an issue and still still, that you know, that will have issues of scale later on. And so I think. If we can do anything to prioritize using data, that doesn't have to be persistently stored forever and ever we should definitely do, that. And so I think in this particular kind of use cases, that we still offer, that very short lifetime expectation for things like oracles without like 10 or 15 minute very cheap very inexpensive entry type. But we also provide flexibility for say an entry, that is used longer term but, that's not sensitive enough to be put in the archive right. And so I think the archive should only really be used for entry types, that can't be recreated I think kind of demome you said is. If an entry type is expensive to recreate. Then why not use a restorable entry we shouldn't prioritize or we

[12:00] shouldn't incentivize, that behavior I think. If an entry is restorable at all then, that should be or is a non-resortable sorry. If an entry type is recreatable at all even. If it's a expensive Recreation we should do everything we can perhaps to prioritize, that in the temporary entry space. Because having a you know an entry, that is arbitrarily recreatable get deleted. And then get recreated on the network is significantly healthier for network scale than having Visio entry type, that is arbitrarily creatable. But for some cost saving whatever it gets thrown in the archive I think the archetype should really only be reserved for security sensitive things. And then for things like balances, that can't be recreating, that you need to have you know a true definition of oh. But what is your developer's story for this week how how do you communicate. Because like it kind of sounds nice in theory. But not sure how this can be enforced I don't think

[13:00] it can be right and there is all Second Street Street well like you cannot make people to create certain sorts of hinges and this thing is. If you know. If I think my entry and it's kind of important to me and they want to maybe recover it it'll it's recoverable entry even. So maybe I shouldn't have it's not clear how can we communicate this clearly like our stretch there is already already pretty complicated complicated and also it's really. But the temperature is like the thing is, that automatic bumps do not provide any guarantees as to how long doses since these to like you know. If you have some proof or whatever you know you cannot reasonably predict, that even. If someone accesses it it will pull on the lifetime of the century enough for it to be useful in other contexts and I

[14:00] I I I'm just not sure how how can he put any expectations on the temp entry pumps. Because well the entry will be gone sooner or later and it's very hard to argue, that you know fuel exists any given period of time beyond the overbound. So I I'm just not sure how would you communicate it and why users won't just use recoverable entries entries whenever they can like like in the context of those oracles I mean I like oracles are like they're going to refresh the you know like the the actual entry. So I think it makes total sense to have this autographed feature like unless you have like abandoned entries like an oracle you know, that basically is creating a thing, that is only for valid for like five minutes. And then for the day right and, that's it. And then you

[15:00] have to catch it. When you can and in, that situation the contract the the this Oracle contract should not it should actually be written with the like the actual exploration baked into it like the the pattern, that was you know in the dark at some point, that was like you know you look at the expiration time and. If it's past the five minutes or whatever you want it to keep it. Then you actually delete it. And then you don't have those problems yeah and to answer your questions email about why would someone use temporary is not restorable just cheaper right. Because I think you know generally speaking speaking you know a efficient market hypothesis let's say, that smart contracts or sophisticated smart contracts are actually used will use the cheapest print as possible or at least a good developer would. And so I think just by having this financial incentive for temporary entries we kind of solve the use case issue and sure. If someone wants to you know just say I

[16:00] don't want to worry about oh my data is important I only use restorable entries, that's fine. But they have to pay for it. And so I think having, that Financial incentive and trying to de-incentivize restorable entries. Because from a network Health perspective we want to de-incentivize de-incentivize you know restorable entries as much as possible. And so I think having this more General and unified temporary storage interface does, that in a much better way than a a separate TTL based approach would I'd like to comment on this from the perspective of developer experience. So this is maybe less to do with incentivizing users to go to choose one or the over the other or or the implementation details of how easy it's going to be for consumers to you know to access this data. But I think you know this unified interface where the only difference between a temp and recoverable storage type type. If I'm understanding this correctly it

[17:00] will lead to you know whether it's restorable or not from the arc whether it's put in the archive or not. When it times out I think, that's going to lead to a better developer experience and lead to develops making better decisions about, which to use. Because we're simplifying the decision process you know by by making, that the only difference functionally about what happens with the data you know we're just making the decision process. So much simpler for them. Because a developer just needs to answer the question do I need this to go to the archive or not and. If they can they answer, that with you know yes or no. And then they make the decision and they move on. When these storage types contain other differences you know suddenly developers have got like this Matrix of features and attributes, that they're needing to decide between and you know, that that can really lead to more complex thinking more you know maybe making the wrong decision. Because somebody thought they needed this this feature

[18:00] from a recoverable type. But but they didn't really need it. So yeah I think this is good yeah I think I'm kind of like what I'm envisioning is the end story to be is, that we just have a unified storage class I think a previous proposal. So we have to separate you know temporary and restorable storage classes. But this would have a single storage class and. When you create an entry you know there's three parameters you specify the lifetime a short meeting long this is the initial Lifetime. And then you specify the type Vision temporary or you can get used to intercepts change. But temporary like a recreatable and unique or something like, that I think just having, that single story is is a significantly better experience. But I think we can talk more to this I think what we're doing is we're narrowing the decision like the decision tree, that somebody needs to go through

[19:00] like were you basically saying to them you just need to decide. So what, that type is and it has like a much narrow impact on on what the result is Lee were you arguing for or against I'm arguing for it. If I suspect maybe I'm misunderstanding something with your question timer maybe I can just try to make sure I understand what you're saying Garen. So the only difference, that the selecting, that type is gonna going to like all of these types are going to have support TTL is, that right well. So under the hood there's not a real TTL essentially there's a rent balance

[20:00] which is detected from. But the way we have to do this. Because run fees variable. So the actual interface will be like you have like a rent balance of XLM, that's deducted from from a variable rent fee. But the interface exposed is on ledgers. So essentially everything will have a TTL. Now you have you can have guarantees at creation time. So the reason why we picked you know 15 minutes seven days and 30 days as our creation times is. Because 30 days is the maximal amount, that we can guarantee past, that there's no guarantees. Because the rental fee can change. But having those I think three initial values is guarantees. Now I think 30 days plenty of days to create the entry and then. If you decide, that you want to last for like six years. Then you can do like a manual. Then bump, that. And so I think those those starting values are reasonable

[21:00] stuff in the chat. If you want to talk about the Oracle issue yeah it's I'm still talking about what I said before, which is I think the yeah like you know let's be clear about this the main reason we're we're working on temporary storage is. Because we've had discussions internal discussions with some of the like the big Oracle projects out there and this is something, that they've expressed a Desiring Desiring and I think, that we're. Now trying to generalize for things. But I think specifically the Autobahn doesn't really sit well with me for for Oracle data. Because the Oracle will probably limit the the amount of time something is relevant for artificially. If it's. If they can't

[22:00] do, that within the storage parameters. And then effectively people are going to like you're like bumping an entry into Oblivion like you know like I'm accessing at 4 pm a value, that should be dead by 5 PM and, that's enforced by the contract. So people like keep enforcing it to theoretically live it you know six or seven PM. But at 5 PM the the access is cut cut. So it's like bumping to nowhere and, that's and, that seems to be what we want to do. So I guess there's two solutions I see of this first off like the contract can just you know be smart about this and say. If you access this entry and it's past its expiration date delete entry. So you don't bump into Oblivion also from just a a practicality standpoint we do Define a maximum rent balance for automatic bumps to avoid issues like this where like an entry is

[23:00] used frequently initially. And then never used again. So it has like this essentially infinite balance, that never runs out of. So there is a maximum. So you can't bump it into Oblivion one possible solution is I think for you know medium and long term you know lifetimes, that's like the the lifetime measured in days and weeks. Then I think our Mac bombs make sense. But we could also just special case the short-term life this is like the one hour life frame time and just saying hey one hour lifetimes it's supposed to be super ephemeral this doesn't get automatic bumps. But the other types do I think, that's going to be fine from a developer standpoint. Because we already have to special case on the short lifetime. Because just doing the win bucket list is structured restorable entry types can't live.short they must live at least to the medium Lifetime. And so we already throw an error. If you have like a short Lifetime with a you know again we have to figure out the SDK. But essentially you know restorable entry

[24:00] types can have a short Lifetime. And so I think it would be reasonable to have almost unified interface and still have you temporary entries with medium long terms Autobahn they just have like the very very short term not out of bump tone with this satisfies your Oracle taste maybe I'm just concerned about having like like yeah different exceptions and rules based on you know things like like the lifetime of a ledger entry yeah you think about it some more well I think what we I think the protocol protocol should should. Because the way the vocalists are structured it's very negative for performance. If the protocol enables a specific boundaries. And so I

[25:00] think. If we just essentially build into the protocol, that there are boundaries. But they're fuzzy boundaries and. If the oracles can accept, that I think, that's a significantly better compromise. So it might not be exactly what the oracles were imagining but. If we can get close enough and unify the interface and not distort Downstream systems I would be heavily in favor of, that or you're describing Aaron, that that fuzzy boundary, that's just. If folks want to use the fuzzy band like, that feature of the system can still code logic into a contract such, that a ledger entry stores value, that's, that's a more granular TTL. If they really need, that right correct yes. So there's there's nothing stopping someone from building something, that's less we're just basically saying you know. If you can exploit this capability of the system you don't have to write. So much code your contract will probably a little bit more efficient Etc

[26:00] yeah and the biggest thing is also fees. Because this is like way cheaper like the short like a temporary entry within a short lifetime will be like way way cheaper than all the other storage types. And so from a financial perspective you know even. If the oracles have to do like this like check the TTL automatic deletion it's still significantly cheaper than using any other storage type for this use case just to answer some questions in the chat chat regarding archival performance the way we're structuring the archival process this is in particular I think Stellar starseed and some others have been talking about the waiver structure the archival process is, that archiving is done very lazily

[27:00] on ethics. So we only archive a very small amount of entries every 30 minutes to one hour and also you know expiration are kind of thing is done on bucket list merge boundaries and so. While this you know system you know the implementation is somehow complex and not simple it's been specifically designed to be low load upon both validators and boundaries Downstream systems also one small clarification point this is probably poor ordering on my part I apologize we've been throwing around terms like archiver the type of archive we're talking about here we should really like read like this is kind of rename the state expiration. But we still use kind of outdated terminology this has nothing to do with the current Archive of the Stellar network this will be a separate service service perhaps we'll say like no this is not validator archive I apologize this is a new type of you know node

[28:00] perhaps a better terminology would be deep state store. And so you know meta is emitted one you know entries expire. If it's temporary entry it's just drops and deleted. If it's a restorable entry. Then it's delete from the bucket list. But the meta is exhibit okay what is node thank you toner excellent the hardest part of computer science name and stuff. And so whenever the restorable entry it gets deleted from The Bucket List delete from a validator. And then is sent to the witness node and the witness stores it in like a goal-like data structure. And then essentially whenever you need to restore something from a witness node you just submit a bid on the Chain with like essentially like how much you're willing to pay for the restoration. And then the witness node. Then services, that that request and whoever services at first gets the reward. So essentially the way this is working is it's you know

[29:00] optimized for Downstream system specifically specifically and it's not the archiver it's not valid or archivers. But rather it's this new witness node type and the witness node type has a financial incentive to run and structured kind of similarly to bitcoin miners in a way instead of you know it's not proof of course they're actually doing useful work work by storing. And then producing these proofs. If that makes sense yeah my apologies for the overload terms okay it does seem like there is like consensus around the unified kind of like storage interface and to some extent I think having a unified storage interface trumps

[30:00] you know having kind of like super specialized Behavior Behavior. So I'm kind of coming around to, that and I think, that. If no one else has any comments of the matter. If you could just like formalize this and dump it in the Soroban Dev Channel later, that would be great does anyone else have any more comments in this specific topic I will take, that as a no on a silence to answer your question we have a cap-like document it was shared at the beginning of this chat it's called Web proposal temporary or a state or it's temporary entry to expiration is the title

[31:00] and right. Now it's outdated. Because it's still the TTL version. But I will be updating this throughout the day with what we talked about in the evenified interface. And so the temporary storage proposal document is the one to watch and, that will be updated with this new results to formalize this okay sounds good I see, that Dima has been trying to say something medima you are muted right. Now now you are not muted and we still cannot hear you. So this sounds sounds Discord Discord the same one he's typed yeah. So the storage access interface. So creating an entry versus malfighting entry. So right. Now we have just an overload set function, which both modifies and creates an entry under this proposal I would like to see, that change so, that we have an

[32:00] explicit create function an explicit modification function, that are separate. And so essentially what I've created would do is create is. When you specify your key your lifetime and your type. And then what are the expectations for red bumps. And so rent is bumped on every access. So this is both read and write accesses the internet bump is on the hook and required and it's Universal. And so what we're going to do is we're going to pick some small rooms of ledgers say 5 to 10 ledgers. And then for every entry, that you read or write you will be charged for logging, that entry five five or ten ledgers the thinking being is, that your model this values be very low. And so transaction fees are still low the thinking maybe, that you know. If a contract like such as USDC or something major like, that is used often the lumens is essentially abstracted away. Because you have these automatic Grant bumps and small incremental bumps

[33:00] that add up and so, that's how it works everything, that you read or write will incur a small bump and we've you know optimized the systems level such, that even, though you're doing a bump lead only entries are still essentially only read only you do have to do a small right. Because of the bottom, that the entry you're writing is very small you don't need them trying to optimize as much as possible. Now in addition to the automatic bumps you can do an explicit you know pump via an operation and in this what you do is in one detail I mentioned earlier with the online Grant bumps before I move on is, that there's also the ceiling such, that you can't you know say like I mean just your own number here say like one user worth of rent. When I say like one year worth of 10 letters worth this is an estimation based off of the current Revenue the current one fee is variable and so, that estimation

[34:00] maybe overestimation or underestimation level run fee each doesn't change super fast. And so the estimation is good enough for us. And so essentially you have a ceiling I'm saying it's like one year or six months or something like, that such, that. If the rent balance is at or above, that ceiling. Then on an overhead bumps on the background bumps and you're not charged for the online recording love fee. If it's at the ceiling. Now in addition to the small required and automatic randoms there's also a operation, that allows you to put as much rent as you want into the entry, which is called manually and so. If you have a particular King, that you're interested in Beyond just the on top right bumps an example of this would be a balance, that you want to keep live on The Ledger even. If you don't use it very often. Then you can call this operation and buy an auditory amount. So you can put you know a ton of X11 there and have your entry exist almost indefinitely. If you want to but, that's essentially how the event interface works with regards to the

[35:00] temporary Almanac versus manual rent bumps drop in the chat. So first new eventually Set yeah so. If you want to reset the room. Then you can delete and create. But outstanding rent balance is burned currently the reason for burning we talked about a little. While ago. But essentially it can be gamed. If you refund red balance and so. If you have and have setting right balance. When an entry is deleted you don't get it back so, that's one disadvantage to this quote-unquote reset the dean wants to answer your question I don't think there's ever a motivation for a rent reset like you know. If you're going to delete and create the entry just modify the entry with your new value and keep the the red ponds it's

[36:00] already there. So we don't really know what you're talking about. When you say run reset. But yes it is possible you just don't get your funds back I was said to answer your question yeah yes. So since those are how we have not included explicit run bumps are not currently contract defined. Because that also opens the door for briefing and Luscious uses. If a contract defines like a super super large rent bottle bottle like an insane fee and so. Because of, that contracts do not Define red bumps the only way to Bob Reynolds is via an operation where you specify the key. So contracts have new mechanism to Bob rent. Now there is a proposal called ice box or auxiliary about bump bump, that means what exposed to Smart contracts contracts. If there are no other pressing issues we can talk about, that that is on the topic today. But it's not super ambient

[37:00] if we have bigger fish to fry I know there's also been some discussion around around transaction metas and results and whether or not their hashes get included included is, that something, that you want to talk. Now what's more important or what's more origin this or garen's topic I think Aaron's topic is more important than my like I might I think my thing will take I can describe in like 30 seconds and I don't think we'd discuss it much. But we can continue with this topic and spend maybe the last five minutes minutes on The Meta issue I'm not scared you're done done. And then we can talk about Oxford thumbs yeah I'll save the last five minutes for you, that's good yeah. So I guess to explain the issue. So currently we have like this post one or this this operation, that bumps around explicitly and this automatic and Pleasant Run bump. But there is no way

[38:00] for a smart contract to define a ramp up action action the reason for this twofold first we want to maintain parallelism. And so one like kind of like what you would think. If a contract could Define run bumps bumps an expected interface would be let's say you have a value or you have an entry you checked your current rent balance of, that entry and. If the rent balance is below some value. Then you bump it. Now the issue with this is it destroys our data dependency graph. If you allow these conditional rent bumps conditional thing you check the current balance and only bump. If it's below some threshold the reasoning for this is. Because entries in both the read and read write sets are receiving this automatic bump bump you essentially have this dependency on literally every entry in every transaction transaction or in like a every transaction, that touches the same smart contract. If you allow conditional bumps. Because even. If an entry is in the read-only set

[39:00] if it's you know. Because of the automatic bumps the rent aspect of, that entry is implicitly turned into a reap right. And so conditional red bumps destroy parallelism. So we don't want to allow, that there are some potential ways we can fix it or do like rent charges in different stages of application. But it gets complicated really fast. And so conditional rent bumps at least from version one or out of the picture. Now a possible second version is to allow green bumps. But not conditionally. And so we would not expose the rent balance to the contract. But would allow a contract to define a rent bump the issue with this is it opens the door for either malicious griefing or just accidental briefing by a bugs. So for instance it would be a poor user interface. If a button a smart contract caused someone to pay 10 years worth of rent on an entry, that would be worthless

[40:00] in two days right it's just open store to a large amount of bugs it also allows the contract to kind of like Define arbitrary fees, which I'm not sure there's something we want to do it's also not super useful. If you can't conditionally check. So it doesn't seem like a great use case. Because it would be probably a bad idea to for a contract to Define behavior, that every time you save you balance of, that balance by six months or something something. If you can't shift around balance. Because you can have very very high levels of rent balance and secondly it's not very clear. If you should do an explicit run bump. So for instance say you have like a token contract, that has to be balanced it might see on paper, that in efficient implementation is to check the rent balance and say okay we want this huge balance to always have six months of rent. And so on every call of imbalance we check the balance or we check the limit balance of the balance entry and

[41:00] then. If it's blowing six months we bump it now, that works well. If the owner of, that token balance is calling view balance however. If a different user say a user wants to charge, that user some amount and they call view balances to check to see how many coins, that person has and they get charged rims, that seems inappropriate. And so it seems to be very difficult for contracts to Define situations or they actually should charge additional rent to the user. Because it's not always clear. If the invoker is the owner of the entries being accessed or has an interest a vested interest and these entries remain live on the ledger. So those are kind of the reasons why. So far we haven't defined rent bump functions, that are exposed to the host contractors over to the smart contracts so, that being said there is one potential idea, that we've been floating around called auxiliary round bumps and there's a section of, that describes this on the second talk I shared, which is

[42:00] the rent proposal a CDS version doc on the section called box rent on post function. So what this is is essentially essentially you can Define this function called ox and bump and it takes a single parameter, which is the key and contracts can Define this and put it arbitrarily and bump arbitrary Keys. Now the trick is the contract can't Define how much to buy the rent by. And so all they can say is this entry should be bumped. But they don't say it by how much. And then and the footprint of the transaction you would have an auxiliary Run pump value, that the user can set to whatever they want. And so for instance. If I'm calling view balance on a token contract and it is in fact my own balance, that I own I can set my auxiliary run bump to six months in the host function, which means, that anytime the smart contract calls logs ramp bump, that entry would be bumped by six months but. If I'm calling the balance on

[43:00] another user's token balance I don't care about. Then instead of setting you know odds to rent to six months I could set it to zero. And so every call to aux rent bump would be a no-op. Because I don't want to pay an additional rent the advantage of the situation is, that. While there is a manual function to bump rent you need to specify the keys and it's a difficult issue. Because the contract developers know what keys belong to a user. But the user knows their use case for how much bump or, that they want to bump so. If you can imagine a smart contract might have you know three different types of data associated with a single user. So for instance a token contract might have both a balance tied to a user's account, that has one key. And then say a nonce with a different key, that's also type of user. And so to be able to properly use my balance I need both entries to be live now. If I'm not you know very sophisticated or I haven't read the contract code in depth

[44:00] I may I even believe, that I only need to bump my balance entry. And so I'll find my balance entry key do my host I'll put six months in there but. If I don't want my Notch value. Then it doesn't matter. Because the knots will be sent to the archive it's impossible. And so it seems reasonable for the contract to Define essentially groups of keys, that belong to a user and this aux rep bump function allows contracts to do, that that essentially what you would do is the contract would call Ox rent bump both on my token balance entry as well as my token non-century. And so then. When I call, that function I'll have to specify specify one value aux rent bump six months. And then both entries are properly bumped. And so this is kind of an interface such, that the contract developers can Define, which groups of keys are bumped. And then the caller defines how much those groups are bumped by by. Now the issue is I'm not sure how useful this would be in practice and also seems

[45:00] a little complicated. And so I guess this the the question here is do we want to allow smart contracts to Define Rebels at all and. If we do. If it is a strong requirement, that they'd be able to Define bumps is this aux rent bump workable or do we need to think about a little bit more and figure out a simpler maybe easier solution do we actually need, that to be in the protocol I think. If we like I thought last time we discussed having like a self-like self-like you know basically like people standardized on a maybe a method or something, that you know you would increment increment as a yeah as I said right, that basically tells you a bunch of hints like, that. And then then only maybe like incorporate this type of functionality into the protocol. If there

[46:00] is like something, that ends up you know working for the majority of people I feel like we are trying to dig something at the low level and set it all specific here I think there's like the the motivation for this is a bit problematic. Because we're saying you know like calling manually the the the rent bump operation might be kind of like more complex. But at the end of the day neither of these are actually going to be performed by the users themselves right this is going to be managed by the wallet the user doesn't necessarily understand the difference or care about the difference and from, that perspective these two don't sound it doesn't sound like enough like we gain enough to to justify The increased complexity here

[47:00] yeah, that sounds reasonable to me I was in super strong at this point. So just to finalize this and I'll let Sid talk for a bit. So are we good with moving forward on rent rent with automatic rent bumps. And then manual run bumps via this operation are we good with, that it sounds like some people are discussing discussing a host function where you provide keys to bump did we decide on doing, that like in contracts you you would provide like a list of keys to get bumped. But not the amount well, that's what I was discussing this is what the box front bump is redefine the set of keys to button. But not the amount to button. And then the amount would be specified in the footprint it's a complex and kind of Niche Solutions. So maybe it's not really required required okay

[48:00] you can move on to the event proofs nope let's do it Okay. So we initially decided to include. So right. Now the sorbine events exist in the transaction meta and transaction meta V3 and The Meta is not included in the Ledger it's not hashed anywhere. So we and initially we said we would hash the the components of the meta most importantly the events and include this hash somewhere somewhere in the ledger. So initially it was going to be in transaction result in a new transaction result. But this would have caused a lot of Downstream issues and we decided instead to move it into the Ledger header. But more recently after discussing with Nico we decided to just not not hash it anywhere and just include in the meta and, which is, which you know we should be fine for. Now and. If we need some way to

[49:00] add proofs for events we can add it on later instead of you know doing putting in a solution now, that may not be sufficient sufficient. Now we haven't discussed this much. So this is an opportunity for anyone to provide any concerns with this process. If there are no concerns. Then we can go ahead I mean I'm I'm very slightly concerned, that something we were recording we're going to be not recording in some ways it gives us you know more wiggle room in the in, that we're not you know we can do replay without reproducing the exact same events as last time. But it also means, that. If we do replay and we completely break events for example we won't notice, that fact. So there's a sort of

[50:00] error checking aspect to recording things, that is being given up here right but, that yeah, that is a good point like events events events don't go into blender and so. If the it's some sort of a question of whether the events, that are emitted by a contract are considered a canonical part of the contracts interaction with the world or or an incidental detail, that you know we can just feel free to break or whatever whatever yeah I don't think we would want to break obviously obviously we don't want to break it. But yeah. So I mean. If it's. If this is a validation question you know on our end we like you know before before we add any type of anything related to this we could just add some validation right where we make sure the meta doesn't change, which which we might do already right we do, that already yeah. So so. If there's any any unit test, that does event emitting in star core, that'll

[51:00] that'll get caught up there. Because we just record them better directly. But yeah. So I mean from, that perspective I think we should be fine and you know the bigger reason to not do this was even, though we you know in the old proposal we had a way to calculate to like verify cryptographically verify, that the event was in a ledger. But the process was very complex and realistically I don't think anyone would be doing it anytime soon right. So it made sense to yeah I'm I think I'm I'm less there's. So yeah there's two completely different use cases for this one of them is is like brief basically you know. So someone someone wants to argue, that hey I saw this event and and you claim it didn't happen and I'm gonna go prove, that it did happen the other is sort of consensus and

[52:00] integrity like does does the record Force us into replaying something precisely or not and I can see, that being both both a blessing and a curse we we've actually spent a lot of time trying to subdivide things, that we want to be recorded precisely versus things, that we don't want to be like we want like diagnostic events and and you know print statements and all this other kind of stuff, that the user can can just sort of sprinkle in willy-nilly and, that the operators can bring along and and us as core developers can put in without becoming canonical. And so we've had this whole question of subdividing things to canonical or non-canonical in the event stream. Now here you're just saying let's just make basically we'll make the entire event stream non-canonical right like it yeah it's it's nice. If we keep it the same from one from One release to the next. But it's not actually part of The Ledger and part of me is okay with, that that

[53:00] everyone who has thought about using events for sort of canonical reference purposes feels okay with, that. Because it seems like a big change to me. But it's it's one, that I can live with certainly it makes life easier in many ways for us do you guys hear me yeah yeah yeah like the thing, that Britain yeah you brought up I think it's something, that I yeah I was not really thinking about, that's actually product. So like for the verification is through the yeah like, which is the thing I was like thinking about. When I said hey let's remove this it doesn't we don't really care I think for the being able to replay historical data you know with High Fidelity this is the only signal we can get and. If we don't include it anywhere we're going to not be able to guarantee

[54:00] that and until we have you know effect coverage in the absorband in the actual code base for how we produce those events, that I don't feel very good actually about not having this anywhere. So maybe we should actually go back to make make put this maybe it's just the advantage or something in the transaction result, which was kind of the info server I mean now, that we're actually back to only one one operation basically for Servant transactions maybe this is not. So bad are you saying using the transaction result of The Ledger header no not to use The Ledger header it would be not a normal result for server for the Soroban invoke

[55:00] what's the name of, that idea yeah and just have, that there and it's we get it for free basically oh in the result yeah it's including the hash. Because that, that's actually the thing I'm really worried about here is, that I'm not sure we can guarantee, that we'll have, that the test coverage will be, that good okay. So thank you sir go ahead yes for historical replay I think, that's the thing I'm really worried about is, that we break events basically basically for for for older managers and we won't know this this okay okay. Because this is related to another issue we need to deal with, which is, that in low cost function up right. Now Returns the SC value, which will

[56:00] actually be a like a vector of SC dollars we moved to multi-invoke so, that should be moved to the meta as well and all, that can be hashed events and the return value can be hashed and included in the in low post-op result, that's what you're saying right. So I thought what we said what the the this result should actually become a system event right right yeah I'm not sure we haven't discussed like the I guess the format is still up for debate. But yeah yeah the SC value is actually. So the actual result, that you create of the operation operation should be a hash, that points to Mira, that was emitted basically right. And then the meta would include a bunch of hashes the result. So I mean or events sorry and potentially we can include the The Ledger changes as well there okay

[57:00] okay yeah so, that was kind of the original plan I guess. But maybe a slightly different now. Because yeah since. Then we moved the SC value results to the events as an event to be an event yeah well just to be clear, that hasn't happened yet. But but we should yeah all those changes make sense together yeah yeah yeah okay I think yeah I think I can update we have some issues and PR's open for this. So I'll go and update them and this makes sense yeah yeah. Because that we were completely blind on this one. So we are going to wind up having basically the just just just a Fidelity check of like a hash for identity yeah so, that we have a way to to guarantee, that we are not breaking historical

[58:00] replays I mean it also forces us to maintain Fidelity right, which means, that we yeah exactly accidentally emitting an event we're going to have backwards compatibility code, that we have to jam in there, that might get annoying I just wanted to bring it up. But not I'm not I don't feel okay well I'm happy either way I guess anyway I just want to make sure we or saw these there sorry the end at the end of State we're we're talking about is. So it sounds like we are going to include the hash in the co-stop result of of all the results results and events. Because the events and the results do the same thing. Now results yeah okay yeah

[59:00] all right and, that winds up in the header. But we don't. But we're not going to have, that sort of monstrous reproduction of transaction result V2 and no no okay. So it's a sort of a mini addition to the Ledger header, that. But we don't have to change the letter editor at all right. If we just change the invoke host of function up result oh. So this. So the result director is got the half now, that's what it sounds like yeah yeah. Because the other way would be making a result translation result D2, which would be annoying, that would be it yeah yeah or or transaction meta V2 like you've gone through several iterations with this right there's a version where you Fork transaction result there's a version where you're forked contacted meta yeah we need a new meta. But I don't think we need a new result new transaction result do we actually need a new meta. If we have. If we're just taking this in the up result you still need to put the events

[01:00:00] and the results like the events of the matter right like you know we have a transaction meta V3 struct I thought oh you need, that in order for the events to actually just go somewhere like for it's for yeah actually extract them okay. So but you're not. going to hatch, that meta no no. But you are going to have those events into the transaction result yeah okay. So the events wind up in two different places they wind up they're full their full content wind up in the Met of e3 so, that Horizon can read it and their hashes wind up incorporated into the transaction result, which is just a normal transaction result yeah okay yeah I can live with, that for sure right okay we are after time any final words from anyone anyone okay let's keep the discussion going

[01:01:00] in Discord thank you all for joining have a great rest of your day

</details>
