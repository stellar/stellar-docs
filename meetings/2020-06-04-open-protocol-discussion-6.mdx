---
title: "Open Protocol Discussion (6/4/20)"
authors:
  - nicolas-barry
  - david-mazieres
  - jed-mccaleb
  - jonathan-jove
  - leigh-mcculloch
  - orbitlens
  - eric-saunders
  - tomer-weller
  - tom-quisel
  - justin-rice
tags: [legacy]
---

import YouTube from "@site/src/components/YouTube";

<YouTube ID="u3B0q3tt7u4" />

- all right welcome everyone we're live-streaming this just so that everyone knows this is the first ever broadcast of the open protocol discussion which is a biweekly meeting in which we discuss and plan for upcoming changes in and improvements to the Stuber protocol generally these meetings are to review core advancement proposals also known as caps which suggests new features and improvements to the protocol sometimes we also talk about the process for perfect call improvement and we're going to do a little both in this meeting first we'll talk about two caps and one issue that outline proposed changes those are all for possible inclusion in protocol 14 and then we'll cover an issue that relates to the process for the creation accounts finally I'll just touch a little bit on the process for orchestrating network upgrades because we've learned a lot upgrading to protocol 13 which is has yet to happen so we published some pre reading requirements for this meeting there in the event description so if you're following along you may want to look at those so that you can keep up and there's also an outline of the agenda on the left of the screen I believe and without further ado I guess we'll just jump in I wanted to start this out with a protocol 13 update so that's the first agenda item basically after surveying the ecosystem we decided to push the upgrade vote two weeks is supposed to be today that was gonna be June 18th to give people more time to prepare basically most of the stellar based businesses that we talked to are ready right now but several crypto exchanges aren't and we just wanted to give them a little bit more time so they don't break so that's the protocol 13 update news any questions okay cool things that we have to talk about our caps that are potentially for a potential inclusion and protocol 14 the first is cap 23 to part payments it's been around for a while we've had a lot of discussions about it the current version is pared down from where it started basically it creates a new ledger entry called a claimable balance into new operations that allow you to create and claim a club level balance the idea is to be able to separate sending and receiving of a payment so that you can send a payment to an account that isn't prepared to receive it cap 23 is there anything else that I mean we talked about this a lot is there more discussion that needs to happen about this doesn't want to have any questions comments Jonathan drove do you feel like you've gotten the feedback you need I think I think we're ready to go I think the only outstanding thing here is that based doing what we decided two weeks ago or whatever the last time we met was I think two weeks ago where this isn't in the proposal yet but instead of trying to send funds back to you know in basically instead of like trying to do this thing where it's like oh you try to send them funds back to the to the creator but if you fail you send them to the recipient we're not we're not gonna do that anymore as we decided it's not reflected in the proposal yet and instead we're just gonna you know unreturnable funds go to the feet pool basically we're already working on that in the implementation but the proposal hasn't been updated yet I just wanted to mention that but everything else is as we agreed I have a question the question is if I wasn't clear to me reading the proposal if the account that's the created buyer or weak at 33 becomes the sponsor do they always have the possibility of claiming back at the claim or balance or does the creative the creating account you need to add themselves as a claimant to the other claim of I so the the creating accountant doesn't have any special privileges relative to any other account it was only there for this bookkeeping about returning the about return in reserve but it's not it's not special in any other way you know if we took the approach of like always destroy the reserve then we wouldn't even have that information there one thing I will mention is like we're not like that created by field isn't gonna exist anymore like the cap 33 functionality is going to supplant it so there won't even it won't even be there anymore it won't look special anymore relative to any of the other sponsorship things but no there's nothing special about it does that answer your question me yep great okay so if there are no other questions the plan here is that I'm going to the the people who are eligible to vote on moving this into final comment period will email me by the end of the day tomorrow and if this if they agree to move this into final comment period we'll post on a mailing list get final comments from anyone out there in the community and go from there sound good cool next on the agenda capped 33 also for potential inclusion and protocol 14 sponsored reserves this proposal allows an entity to cover the reserve for accounts controlled by another party without getting that other party control to the reserve it basically extends account and ledger entries so they record pertinent information about sponsorships creates new operations to initiate and terminate sponsorship and update sponsorship information for existing ledger entries and so the goal is to allow people like asset issues and wallets to cover the reserves for users this one landed more recently and so I guess my first question is does anyone have any comments questions or suggestions about the sort of recent version of this that Jonathan turned in I had a question in order to use this stuff you have to have creation of the sponsor the sponsorship happens by one account and then there's a closing out and that happens by the other account right to make sure the this thing is sandwiched properly with angel not supposed to authorize question is how does it work him like a workflow a kind of vibrant like workflow and a great Lee's account I was struggling to kind of see in my head what the path was because you have to get the the account the two accounts to coordinate with each other do we have an example of that somewhere what could somebody talk me through it enough revived so that certainly should answer this we might also have more context on this than me so if you feel comfortable taking this money I would appreciate that but otherwise I will do it yeah I can I can talk about it I actually also have a question about this and a concern about how specifically in the situation that that Eric brought off by creating accounts but yeah so I think if it was to work how to read in the proposal the the client a client on the server would have to be negotiating so the clients gonna make some initial hello that starts off the process the server's going to create the transaction assign an account that can use that sequence number for the duration of this whole handshake the transactions going to have to be signed by them and passed back to the client sigh and and then submitted say there is like this back and forth negotiation that has to happen the sower or the service that's creating and sponsoring create an account and sponsoring it can't do it on its own does that answer your question Eric yeah I guess so although I start having more questions then like what happens if the account doesn't exist just fine so do you think it would make sense to explain this in a non normative section of the document I think we actually need a new set for this and it's very analogous to what set 8 is to cap 18 basically how does how do you actually do to the negotiation off chain and then before you submit to the network so I would I think that Lee because you guys are gonna be probably one of the first implementers of this it would be great to have you guys figure out what makes sense to you and then inform the rest of the ecosystem or ask for comments yes I think so I actually have a concern with this so my understanding of why we have that second that's that last transact so their last operation to confirm and close it out he's we made what we want we see value in the account that's being sponsored confirming that they actually are okay with being sponsored and I think a problem with that so I think that works for a lot of cases where the account being sponsored can be the account where the sequence number is coming from but for the create account operation I think this is going to be really difficult at scale because the the service the sponsor is going to have to lock up an account with a sequence number during that process of that negotiation and I think that's gonna be I think that's going to be problematic enough that this way that could prevent this from scaling and we really want this to work sponsorship to work at a significant scale because it's primarily for an enterprise that's going to be sponsoring lots of accounts so I'm wondering if like if we're putting too much value on what this soul's want the problem of the souls and if this will create a larger problem yeah that's a good question I mean there's there's definitely like this this is not the only sequence number provision problem in in the world of stellar for sure and I think I think given the like you know fee bump improvements that are coming in protocol 13 this is kind of a step backwards in that regard for this particular issue I am a pretty strong believer that there are a lot of advantages to making this like double signature requirement I mean like I think we're gonna be here for months otherwise just in the sense of like me going through and just like making sure that everything is still going to work and doing sanity checks on everything because it weakens the backwards-compatibility constraints a lot that being said like David was at our last meeting talking about I think you actually sent an email about this which I'm going to confess to not having read as good as I feel have read it it's not the startup mailing list I can I can post a link to it somewhere else if you want yeah review it after this now because it's seeming more relevant and I wanted to start by saying like whatever I'm about to say is like definitely not gonna happen in protocol 14 no matter what because there's just no there's no time but like as a longer-term solution like providing some other kind of mechanism to avoid this need to you know manage sequence numbers for all sorts of random stuff that that could be the long-term solution to this kind of problem you know using something like a hash preimage or something else that you know to do it Mike I think that that's like the calm that was the concept right David like some other kind of authorization thing actually it was basically saying that you can sign an operation and then that up you don't have to sign the transaction someone can use the transaction he someone can include that operation in a transaction and it will not increase the signature requirements on the transaction envelope oh so that that would allow you to sign the transaction envelope at a later time basically once you've already tripped like at a time when you can choose the sequence number right like basically let's say I want to allow you to add a particular trust line to my account or I want to allow you to authorize a particular trust line on an account I can just sign that one operation and give it you and you can include that operation in whatever transaction you want yeah that's an interesting idea that would that would mitigate this problem I mean I'm kind of I'm kind of like I'm kind of like backing out on this basically and look I don't have a good way to avoid this problem today given this design and my stance is kind of like the merits of this design warrant searching for another way to avoid this problem which is like a general-purpose teller problem anyway you know trying to solve it for this specific issue isn't gonna solve it for some future issue where we're going to encounter the exact same thing and they need to engineer some solution for that as well and to be clear the problem arises specifically with the create account operation correct yeah yeah and it specifically arises there just because the sequence number is being locked up by another party so you know most the time when you're creating accounts right now it's not such an issue because the service loss of the sequence number for it for the time it needs it to be locked up for but this is gonna be looked up for the time requires to party to negotiate yeah I mean one approach you could kind of take it's basically the stance that like you need to do basically you set some time limit on how long this negotiation can take you know this off chain communication you say like basically like hey I'm unless you take like up to one minute to sort this out with my server and otherwise you have to like reinitiate this with me at some later time and in that time again you'll have one minute and then this could allow you to use like a small pool of accounts you know you only need to maintain one minutes worth of accounts basically to use a sequence numbers obviously it's not amazing solutionn it's not elegant it comes back to the channel problem again sounds like a minutes worth of accounts for a high through but service is a lot of accounts agreed well I'm not so sure I mean signups are typically a very small fraction of what happens on a service and so that's I think when you do create account I guess maybe you do create account during escrow operations as well so I'll make it might make a trickier but I don't know my take is like the you're probably gonna have to build a channel system anyway with things the way they are and so sure this maybe means that you need a hundred channel accounts rather than ten but it's it's not really fundamentally changing the situation maybe that's a really optimistic I don't know yeah I think think where I can see the challenges is just in typically at least how I know by we have implemented this before is you take a channel account you lock it for some pre different you lock it for some predefined operation that you're gonna run in code so just becomes more complex to say okay I'm gonna lock that based off someone else's actions and or some timeout yeah I agree it's it's just building on existing complex in here so yeah it's not really new complexity also I think the the timeouts are in the same order of magnitude right like we're talking at Terra transaction typically valid for like let's say a minute I would don't imagine you would go you know longer than that for those interactive things anyways I mean not know inter don't directly I mean it's really just you're physically passing this to the client they kind signs it and you know I know that it's probably the same thing that's what I imagine I think this is a good opportunity for us at the SDF to put some open-source example of how to actually achieve something like this in a you know in a fairly high throughput manner and like John said I think that this specific problem doesn't actually relate to cap 33 it's more of a general store problem so maybe trying to solve for this right now is counterproductive I mean on the other hand it would be nice to at least commit to some way of solving it you know like if there's an assay you know this is gonna be a problem and what we do is we approve cap 33 and then you know followed by six months of discussing which of like four approaches should we take to solve this problem that that could be an issue I don't think so I think there are also you know like we have to solve it in general like it's not just for for that particular operation right like you won't even like a paycheck 18 you need some way of doing that efficiently I guess happy yeah then maybe they should be disgusting maybe there should be just a short non normative section of the cap that discusses the need for some kind of mechanism and then subsequently caps can cite this you know will sort of provide ammunition to get whatever a solution would come up with over the line later on yeah I think that's great now I'll add that after this meeting or sometime later this week just a little discussion about how this is like it's an annoying source of complexity it's probably worth it nonetheless and it's just a manifestation of a bigger problem that we're fighting all the time and then that and then the plan would be to create some sort of group to solve this larger problem like a working group but but from what I understand this cap cap 33 we could move on to final comment period because it seems like there's not a way to do it that doesn't encounter this larger issue is that correct yeah I mean my stance that would be like it if you avoid this issue you'll find a difference like we'll find the other issues that were problems with cap 31 which we rejected in favor of this so it's like you can't avoid both sets of problems you have to pick which one you want I'm picked this one this set of problems only from the perspective that like they're problems that are general-purpose manifestations not not single purpose and I think that the other benefits are better is on top of that but John you think you can add this language before final comment period yeah I I mean like we make modifications to these during implementation also and then we're going to the implementation period so yeah I mean I'll add the language and it'll be there during the final comment period for sure so you'll add it and then we'll vote okay John when John's added it I'll I'll submit it to to eligible parties to vote on and then we can see and if it it basically if people are like no we don't think it's ready we can bring it back in the next meeting but if people look at it and decide that it is we can go ahead and fold it into final comment period and open it up for final comments cool I had one other question other operations you said other operations will make it semantics and what its behave correctly proposal that's Spencer that might include I'm having a little trouble hearing you Eric can you say that one more time yeah the other operations need updated semantics in order to behave correctly can you just give like a high-level view of what that might include is that something we need to worry about it's not something that we need to worry about well it's something that I'm I'm already worrying about I'm working on it I was working on it right before this meeting actually but basically but like what's kind of what kind of needs to be done is like everywhere where we do like a where we change the like account numbers of entries field we now need to do it we now need additional logic to say like hey like what's the response err oh if there wasn't and then do what we used to do if there was then we have to do all this other stuff like oh like check the sponsoring account still exists it doesn't have to still exist for example so like that's a new failure mode I haven't worked out the precise details on this because it's like I need to kind of go to the implementation and see what's gonna work and that's why it's kind of very nebulous in the proposal but the kind of consequences you're gonna be like potentially a few new failure modes that are only possible with sponsorships and and basically just just new code for me to write but every other perspective everything will kind of just like work the same like when a create account works it'll just work and you won't really be able to tell the difference other than some sponsorship the information will have changed okay so it sounds like most this is internal to the implementation but we might see some new error codes yeah and like that those kinds of changes are where like like we have like the ledger entry extension v1 and the account entry extension v2 those changes are where those things will we will be ma will be maintained so you know that that's pretty much what it comes down to okay is there anything else there to talk about in relation to cap 33 well I feel like the plan right now is John gets back to work that's this extra session you send it out and see if it gets voted in final comically but I don't want to close it if there's still questions just want to say that it's a great cap John much better than cap 31 I think I really like the whole moving things to the off chain logic really nice cover I appreciate that great well then we will move on to the next item on the agenda that's issues 622 which is about changing the application of clothes fine basically it changes the clothes time for a transaction so it's set for the ledger after the transaction gets a bike because right now in a bank transaction we use the clothes time decided during consensus and that can create issues for the transaction gets accepted but into a ledger but fails later I think this is just a just an optimization does anyone have any issues with it does it feel like something that should be worked on for protocol 14 yeah it's an annoyance basically false about contracts and we are kind of hanging out those things over time this is a small small item so that's why well yeah I'm not sure I'm not sure I understand the issue right now who decides the time that's evaluated against time balance it is not about deciding the time this is about all we reason about the time from a transaction ready DT point of view because of time balance right okay so time downs are you know we look at we compare it to the to the to some time right right and right now we use the time that were this tidy during the consensus round right and this is wrong and so in the wait time you're proposing is to use the time from the previous ledger because the time from the previous ledger was already decided when you were checking for validity of the transactions when they were submitted I mean this seems somewhat dangerous this means like if there's an outage it's possible that we can apply a transaction that's like an hour old or something yeah that's yes and the first time make also jump by an hour right so there's no like with we have to decide I mean this is not a you know that's just the way they know you have to make a trade-off you know what happens you have an outage which transactions you want to reject I guess so like let's say that like we have an option where I have a transaction that I can submit that will trade X for Y or something right and since I don't know the value of x and y in an hour you know like we agreed on this now so now I could theoretically you know toss the network and get like a free option to you know basically make my decision with an extra hours worth of information I mean obviously the alternative is and that's a lot harder is to remove those transactions from the transaction set and the things that we cannot do that right now we have no way of doing this right consensus is still running like he can't change the transaction set I mean I I do see other ways of doing this and I haven't you know haven't thought deeply about this but just you know so another thing if you do is for example when you nominate a transaction set it could have some expiration time or something and then but that's not your fist okay you know bit based on or you could kind of like I'm not saying that you you would have you would look at very DG based on unlike some heuristic on the on the time stand awesome another saying like you know currently we sort of take the largest transaction set when we're sort of combining multiple nominated values and now maybe we could take the the largest transactions or the the transaction set with like the most number of unexpired transactions or something but you still end up with some expired transactions right that's the issue here is that those guys what do you do with them because it is basically the the I guess the reason we have this problem is the close time and transaction set are kind of decided separately could we could we modify our validity checks to like I'm specifically thinking about David's like one-hour window thing that he was talking about so this is still under the assumption that we're gonna make the change described in 622 but could we modify the validity check such that you won't vote for anything if you're not Byzantine that is in basically it's like transactions time bounds are checked both using the last closed time and the current time because then it's like you wouldn't vote for something from an hour ago because it wouldn't have been valid using your current timestamp it has to meet those conditions to work there's the only vertical level change it's not that you only if you do that you only reduce the chance of having a bad time stamp we don't make you don't eliminate it and and so that the main I mean it's the main issue here just that we have garbage in in the set of transactions that we can't charge right yeah right now no it's not gathered I mean it's a it's more like that we end up with transactions that are accepted for you know during consensus but because they are now I graduated against a different time stamped and the one from you know when they were nominated did now becoming valid so now you have like those smart contracts potentially getting dust right where if I if I because you know they are valid when consensus starts and now now invalid during consensus and yeah they are failed transactions and they will consume that account number and now maybe that smart contract is that way they don't consume sequence number the bug is but 622 that's what the core of the problem is because you know we have the invariant that anything that gets into the ledger we're going to guarantee we're gonna we're gonna take the fee and we're gonna take the sequence number and so did that's the thing that we're betting law wants to combat here is you know getting your your smart contract broken by one of these like boundary case time stamps well this is another way to solve this would be say authenticated operations so I feel like there are other things that know why you think that know how this has nothing to do with the authenticated operations this is time stamps well the authenticated operation gets rid of the problem of consuming sequence numbers it the part of the part of the problem here is how brittle a lot of these protocols are because of like sequence numbers right so the issue that sometimes don't work right so like you're saying like yet you could fix certain smart contracts by using like those you know this new you know like basically use a different sequence number basically from you know a different account you offload the sequence number some you know live account basically but yeah that's not what we are talking about we are talking about you know sequence numbers in general like today we do see do like once in a while Ledger's will failed time you know in the in the set of trade transactions I understand but I'm saying that the the one of the arguments in favor of this is that right now there are annoying situations that break certain protocols because a sequence number gets consumed by a transaction with an invalid time bounds and I'm saying that well because of CAF 33 you've already said there's a need for something and and one of the ways to do that something would be the authenticated transaction with the authenticate operations not saying that that's the right solution but it just so happens that authenticated operations also solve this problem all right no it cannot hold it right like like you're saying that no smart contract would ever rely on on a time bound or something like it yes no smart contract that ideally smart contracts would not rely on sequence numbers in a way that breaks if the sequence number gets consumed by an invalid transaction that doesn't sound that plausible to me actually because on Elections if you do that right not only that but you can't you can't do the bump sequence trick without that and you can because of the way I I mean at least though I'm not saying this is the right answer but it's an existence proof that you can do this right because of the way that because the because the authenticated operations can depend on there being some other operation in the transaction that other operation can be a pump sequence right so we've got existing smart contracts like what about ones who already have this problem then they'll have a different problem if we do 622 Oh like only a line the only reason you would have a problem is the DOS situation if you have like those funny time windows normally it's more like starting from a certain date this is valid you know expiration you know if you have an expiration and you don't write around the expiration time I can see that this is a problem regardless right we have this is not a sole thing like well you basically rely on the fact that the network has a semi accurate time right but in the event of a dirty not accurate it's going to be off by some number look I think that you know there's a problem here I think that if you were to write up like a requirements list my suspicion is that I could you know propose some alternative that doesn't look like the proposal here whether that's better or not I don't know but I think it would probably be worth considering multiple approaches based on a kind of specific kind of like a slightly more detailed description of the problem and like what we're trying to achieve does anyone object to taking that course basically writing up a requirements list and getting David an opportunity to come up with an alternative solution that's fine it doesn't have to be like you know I'm not trying to create a lot of make work here like you could just be you know a couple simple examples of what what we're trying to you know scenarios that were tranqued where we're trying to avoid a problem but I think honestly that it would be it'd be good to think about it a little more just from the perspective that like I I want to try to understand that that da scenario well like is it a problem or does it just sound like a problem I'm not I'm not sure that it's action a problem but I'm also not sure that it's actually not a problem it's a big existential question so like I think it's worth looking at least a little deeper about this and making sure we know what we're doing I think we're also talking about that type of scenario is quite a bit already on the mailing list I think because David had this other change to the timing bounce to remember David like that was like what yoga at this point I remember we went back and problem on time bonds that's basically is what ended up being replaced by cap 23 I think but in that proposal he had some interesting new time bones right I had like preconditions I think but there were some discussions around like those type of things like what happens when you when you're like an attacker delays the network you know what other type of properties you are trying to get here and maybe the issue is that we don't fully right now we don't have basically a written statement on what we expect smart contracts developers to do when you have this type of attacks I think that's made it just you know one of the other things that we need to think about here yeah um so yeah it basically what I'm saying is before someone invests the time to like write a whole cap for this let's just like get some requirements down and just you know at a subsequent meeting just talk through like whatever approaches people have and come up with an approach we think it's like the best approach because there may be there may be other approaches maybe not maybe I'm wrong but that seems like a great solution to me cool any other discussion about this are we ready to move on to the next item great so the next item is issue 624 which is improved the cap process so it clarifies the role of working groups also it tends to take into account more information about the impact of proposed changes on downstream systems thoughts questions discussion that we want to have about this I mean I guess for me it makes sense to to better figure out how working groups create caps and who owns them and and who participates in those groups and I mean this proposal made a lot of sense to me and then I think it's just a question of starting to experiment with it and seeing if it works right like maybe like as background like one nice when I wrote this stuff like one of the things I also took into account is that in the current like process that we have actually written in the criticals repo it says that there is this I know mythical creature that participates into the cap process that's the body or whatever yeah that's right right that doesn't exist so and and basically as I really and also you know with the way we've been working more and more it seems to me that that body was you know concept was more or less a over-engineering in a way from the protis point of view in trying to take away you know like room for the working group to actually figure out who are the best people to actually have in that working group so I think like if we end up with like more something more like what I'm highlighting in this issue who would remove the body from the process yeah I mean just generally object to the word buddy it just sounds I just don't like the sound of it okay but also I think if it's something that we're not using and it was the same thing that John brought up on this with it with the test section right like I guess that we need to just look at the actual I guess it leaves in the cap reading that defines the the cap process and make sure that it actually adheres to a process that we feel good about and that reflects what we've learned but then I think we also need to be relying more strongly on working groups right yeah and maybe like III maybe this time we can I saw that Eric had a question like what does it mean to have the rest of the stack you know like light up and all that like to me the intention is to have the working group think about the implications of that change in a more holistic manner basically if we need like very often some of the changes at all we need a set basically no the sap is not should be basically written in parallel with the cap you know by the working group if that's the only way that that thing can be used because that's how we are going to find bugs in the cap another thing on performance because I think Eric with Erica maybe I don't somebody has asked about performance I wanted people to think about performance implications in other systems as well like the working group should be thinking about well the cap itself or he talks about you know the local performance impact but at the same time for example one of the most painful changes in protocol 13 is but it was very surprising to me it was the the change that he column in Horizon right the table migration that takes like nine hours well whatever it's something you know maybe we do would have it made some changes I don't know like you know like if we had identified this early on so this is kind of thing I'm trying to to get to is get you know sometimes changes look trivial you know in the poor layer by the implications up streams are just terrible and I kind of want people to think about those type of implications early on so that we know we can make adjustments into basically the working group would figure that stuff out document it as part of the proposal submit it to this group with all that documentation so that all the research would be done you know yeah a little bit more what we were talking about yeah and to me that sounds great I mean the only question that I have is a feasibility one right like if we had the all the right people to staff any given working group that we wanted to create this would work I just wonder if in reality we're gonna run up against issues where we just like we want to have three working groups we don't have three working groups of people with the necessary insight just to build those working groups that's my only like feasibility concern that make sense I mean we can you know I run into that problem already and yes we do and at the same time and I know my response is that if we don't have time to think about this maybe we should not do it in that protocol version if we do the due diligence you know that goes with a specific change that means we're not thinking about it right so I think that the additional lift here which is reasonable is to basically improve the process of putting together working grade so it's like improve what a working group does define it better add it to the cap process and then also get better at putting working groups data which is seems reasonable to me and and my hope also made that maybe the chair on the top would be if we have more of those kind of lively discussions that the working group level do they should become quite be a bit more those conversations I think end up being a little more inclusive from a ecosystem point of view because they are actually touching a lot more different paths right now I think the issues with any thread on the dev mailing list that our protocol changes they are so far removed from the end from the actual developers that nobody can really chime in right they don't see how this is really impacting them unless it's like you know obvious so my hope is that yeah we can maybe get a little more feedback early on from the you know people that are going to use that those things in the future if anyone's watching this right now is like I would love to be in a working group in the future you should email me just another org like I got it you know I think it's gonna be about going out and collecting people right inside people with insight people who are building stuff and making sure that they understand the potential implications that one of these chord changes have and getting their insight rate yeah that makes sense to me I like the working group direction and being more inclusive of you know people on the Horizon team or SDK team or even application developers I think one other element that seemed pretty central to me that I didn't I didn't maybe I missed it but I didn't really fully see it flushed out in this this issue was was kind of the contents of the cap and and having an explicit section of the cap that discusses the changes that we've made to Horizon so like to to Nico's point like saying yeah we're gonna migrate this column and within the base table we're gonna change the schema this way I'm going to add these endpoints we're going to modify the go SDK to have these new calls or deprecated this call that seems pretty key to have as part of them for understanding the downstream effects and I I didn't really see it articulated here I mean that the I mean like the issue by the way like it was really to start the conversation it's not the actual day for oh you know what we're going to do on the on that week me or whatever at the top level I agree I mean I think at the same time yeah who the cab become you know more implementing implementation you know focused I don't know like I like that right now it's a little more the spec level you know like functional and not so much at the you know - too low into the details right and I think that if we have the right participants in that working group the implementation kind of pulls in place more in github issues and so on not in the actual dark like the actual dock is more like tracking like the high level like does that even make sense right for all the systems involved and depending on the change there may be a cept that needs to actually certain cap don't make sense without an accompanying except and so there's no point in like talking about you know what database tables you're gonna migrate in the car when there's like very associate itself I also agree that this I think the cap is the wrong place for this kind of stuff the cap is evolving as its implemented and then there's a key there's like there's a point where it becomes reasonable to think about the details for downstream but the high-level details can be thought of separately and should be done in a working group and I think most of the time there should be a set associated with the cap because something is motivating this work right and that should be the self yeah that's kind of what I was gonna say Eric like maybe we should have a new standard which is like we don't accept caps that don't have sex and this EPS might not be like a hey here's some you know new off protocol that you know climb server need to implement or something like that new end points it might just be like hey like Horizon is gonna be broken by this and we know lots of people depend on Horizon so it's part of because that's that's not oh and there can't be a rule right I mean if we like fixed like when we fix the bucket list or whatever you know like that you know you don't need a set always but like you know some when you're adding a new feature like it generally is gonna make sense to have a step involved well maybe it's a question that you have to answer does this require a sensor is known link like so maybe one of the header fields should be like associated steps maybe there's multiple ones right there's new feature that can be used in two different ways so so it's a kind of metadata thing that needs to be out it well while we're on the metadata this is this is kind of minor but you know I mostly think that's fine but I'd like to argue for keeping the term author instead of recommender and maybe having a maintainer instead of an owner just because I want to make sure that everybody who contributes to writing a cap gets you know appropriate credit and the term author kind of suggests that you deserve credit for something whereas recommender doesn't necessarily carry that same connotation I mean those are names from yeah I guess they are from different worlds like the names I used where the from the RACI thing right so and that's why I stand out oh just doesn't race to use authors into a for often no according to be read it means several different things one of which is how many things which like definitely makes no sense in this context yeah what what makes no sense acceptor yeah yeah all names of superheroes yeah like we can try to tweak it as long as we have clear definitions of what those things means right yeah yeah I think just to chime in again I I think like what we're describing maybe is a little bit closer to our current process and so I'm worried it might fall into some of the same pitfalls like I mean maybe it's just kind of a terminology thing like in my experience except did doesn't talk about the rot changes the Horizon end points I I've never seen that in this app and and I think I don't care what document it's called exactly where it appears but I think there needs to be a link in the cap at least if not included directly in it that explores changes to Horizon changes to the SDKs because I think that's been the issue so far as we have a disconnection between the cap and then the implications it has downstream in this nasty case so as long as we cover that in some kind of dock maybe we kind of change that aceptas to include that yeah or we can do that posit ori or some new place to store that particular kind of dock right Mike yeah like I said like a cap links to except in acceptance to like a you know Horizon working document or something whatever we call it yeah I support this I just want to make it clear that like we may not find all this stuff at the right time right it's good to think about it at some level but like the the earthy change was very subtle it's in its one line in a piece of XDR that you have to notice and then realize that actually that's implemented within in 32 in Horizon and then there's all these consequences we are not gonna get all the things so I wouldn't want to like gate gate the cap and the only way we get those is if we like release some protovision of core and then it had a long time to implement all the Horizon changes and discover them I think in the same way that the cap evolves as scored as their implementation some of the Cottagers will become visible as you think 3ds annotation and the SDKs or Horizon yeah yeah and my point was I think this due diligence had to happen before the cap gets into the final state even if you missed some stuff I mean no but the point is that you know what Eric was saying for example all days that change people have to actually go through every change think about every change because that's how we do right the cap we have to actually think about you know in detail what does it mean to make that change in call right same thing for the other systems I feel like part of the surprise with the feeching with the with the change in columns in the Horizon was just how long it took right like it maybe I'm wrong but I think it was hard to know and so you started doing it like oh man that copying and pasting like basically creating these two new columns is gonna take forever in like okay yeah about that move yeah let alone I guess but like in general right it's more like we should be like maybe we shouldn't we would not have identified this this free change until what much later it's more about the pattern right that we should evolve if you think about you know like oh there's this schema change coming and maybe we don't done exactly like the implication but we know there's this big schema change yeah yeah and then hopefully you know the more eyes we get on that thing people you know remember all when you make this kind of change you know it's going to you're going to take a hit yeah I mean I definitely support this I support through instant due diligence upfront and trying to think it through at a point where we can still make changes in the cat that seems like a no-brainer to me I'm just saying to understand all of the implications is very difficult and we're not going to sit down and think really hard and figure that out just to be sure okay I mean do you like the idea of listener listening out the changes to the Horizon API for example before finalizing the cap I like is this some kind of summary that says what we think the impact is our high level I just don't know how detailed that can get but we you know we'll try try our best and so happens now the other is it says representative group of stakeholders which is I guess intentionally vague and so we have to be careful that we don't fall into the trap of thinking about the consequences fall for something like Horizon and then forgetting something else like maybe the consequences for hardware wallets you know for example yeah definitely yeah that's that's the reason is vague is because basically there is a when the working group is kind of forming it should actually decide who are the members right I also think like those members might be thinking over time that's something I've been thinking this whole time or it's like at the beginning like at the beginning you need people to know how poor works you know plus some people who have like a reason to motivate this thing and then as the core part of it develops and it's like oh okay like we have these ideas for how we could do things like let's make sure we're like none of these are offensive to Horizon or offensive to Hardware walls and then you start roping those people in and you got a different set of voices so everybody gets to spend a day with John what a present for everybody okay I mean obviously that's needs thought and work and it but I think that it should kind of kicked it off and we can talk that more I don't know that we're gonna come to any greater conclusion after this I mean it seems like we could talk about this on on the on the dead mailing list and eventually I feel like we need to update the readme or on the kathleen and probably like the actual template for Cap's - and work on working groups we should not even great to work on working groups may be a way forward is everybody can comment on this issue that Nico's raised and we can iterate a little bit because as he says it's not the we're not saying this is the dif we're saying his a starting point so we should have had this discussion great perfect so we'll start the conversation there which is issue 624 in the protocol really cool um it's I'm just gonna take one minute and say that you know obviously we're part of the way through all of this impacts what I'm the upgrade process protocol thirteen you know we delayed the boat through two weeks and I think we've learned a lot about just better notification um so I think you know the basic idea which I've post or is to work out the timeline for Horizon and SDK readiness and I think these working groups will help do that then to pose in a great guide that tells everyone what to do and where to find stuff message all the relevant channels and then to verify that key projects and the ecosystem are ready basically get them to write back to us and say we are ready to upgrade then I think do the tests enough upgrade then coordinate for the public nib upgrade and then once an upgrade happens we post an upgrade notice with all the errors and any information about how to use the new features so it's like all concise and that's again just a proposal that we did most of that with protocol thirteen but we didn't reach out specifically to key organizations until later in the process and it's gettin it's gettin it's gettin somewhat better but I'm open to any suggestions that anyone ever has about how to improve the process whose a key organization do we have like a mailing list of key organizations or something by the list yeah is that anyone can join inotify like places where anyone can join which are all of our public channels are notified out the wazoo right so like they get first notification they get notification every time that there's an update and a week in advance so any place where people opt in like but we also need to reach out to people who will not opt in to our own channels like so specifically what too late this protocol release is like making sure that crypto exchanges where you know they deal with a lot a lot of different networks and stellar isn't first and foremost in their minds it's hard to get their attention or get them to opt into a channel so yes anyone can opt in and we can check readiness or anyone goes opted-in but we also need to do some spoke outreach people who have difficulty okay radical so that that's the end of our first broadcasted stellar Protocol meeting how's everybody feel

Justin Rice hosted the first livestreamed protocol call, starting with a protocol-13 update (the validator vote slipped two weeks so exchanges could finish testing) and moving into the protocol-14 backlog. CAP-23s claimable balances are headed to final comment, giving wallets a way to separate payment senders from recipients.

CAP-33s sponsored reserves dominated the rest of the conversationhow wallets will coordinate the handshake, how sequence numbers complicate `create_account`, and why we may need a broader fix for delegated signing. The group closed with process talk: forming working groups, documenting downstream impact (Horizon/SDK), and tightening network-upgrade comms.

Key discussion threads:

- `Protocol 13` upgrade vote pushed to late June so exchanges can deploy; plan for better upgrade runbooks and readiness checks.
- `CAP-23` claimable balances (two operations, unclaimed funds go to the fee pool) ready for final-comment review.
- `CAP-33` sponsored reserves, handshake requirements, and the need for a general solution to sequence-number delegation.
- `Process` improvements: clarify working groups, capture Horizon/SDK impact per CAP, and keep ecosystem stakeholders informed throughout upgrades.

all right welcome everyone we're live-streaming this just so that everyone knows this is the first ever broadcast of the open protocol discussion which is a biweekly meeting in which we discuss and plan for upcoming changes in and improvements to the Stuber protocol generally these meetings are to review core advancement proposals also known as caps which suggests new features and improvements to the protocol sometimes we also talk about the process for perfect call improvement and we're going

<details>
  <summary>Video Transcript</summary>

[04:00] All right, welcome everyone. We're live streaming this, just so that everyone knows. This is the first ever broadcast of the Open Protocol Discussion, which is a biweekly meeting in which we discuss and plan for upcoming changes in and improvements to the Stellar protocol generally. These meetings are to review Core Advancement Proposal, also known as CAPs, which suggests new features and improvements to the protocol. Sometimes we also talk about the process for perfect call improvement and we're going to do a little both in this meeting. First we'll talk about two CAPs and one issue that outline proposed changes. Those are all for possible inclusion in Protocol 14, and then we'll cover an issue that relates to the process for the creation accounts.

[05:00] Finally, I'll just touch a little bit on the process for orchestrating network upgrades, because we've learned a lot upgrading to Protocol 13, which is has yet to happen. So we published some pre-reading requirements for this meeting there in the event description, so if you're following along, you may want to look at those so that you can keep up, and there's also an outline of the agenda on the left of the screen, I believe, and without further ado, I guess we'll just jump in. I wanted to start this out with a Protocol 13 update. So that's the first agenda item. Basically, after surveying the ecosystem, we decided to push the upgrade vote two weeks is supposed to be today, that was gonna be June 18th- to give people more time to prepare. Basically, most of the Stellar-based businesses that we talked to are ready right now, but several crypto exchanges aren't, and we just wanted to give them a little bit more time. so they don't break. So that's the Protocol 13 update news. Any questions? Okay, cool things that we have to talk about: our CAPs that are potentially for a

[06:00] Potential inclusion, and Protocol 14. The first is CAP 23 to part payments. It's been around for a while. We've had a lot of discussions about it. The current version is pared down from where it started. Basically, it creates a new ledger entry called a claimable balance into new operations that allow you to create and claim a club level balance. The idea is to be able to separate sending and receiving of a payment so that you can send a payment to an account that isn't prepared to receive it. CAP 23- is there anything else that I mean we talked about this a lot Is there more discussion that needs to happen about this? Doesn't want to have any questions. Comments. Jonathan drove, do you feel like you've gotten the feedback you need? I think we're ready to go. I think the only outstanding thing here is that, based doing what we decided two weeks ago or whatever, the last time we met was, I think, two weeks ago. where this isn't in the proposal yet. But instead of

[07:00] Trying to send funds back to you know, in basically, instead of like, trying to do this thing where it's like, oh, you try to send them funds back to the creator, but if you fail, you send them to the recipient. We're not gonna do that anymore, as we decided, it's not reflected in the proposal yet and instead we're just gonna, you know, unreturnable funds go to the feet pool. Basically we're already working on that in the implementation, but the proposal hasn't been updated yet. I just wanted to mention that. But everything else is as we agreed. I have a question. The question is, if I wasn't clear to me reading the proposal, if the account that's the created buyer or weak at 33, becomes the sponsor, do they always have the possibility of claiming back at the claim or balance, or does the creative, the creating account you need to add themselves as a claimant to the other claim of I. So the creating

[08:00] Accountant doesn't have any special privileges relative to any other account. It was only there for this bookkeeping about returning the, about return in reserve, but it's not special in any other way. You know, if we took the approach of like always destroy the reserve, then we wouldn't even have that information there. One thing I will mention is like we're not, like that created by field isn't gonna exist anymore. Like the CAP 33 functionality is going to supplant it, so there won't even. It won't even be there anymore. It won't look special anymore relative to any of the other sponsorship things. But no, there's nothing special about it. Does that answer your question me? Yep, great, okay, so if there are no other questions, the plan here is that I'm going to the people who are eligible to vote on moving this into Final Comment Period will email me by the end

[09:00] Of the day tomorrow and if this, if they, agree to move this into Final Comment Period, we'll post on a mailing list, get final comments from anyone out there in the community and go from there. Sound good, cool. Next on the agenda: capped 33 also for potential inclusion, and Protocol 14: sponsored reserves. This proposal allows an entity to cover the reserve for accounts controlled by another party without getting that other party control to the reserve. It basically extends account and ledger entries so they record pertinent information about sponsorships, creates new operations to initiate and terminate sponsorship and update sponsorship information for existing ledger entries, and so the goal is to allow people like asset issues and wallets to cover the reserves for users. This one landed more recently, and so I guess my first question is: does anyone have any comments, questions or suggestions about the sort of recent version of this that Jonathan turned in? I had a question. In order to use this

[10:00] Stuff, you have to have creation of the sponsor. The sponsorship happens by one account and then there's a closing out and that happens by the other account. Right to make sure the this thing is sandwiched properly with angel not supposed to authorize. Question is: how does it work him? Like a workflow, a kind of vibrant, like workflow and a great Lee's account? I was struggling to kind of see in my head what the path was, because you have to get the account, the two accounts, to coordinate with each other. Do we have an example of that somewhere? What could somebody talk me through it? Enough revived, so that certainly should answer this. We might also have more context on this than me. So if you feel comfortable taking this money, I would appreciate that, but otherwise I will do it. Yeah, I can talk about it. I actually also have a question about this and a concern

[11:00] About how, specifically in the situation that Eric brought off by creating accounts, but yeah, so I think if it was to work, how to read in the proposal, the client- a client on the server- would have to be negotiating. So the clients gonna make some initial hello, that starts off the process. The server's going to create the transaction, assign an account that can use that sequence number for the duration of this whole handshake. The transactions going to have to be signed by them and passed back to the client, sigh and then submitted. Say there is like this back and forth negotiation that has to happen. The sower or the service that's creating and sponsoring, create an account and sponsoring it can't do it on its own. Does that answer your question, Eric? Yeah, I guess so, although I start having more questions then, like what happens if the

[12:00] Account doesn't exist? Just fine. So do you think it would make sense to explain this in a non normative section of the document? I think we actually need a new set for this and it's very analogous to what set 8 is to CAP 18, basically how does? How do you actually do to the negotiation off-chain and then, before you submit to the network, so I would. I think that, Lee, because you guys are gonna be probably one of the first implementers of this, it would be great to have you guys figure out what makes sense to you and then inform the rest of the ecosystem or ask for comments. Yes, I think. So I actually have a concern with this. So my understanding of why we have that second, that's that last transact, so their last operation to confirm and close it out, he's:

[13:00] We made what we want. We see value in the. account that's being sponsored, confirming that they actually are okay with being sponsored, and, I think, a problem with that. So I think that works for a lot of cases where the account being sponsored can be the account where the sequence number is coming from. But for the create account operation, I think this is going to be really difficult at scale because the service, the sponsor, is going to have to lock up an account with a sequence number during that process of that negotiation, and I think that's gonna be. I think that's going to be problematic enough that this way that could prevent this from scaling. And we really want this to work, sponsorship to work at a significant scale, because it's primarily for an enterprise that's going to be sponsoring lots of accounts. So I'm wondering if, like, if we're putting too much value on what this soul's want- the problem of the souls- and if

[14:00] This will create a larger problem. Yeah, that's a good question. I mean there's definitely like this is not the only sequence number provision problem in the world of Stellar, for sure. And I think, given the like you know, fee bump improvements that are coming in Protocol 13, this is kind of a step backwards in that regard for this particular issue. I am a pretty strong believer that there are a lot of advantages to making this like double signature requirement. I mean like I think we're gonna be here for months otherwise, just in the sense of like me going through and just like making sure that everything is still going to work and doing sanity checks on everything, because it weakens the backwards compatibility constraints a lot. That being said, like David was at our last meeting talking about. I think you

[15:00] Actually sent an email about this, which I'm going to confess to not having read as good as I feel have read it. It's not the startup mailing list. I can post a link to it somewhere else. If you want, yeah, review it after this now, because it's seeming more relevant. And I wanted to start by saying, like, whatever I'm about to say is like definitely not gonna happen in Protocol 14, no matter what, because there's just no, there's no time. But like, as a longer term solution, like providing some other kind of mechanism to avoid this need to, you know, manage sequence numbers for all sorts of random stuff. That could be the long term solution to this kind of problem, you know, using something like a hash preimage or something else that you know to do it, Mike. I think that that's like the calm. That was the concept, right, David? Like some other kind of authorization thing. Actually, it was basically saying that you can sign an operation and then that up, you don't have to sign the transaction. Someone can use the transaction, he, someone can

[16:00] Include that operation in a transaction and it will not increase the signature requirements on the transaction envelope. Oh, so that would allow you to sign the transaction envelope at a later time. Basically, once you've already tripped, like at a time when you can choose the sequence number, right, like basically, let's say, I want to allow you to add a particular trust line to my account, or I want to allow you to authorize a particular trust line on an account. I can just sign that one operation and give it you and you can include that operation in whatever transaction you want. Yeah, that's an interesting idea that would mitigate this problem. I mean, I'm kind of like backing out on like. I'm kind of like backing out on this, basically, and look, I don't have a good way to avoid this problem today, given this design, and my stance is kind of like the merits of this design warrant searching for another way to avoid this problem, which is like a

[17:00] General purpose Steller problem. Anyway, you know, trying to solve it for this specific issue isn't gonna solve it for some future issue where we're going to encounter the exact same thing and they need to engineer some solution for that as well. And, to be clear, the problem arises specifically with the create account operation, correct? Yeah, and it specifically arises there just because the sequence number is being locked up by another party. So you know most the time when you're creating accounts- right now it's not such an issue, because the service loss of the sequence number for it for the time it needs it to be locked up for- but this is gonna be looked up for the time- requires to party to negotiate. Yeah, I mean one approach you could kind of take. It's basically the stance that, like, you need to do. Basically, you set some time limit on how long this negotiation can take. You know

[18:00] This off-chain communication. You say like basically, like, hey, I'm, unless you take like up to one minute to sort this out with my server, and otherwise you have to like reinitiate this with me at some later time and in that time again you'll have one minute and then this could allow you to use like a small pool of accounts. You know, you only need to maintain one minutes worth of accounts, basically to use a sequence numbers. Obviously it's not amazing solutionn it's not elegant. It comes back to the channel problem. Again sounds like a minutes worth of accounts for a high through, but service is a lot of accounts agreed. Well, I'm not so sure. I mean, signups are typically a very small fraction of what happens on a service, and so that's, I think, when you do create account, during escrow operations as well, so I'll make it. Might make a trickier, but I don't know. My take is like the you're probably gonna have to build a channel system anyway with things the way they are, and so sure. This

[19:00] Maybe means that you need a hundred channel accounts rather than ten, but it's not really fundamentally changing the situation. Maybe that's a really optimistic, I don't know. Yeah, I think where I can see the challenges is just in typically, at least how I know by- we have implemented this before- is you take a channel account, you lock it for some predefined operation that you're gonna run in code. So just becomes more complex to say, okay, I'm gonna lock that based off someone else's actions and or some timeout. Yeah, I agree, it's just building on existing complex in here. So, yeah, it's not really new complexity. Also, I think the timeouts are in the same order of magnitude, right, like we're talking at Terra transaction, typically valid for, like, let's say, a minute. I would don't imagine you would go, you know, longer than that for those

[20:00] Interactive things anyways, I mean not know inter, don't directly. I mean it's really just you're physically passing this to the client. They kind signs it and you know, I know, that it's probably the same thing. That's what I imagine. I think this is a good opportunity for us at the SDF to put some open source example of how to actually achieve something like this in a- you know, in a fairly high throughput manner. And, like John said, I think that this specific problem doesn't actually relate to CAP 33, it's more of a general store problem. So maybe trying to solve for this right now is counterproductive. I mean, on the other hand, it would be nice to at least commit to some way of solving it. You know, like,

[21:00] If there's an assay, you know this is gonna be a problem and what we do is we approve CAP 33 and then, you know, followed by six months of discussing which of like four approaches should we take to solve this problem. That could be an issue. I don't think so. I think there are also, you know, like we have to solve it in general, like it's not just for that particular operation, right? Like you won't even like a paycheck 18. You need some way of doing that efficiently. I guess, happy, yeah, then maybe they should be disgusting. Maybe there should be just a short, non normative section of the CAP that discusses the need for some kind of mechanism and then subsequently, CAPs can cite this, you know, will sort of provide ammunition to get whatever a solution would come up with over the line later on. Yeah, I think that's great. Now I'll add that after this meeting or sometime later this week. Just a little discussion about how this is like. It's an annoying

[22:00] Source of complexity. It's probably worth it nonetheless and it's just a manifestation of a bigger problem that we're fighting all the time. And then that, and then the plan would be to create some sort of group to solve this larger problem, like a working group. But from what I understand this CAP 33, we could move on to Final Comment Period, because it seems like there's not a way to do it that doesn't encounter this larger issue. Is that correct? Yeah, I mean my stance, that would be like it. If you avoid this issue, you'll find a difference, like we'll find the other issues that were problems with CAP 31, which we rejected, in favor of this. So it's like you can't avoid both sets of problems. You have to pick which one you want. I'm picked this one, this set of problems, only from the perspective that, like they're problems that are general purpose manifestations, not single purpose, and I think that the other benefits are better is on top of that. But, John, you think you can add this language before Final Comment Period.

[23:00] Yeah, I mean like we make modifications to these during implementation also, and then we're going to the implementation period. So, yeah, I mean I'll add the language and it'll be there during the Final Comment Period for sure. So you'll add it and then we'll vote. Okay, John, when John's added it, I'll submit it to eligible parties to vote on and then we can see. And if it, basically, if people are like no, we don't think it's ready, we can bring it back in the next meeting. But if people look at it and decide that it is, we can go ahead and fold it into Final Comment Period and open it up for final comments. cool. I had one other question: other operations. You said other operations will make it semantics and what its behave correctly proposal. That's, Spencer, that might include. I'm having a little trouble hearing you, Eric. Can you say that one more time? Yeah, the other operations need updated semantics in order to behave correctly.

[24:00] Can you just give like a high level view of what that might include? Is that something we need to worry about? It's not something that I'm already worrying about. I'm working on it. I was working on it right before this meeting actually, but basically, but like, what's kind of what kind of needs to be done is, like, everywhere where we do like a, where we change the like account numbers of entries field, we now need to do it. We now need additional logic to say like, hey, like, what's the response? Err, oh, if there wasn't, and then do what we used to do. If there was, then we have to do all this other stuff, like, oh, like, check the sponsoring account still exists. It doesn't have to still exist, for example. So, like, that's a new failure mode. I haven't worked out the precise details on this because it's like I need to kind of go to the implementation and see what's gonna work, and that's why it's kind of very nebulous in the proposal, but the kind of consequences you're gonna be like potentially a few new failure modes that are only possible with sponsorships and basically just

[25:00] New code for me to write, but every just perspective. Everything will kind of just like work, the same like when a create account works. It'll just work, and you won't really be able to tell the difference, other than some sponsorship. The information will have changed. Okay, so it sounds like most this is internal to the implementation, but we might see some new error codes, yeah, and like that. Those kinds of changes are where, like we have like the ledger entry extension v1 and the account entry extension v2. Those changes are where those things will, we will be, ma will be maintained. So you know that that's pretty much what it comes down to. Okay, is there anything else there to talk about in relation to CAP 33. Well, I feel like the plan right now is John gets back to work. That's this extra session. You send it out and see if it gets voted in final, comically, but I

[26:00] Don't want to close it if there's still questions- just want to say that it's a great CAP John, much better than CAP 31. I think I really like the whole moving things to the off-chain logic. Really nice cover. I appreciate that great. Well then we will move on to the next item on the agenda. That's issues 622, which is about changing the application of clothes. Fine, basically, it changes the clothes time for a transaction so it's set for the ledger after the transaction gets a bike, because right now in a bank transaction we use the clothes time decided during consensus and that can create issues, for the transaction gets accepted but into a ledger but fails later. I think this is just a just an optimization. Does anyone have any issues with it? Does it feel like something that should be worked on? For Protocol 14? Yeah, it's an annoyance,

[27:00] Basically false about contracts and we are kind of hanging out those things over time. This is a small item, so that's why. Well, yeah, I'm not sure I understand the issue right now. Who decides the time? That's evaluated against time balance. It is not about deciding the time. This is about all we reason about the time from a transaction ready DT point of view because of time balance, right, okay. So time downs are you know we look at? We compare it to the to some time? Right, and right now we use the time that were this tidy during the consensus round, right, and this is wrong. And so in the wait time, you're proposing is to use the time from the previous

[28:00] Ledger, because the time from the previous ledger was already decided when you were checking for validity of the transactions when they were submitted. I mean, this seems somewhat dangerous. This means like, if there's an outage, it's possible that we can apply a transaction that's like an hour old or something. Yeah, that's yes, and the first time make also jump by an hour, right, so there's no. Like with we have to decide. I mean this is not a. You know that's just the way they know. You have to make a trade off you know what happens. You have an outage. Which transactions you want to reject. I guess. So like, let's say that, like we have an option where I have a transaction that I can submit that will trade X for Y or something right. And since I don't know the value of x and y in an hour, you know,

[29:00] Like we agreed on this now, so now I, could theoretically, you know, toss the network and get like a free option to, you know, basically make my decision with an extra hours worth of information. I mean, obviously the alternative is- and that's a lot harder- is to remove those transactions from the transaction set and the things that we cannot do that right now we have no way of doing this right. Consensus is still running like he can't change the transaction set. I mean, I do see other ways of doing this and I haven't, you know, haven't thought deeply about this, but just you know. So another thing if you do is, for example, when you nominate a transaction set, it could have some expiration time or something, and then, but that's not your fist, okay, you

[30:00] Know, bit based on, or you could kind of like- I'm not saying that you would have you would look at very DG based on- unlike some heuristic on the time stand, awesome. Another saying: like you know, currently we sort of take the largest transaction set when we're sort of combining multiple nominated values and now maybe we could take the largest transactions or the transaction set with, like the most number of unexpired transactions or something, but you still end up with some expired transactions, right? That's the issue here. Is that those guys? What do you do with them? Because it is basically the? I guess the reason we have this problem is the close time and transaction set are kind of decided separately. Could we modify our

[31:00] Validity checks to like- I'm specifically thinking about David's like one hour window thing that he was talking about. So this is still under the assumption that we're gonna make the change described in 622. But could we modify the validity check such that you won't vote for anything if you're not Byzantine, that is in? Basically it's like transactions, time bounds are checked both using the last closed time and the current time, because then it's like you wouldn't vote for something from an hour ago because it wouldn't have been valid using your current timestamp. It has to meet those conditions to work. There's the only vertical level change. It's not that you only if you do that, you only reduce the chance of having a bad time stamp. We don't make, you, don't eliminate it, and so that the main- I mean it's

[32:00] The main issue here- just that we have garbage in the set of transactions that we can't charge right, yeah, right now, no, it's not gathered, I mean it's a. It's more like that. We end up with transactions that are accepted for, you know, during consensus, but because they are now, I graduated against a different time stamped and the one from you know when they were nominated did now becoming valid. So now you have like those smart contracts potentially getting dust right where, if I, because you know they are valid when consensus starts and now invalid during consensus and yeah, they are failed transactions and they will consume that account number. And now, maybe that smart contract is that way they don't consume sequence number. The bug is but 622. That's what the core of the problem is, because, you know, we have

[33:00] The invariant that anything that gets into the ledger, we're going to guarantee we're gonna take the fee and we're gonna take the sequence number and so did. That's the thing that we're betting law wants to combat here is, you know, getting your smart contract broken by one of these like boundary case time stamps. Well, this is another way to solve this would be, say, authenticated operations. So I feel like there are other things that know why you think that know how this has nothing to do with the authenticated operations. This is time stamps. Well, the authenticated operation gets rid of the problem of consuming sequence numbers. It the part of the problem here is how brittle a lot of these protocols are because of, like, sequence numbers, right. So the issue that

[34:00] Sometimes don't work, right. So, like you're saying, like, yet you could fix certain smart contracts by using, like those, you know this new. You know like, basically use a different sequence number. Basically, from you know a different account, you offload the sequence number, some you know live account basically, but yeah, that's not what we are talking what we are talking about. You know, sequence numbers in general, like today, we do see, do like once in a while Ledger's will failed time. You know in the set of trade transactions. I understand, but I'm saying that the one of the arguments in favor of this is that right now there are annoying situations that break certain protocols because a sequence

[35:00] Number gets consumed by a transaction with an invalid time bounds. And I'm saying that, well, because of CAF 33. You've already said there's a need for something and one of the ways to do that something would be the authenticated transaction with the authenticate operations. Not saying that that's the right solution, but it just so happens that authenticated operations also solve this problem. All right, no, it cannot hold it right, like you're saying that no smart contract would ever rely on a time bound or something like it. Yes, no smart contract, that ideally, smart contracts would not rely on sequence numbers in a way that breaks if the sequence number gets consumed by an invalid transaction. That doesn't sound that plausible to me, actually,

[36:00] Because, on Elections, if you do that right, not only that, but you can't do the bump sequence trick without that. And you can because of the way I mean, at least though I'm not saying this is the right answer, but it's an existence proof that you can do this right because of the way that, because the authenticated, operations can depend on there being some other operation in the transaction, that other operation can be a pump sequence, right. So we've got existing smart contracts like. What about ones who already have this problem? Then they'll have a different problem. If we do 622, Oh, like only a line, the only reason you would have a problem is the DOS situation. If you have, like those funny time windows, normally it's more like starting from a certain date. This is valid. You know

[37:00] Expiration. You know if you have an expiration and you don't write around the expiration time, I can see that this is a problem regardless. Right, we have this is not a sole thing like well. You basically rely on the fact that the network has a semi accurate time, right, but in the event of a dirty, not accurate. It's going to be off by some number. Look, I think that you know there's a problem here. I think that if you were to write up like a requirements list, my suspicion is that I could, you know, propose some alternative that doesn't look like the proposal here. Whether that's better or not, I don't know, but I think it would probably be worth considering multiple

[38:00] Approaches based on a kind of specific, kind of like a slightly more detailed description of the problem and like what we're trying to achieve. Does anyone object to taking that course, basically writing up a requirements list and getting David an opportunity to come up with an alternative solution? That's fine. It doesn't have to be like you know I'm not trying to create a lot of make work here, like you could just be. You know a couple simple examples of what we're trying to. You know scenarios that were tranqued where we're trying to avoid a problem, but I think honestly that it would be. It'd be good to think about it a little more just from the perspective that, like I want to try to understand that da scenario well, like, is it a problem or does it just sound like a problem? I'm not sure that it's action a problem, but I'm also not sure that it's actually not a problem. It's a big existential question. So, like, I think

[39:00] It's worth looking at least a little deeper about this and making sure we know what we're doing. I think we're also talking about that type of scenario is quite a bit already on the mailing list, I think, because David had this other change to the timing bounce. To remember David, like that was like what yoga. At this point I remember we went back and problem on time bonds. That's, basically, is what ended up being replaced by CAP 23, I think. But in that proposal he had some interesting new time bones, right, I had like preconditions, I think. But there were some discussions around like those type of things, like what happens when you, when you're like an attacker delays the network. You know what other type of properties you are trying to get here, and maybe the issue is that we don't fully right now we don't have basically

[40:00] A written statement on what we expect smart contracts developers to do when you have this type of attacks. I think that's made it just you know one of the other things that we need to think about here. Yeah, so, yeah it. Basically what I'm saying is, before someone invests the time to like write a whole CAP for this, let's just like get some requirements down and just, you know, at a subsequent meeting, just talk through like whatever approaches people have and come up with an approach. We think it's like the best approach because there may be other approaches, maybe not, maybe I'm wrong, but that seems like a great solution to me. Cool,

[41:00] Any other discussion about this. Are we ready to move on to the next item? Great, so the next item is issue 624, which is improved the CAP process. So it clarifies the role of working groups. Also, it tends to take into account more information about the impact of proposed changes on downstream systems. Thoughts, questions discussion that we want to have about this. I mean, I guess for me it makes sense to better figure out how working groups create CAPs and who owns them and who participates in those groups. And I mean this proposal made a lot of sense to me and then I think it's just a question of starting to experiment with it and seeing if it works right, like maybe like as background, like one nice, when I wrote this stuff, like one of the things I also

[42:00] Took into account is that in the current like process that we have actually written in the criticals repo, it says that there is this, I know mythical creature that participates into the CAP process. That's the body or whatever. Yeah, that's right, that doesn't exist. So and basically, as I really, and also you know, with the way we've been working, more and more it seems to me that body was, you know, concept, was more or less a over engineering in a way from the protis point of view, in trying to take away, you know, like room for the working group to actually figure out who are the best people to actually have in that working group. So I think, like, if we end up with

[43:00] Like more, something more like what I'm highlighting in this issue, who would remove the body from the process? Yeah, I mean just generally object to the word buddy, it just sounds I just don't like the sound of it, okay, but also, I think if it's something that we're not using- and it was the same thing that John brought up on this with it with the test section, right, like I guess that we need to just look at the actual- I guess it leaves in the CAP reading that defines the CAP process and make sure that it actually adheres to a process that we feel good about and that reflects what we've learned. But then I think we also need to be relying more strongly on working groups, right, yeah, and maybe, like III, maybe this time we can. I saw that Eric had a question like: what does it mean to have the rest of the stack? You know, like, light up and all that like to me, the intention is to have the working group

[44:00] Think about the implications of that change in a more holistic manner. Basically, if we need, like very often, some of the changes at all, we need a set, basically, no, the sap is not should be basically written in parallel with the CAP, you know, by the working group, if that's the only way that thing can be used, because that's how we are going to find bugs in the CAP. Another thing on performance, because I think Eric, with Erica maybe I don't, somebody has asked about performance- I wanted people to think about performance implications in other systems as well, like the working group should be thinking about, well, the CAP itself, or he talks about, you know, the local performance impact, but at the same time, for example, one of the most painful changes in Protocol 13 is- but it was very surprising to me, it

[45:00] Was the change that he column in Horizon, right the table, migration that takes like nine hours. Well, whatever, it's something you know, maybe we do- would have it made some changes, I don't know like. You know, like, if we had identified this early on. So this is kind of thing I'm trying to get to is get you know. Sometimes changes look trivial, you know, in the poor layer, by the implications up streams are just terrible, and I kind of want people to think about those type of implications early on so that we know we can make adjustments into. Basically, the working group would figure that stuff out, document it as part of the proposal, submit it to this group with all that documentation, so that all the research would be done. You know, yeah, a little bit more. What we were talking about, yeah, and to me that sounds great. I mean the only question that I have is a feasibility

[46:00] One right like if we had the all the right people to staff any given working group that we wanted to create. This would work. I just wonder if in reality we're gonna run up against issues where we just like we want to have three working groups. We don't have three working groups of people with the necessary insight just to build those working groups. That's my only like feasibility concern that make sense. I mean we can you know I run into that problem already and yes, we do. And at the same time- and I know my response is that if we don't have time to think about this, maybe we should not do it in that protocol version. If we do the due diligence, you know that goes with a specific change. That means we're not thinking about it right. So I think that the additional lift here which is reasonable is to basically improve the process of putting together working grade. So it's like improve what a working group does, define it better, add it to the CAP process and then also get

[47:00] Better at putting working groups data, which is seems reasonable to me and my hope also made that maybe the chair on the top would be. If we have more of those kind of lively discussions that the working group level do. They should become quite be a bit more. Those conversations, I think, end up being a little more inclusive from a ecosystem point of view, because they are actually touching a lot more different paths right now. I think the issues with any thread on the dev mailing list that our protocol changes- they are so far removed from the end from the actual developers that nobody can really chime in. Right, they don't see how this is really impacting them unless it's, like you know, obvious. So my hope is that, yeah, we can maybe get a little more feedback early on from the you know people that are going to use that those things in the

[48:00] Future. If anyone's watching this right now is like I would love to be in a working group in the future, you should email me just another org like I got it. You know, I think it's gonna be about going out and collecting people right inside, people with insight, people who are building stuff and making sure that they understand the potential implications that one of these chord changes have and getting their insight rate- yeah, that makes sense to me. I like the working group direction and being more inclusive of, you know, people on the Horizon team or SDK team or even application developers. I think one other element that seemed pretty central to me that I didn't- maybe I missed it, but I didn't really fully see it flushed out in this issue- was kind of the contents of the CAP and having an explicit section of the CAP that discusses the changes that we've made to Horizon. So, like to Nico's point, like

[49:00] Saying, yeah, we're gonna migrate this column and, within the base table, we're gonna change the schema this way: I'm going to add these endpoints, we're going to modify the go SDK to have these new calls or deprecated this call. That seems pretty key to have as part of them for understanding the downstream effects. And I didn't really see it articulated here. I mean that the. issue, by the way, like it, I mean like the issue, by the way, like it was really to start the conversation. It's not the actual day for, oh, you know what we're going to do on the on that week, me or whatever, at the top level, I agree. I mean, I think, at the same time, yeah, who the cab become, you know, more implementing implementation, you know focused, I don't know like I like that right now it's a

[50:00] Little more the spec level, you know like functional and not so much at the you know too low into the details, right, and I think that if we have the right participants in that working group, the implementation kind of pulls in place more in github issues and so on, not in the actual dark, like the actual dock is more like tracking. Like the high level, like does that even make sense, right, for all the systems involved and, depending on the change, there may be a cept that needs to. Actually, certain CAP don't make sense without an accompanying except, and so there's no point in like talking about you know what database tables you're gonna migrate in the car when there's like very associate itself. I also agree that this, I think the CAP is the wrong place for this kind of stuff. The CAP is evolving as its implemented and then there's a key. There's like there's a point where it becomes reasonable to think about the

[51:00] Details for downstream, but the high level details can be thought of separately and should be done in a working group and I think most of the time there should be a set associated with the CAP because something is motivating this work right, and that should be the self. Yeah, that's kind of what I was gonna say, Eric, like maybe we should have a new standard which is like we don't accept CAPs that don't have sex and this EPS might not be like a hey. Here's some you know new off protocol that you know climb server need to implement or something like that, new end points. It might just be like hey, like Horizon is gonna be broken by this and we know lots of people depend on Horizon. So it's part of because that's not oh and there can't be a rule, right? I mean if we like fixed, like when we fix the bucket list or whatever you know like that. You know you don't need a set always, but, like you know some, when you're adding a new feature, like it generally is gonna make sense to have a step involved. Well, maybe it's a question that you have to answer. Does this require a sensor? Is known link, like? So maybe one of the header fields should be

[52:00] Like associated steps. Maybe there's multiple ones. Right, there's new feature that can be used in two different ways. So it's a kind of metadata thing that needs to be out it well while we're on the metadata, this is kind of minor, but you know, I mostly think that's fine. But I'd like to argue for keeping the term author instead of recommender and maybe having a maintainer instead of an owner, just because I want to make sure that everybody who contributes to writing a CAP gets, you know, appropriate credit and the term author kind of suggests that you deserve credit for something, whereas recommender doesn't necessarily carry that same connotation. I mean those are names from. Yeah, I guess they are from different worlds, like the names I used, where the from the RACI thing, right, so, and that's why I stand out. Oh, just doesn't race to use authors into a, for often, no, according to be read, it

[53:00] Means several different things, one of which is how many things which, like, definitely makes no sense in this context. Yeah, what makes no sense? Acceptor: yeah, all names of superheroes. Yeah, like, we can try to tweak it as long as we have clear definitions of what those things means, right? Yeah, I think, just to chime in again, I think, like, what we're describing maybe is a little bit closer to our current process, and so I'm worried it might fall into some of the same pitfalls. Like, I mean, maybe it's just kind of a terminology thing, like in my experience, except did doesn't talk about the rot changes, the Horizon end points. I, I've never seen that in this app and I think I don't care what document it's called, exactly where it appears, but I think there needs to be a link in the CAP, at least, if not included directly in it, that explores changes to

[54:00] Horizon, changes to the SDKs, because I think that's been the issue so far as we have a disconnection between the CAP and then the implications it has downstream in this nasty case. So, as long as we cover that in some kind of dock, maybe we kind of change that aceptas to include that, yeah, or we can do that posit ori or some new place to store that particular kind of dock, right, Mike? Yeah, like I said, like a CAP links to, except in acceptance to, like a, you know, Horizon working document or something, whatever we call it. Yeah, I support this. I just want to make it clear that, like we may not find all this stuff at the right time, right, it's good to think about it at some level. But, like the earthy change was very subtle. It's in its one line, in a piece of XDR that you have to notice, and then realize that actually that's implemented within in 32 in Horizon. And then there's all these consequences. We are not gonna get all the things, so I wouldn't want to like gate the CAP and the only way

[55:00] We get those is if we like release some. Protovision of core, and then it had a long time to implement all the Horizon changes and discover them. I think, in the same way that the CAP evolves as scored as their implementation, some of the Cottagers will become visible, as you think, 3ds annotation and the SDKs or Horizon. Yeah, and my point was: I think this due diligence had to happen before the CAP gets into the final state, even if you missed some stuff. I mean no, but the point is that you know what Eric was saying. For example, all days that change, people have to actually go through every change, think about every change, because that's how we do, right, the CAP. We have to actually think about you know in detail what does it mean to make that change in call right same thing for the other systems. I feel like part of the surprise with the feeching, with the

[56:00] Change in columns in the Horizon was just how long it took, right, like it. Maybe I'm wrong, but I think it was hard to know. And so you started doing it like, oh man, that copying and pasting, like basically creating these two new columns, is gonna take forever in. Like, okay, yeah, about that move, yeah, let alone, I guess. But like in general, right, it's more like we should be, like maybe we shouldn't, we would not have identified this free change until what, much later. It's more about the pattern, right, that we should evolve. If you think about you know like, oh, there's this schema change coming and maybe we don't done exactly like the implication, but we know there's this big schema change, yeah, and then hopefully, you know, the more eyes we get on that thing, people, you know, remember all. When you make this kind of change, you know it's going to

[57:00] You're going to take a hit. Yeah, I mean I, definitely support this. I support through instant due diligence, upfront and trying to think it through at a point where we can still make changes in the cat. That seems like a no brainer to me. I'm just saying to understand all of the implications is very difficult and we're not going to sit down and think really hard and figure that out just to be sure, okay. I mean, do you like the idea of listener, listening out the changes to the Horizon, API, for example, before finalizing the cap? I like, is this some kind of summary that says what we think? The impact is our high level. I just don't know how detailed that can get, but we, you know we'll try our best and so happens now. The other is: it says representative group of stakeholders, which is, I guess, intentionally vague, and so we have to be careful that we don't fall into the trap of thinking about the consequences, fall for something like Horizon and then forgetting something

[58:00] Else, like maybe the consequences for hardware wallets, you know, for example, yeah, definitely, yeah, that's the reason is vague is because basically there is a when the working group is kind of forming, it should actually decide who are the members, right? I also think, like those members might be thinking over time- that's something I've been thinking this whole time- or it's like at the beginning, you need people to know how poor works. You know, plus some people who have like a reason to motivate this thing, and then, as the core part of it develops and it's like, oh, okay, like we have these ideas for how we could do things, like let's make sure we're like none of these are offensive to Horizon or offensive to Hardware walls. And then you start roping those people in and you got a different set of voices. So everybody gets to spend a day with John. What a present for everybody.

[59:00] Okay, I mean, obviously that's needs thought and work and it. But I think that it should kind of kicked it off and we can talk that more. I don't know that we're gonna come to any greater conclusion after this. I mean, it seems like we could talk about this on the dead mailing list and eventually I feel like we need to update the readme, or on the kathleen and probably like the actual template for Cap's and work on working groups. We should not even great to work on working groups may be a way forward is everybody can comment on this issue that Nico's raised and we can iterate a little bit because, as he says, it's not the. We're not saying this is the dif, we're saying his a starting point. So we should have had this discussion. Great, perfect. So we'll start the conversation there, which is issue 624 in the protocol. Really cool it's. I'm just gonna take one minute and say that you know obviously we're part of the way through. All of this impacts what I'm the upgrade process, protocol thirteen. You know we delayed the boat

[01:00:00] Through two weeks and I think we've learned a lot about just better notification. So I think you know the basic idea which I've post or is to work out the timeline for Horizon and SDK readiness and I think these working groups will help do that then to pose in a great guide that tells everyone what to do and where to find stuff, message all the relevant channels and then to verify that key projects and the ecosystem are ready. Basically get them to write back to us and say we are ready to upgrade. Then I think, do the tests enough, upgrade, then coordinate for the public, nib upgrade and then once an upgrade happens, we post an upgrade notice with all the errors and any information about how to use the new features. So it's like all concise and that's again just a proposal that we did most of that with protocol thirteen but we didn't reach out specifically to key organizations until later in the process and it's gettin, it's gettin and it's gettin somewhat better. But I'm open to any suggestions that anyone ever has about how to improve the process. Whose a key

[01:01:00] Organization do we have like a mailing list of key organizations or something by the list. Yeah, is that anyone can join, inotify like. Places where anyone can join, which are all of our public channels, are notified out the wazoo right. So, like, they get first notification. They get notification every time that there's an update and a week in advance. So any place where people opt in like. But we also need to reach out to people who will not opt in to our own channels like. So, specifically, what too late this protocol release is like making sure that crypto exchanges, where you know they deal with a lot of different networks and Stellar isn't first and foremost in their minds. It's hard to get their attention or get them to opt into a channel. So, yes, anyone can opt in and we can check readiness or anyone goes opted in but we also need to do some spoke outreach people who have difficulty: okay, radical. So that that's

[01:02:00] The end of our first broadcasted Stellar Protocol meeting. How's everybody feel?

</details>
