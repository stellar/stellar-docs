---
title: "2021-09-09"
authors:
  - david-mazieres
  - eric-saunders
  - karen-chang
  - leigh-mcculloch
  - nicolas-barry
  - jed-mccaleb
  - jonathan-jove
  - orbitlens
  - siddharth-suresh
  - tomer-weller
  - justin-rice
tags: [legacy]
---

import YouTube from "@site/src/components/YouTube";

<YouTube ID="yz63i52W2Ek" />

- [Music] right now [Music] hello everyone and welcome to another stellar open protocol discussion um as per usual in these meetings we discuss potential changes to the stellar protocol that take the form of core advancement proposals or caps these are technical specs they suggest changes to the stellar protocol that allow the stellar protocol to add new features and evolve to meet the needs of the ecosystem we're live streaming them so that anyone who's out there can follow along but again i do want to point out it's technical so if you are watching this you should probably look at cap 21 in order to understand what we're talking about that is what we're going to be talking about today cap21 and you should also join the stellar dev mailing list where offline discussions about these changes take place um also there it we do keep an eye on the discussion box so if you put comments or questions in there they do help inform our decisions going forward um we may not actually address them in this meeting although if they're super germaine i may bring them up today we are focusing specifically as i said on cap 21.
- cap 21 basically is a cap that uh lays the groundwork for building payment channels on stellar so what we're talking about today sounds a little obscure keep that in mind payment channels are things that allow multiple parties to securely transact off chain and periodically settle on chain and among other things that make it easier to build high volume use cases on stellar so changes to cap 21 are proposed by cat 21 they allow for payment channels um last time we also discussed cap 40 and basically got it to a point where it was near ready to be accepted but cat 40 is contingent on cap 21 and so here's where we are with cat 21 there are a few outstanding issues and questions that we're going to try to walk through today um i think that we are actually quite close to getting this accepted although we'll see what the outcome of today's conversation is so with that in mind let's just kick it off um cap 21 uh is what we were talking about today and i believe that you know the question is i i think that there are a couple of questions that came up on the mailing list and there was a question about transactions failing during execution that came up during the last meeting but to start with i think we should sort of try to deal with the outstanding questions that are on the mailing list and nico if you can just share the first of those questions with us so that we can start to discuss it uh i was looking yeah i didn't have those questions open uh hold on sorry so yeah so yeah i guess like the first question was more of a of a minor minor thing that i that i didn't we didn't discuss but that maybe is something we should be at least putting as like a potential thing that is um should that behavior that we have for uh tracking the uh modified time basically for the sequence number this be an opt-in right now it's kind of uh making this blanket change right like uh as soon as protocol whatever uh as soon as cap basically becomes uh active um we are going to kind of yeah make um like track this new um less modified basically in each account i mean it seems like from an implementation i mean the reason i mentioned that as a flag right instead instead of being a a like a protocol base right like in terms of the code it's actually the same thing like you have to in the code to deal with all protocol version new protocol version so instead of checking against protocol version we could check against the flag the difference is that uh it would make it that uh the tests for sure are going to be much simpler because now we can actually um just test that part like in a solution fairly easily whereas i know that uh lee in the past raised the issue and i think that's true that we would have to rework a bunch of tests uh given the the way they are written today in core at least i don't know in outside i mean it seems like a pretty big foot gun to have this flag right because now this is something something that's going to like catastrophically break all kinds of you know smart contracts and stuff if like this flag ever gets cleared or if like people don't realize that it's not set so it would be there would have to be like a huge huge advantage to uh having these like two kinds of accounts one that just blanket failed preconditions and ones that that actually implement the preconditions no it would not so the preconditions would not fail it's the uh the last modified yeah would not be enabled yeah so i don't know if it's uh yeah like preconditions i think that the cap says that if the you know if you take it there it's treated as zero yeah it's exactly it would be zero so i don't know i think if you added the flag we could we could actually we don't need to have a default at all we just say that a transaction is invalid uh if it tries to use that feature and the account doesn't have it enabled and for any account to enable the feature the new stack that's a right now you have to like constantly check that uh that when you're engaging in a protocol that looks like it's okay that that account actually has this flag set so i'm really i don't understand what benefit could possibly uh outweigh like i was saying it's a faster implementation so you know if we if if uh you know if no i just wanted to mention because i know that was raised before and and and by looking at the first kind of round of questions on that lee had on that prototype uh i mean it looks like it's a legitimate concern uh i mean so maybe can you explain a little bit better like what what the complication is of having it um it's around the setup i think of test code like a lot of times uh we're creating accounts we're doing all those things and i think uh those accounts are created without accounting entry extensions well with the uh yeah with the default change like that they would be created with the this extension and and then when we do the uh so basically we create like a snapshot of the ledger right um and then we run a bunch of tests for different protocol versions and here the protocol version is obviously in like for older protocol versions this would be invalid an invalid ledger state uh so i think there's a bunch of refactoring that needs to be done i mean they've been involved ledger state well an account with such an extension is not valid as of today right so i mean what what happened when you upgraded to account entry extension v2 why is this any different from the v2 v1 to v2 uh beyond v2 was an opt-in right like it was only when you were using uh i mean from everyone to each other liabilities right so that's what one uh number sponsored and number sponsoring like sponsors yeah otherwise we didn't change it we would not and touch it clarify something here is the the way that the proposal is currently written i i think what i'm understanding is that when an account is created it'll automatically have an accounting entry extension v3 at that point there's no way otherwise right and yeah so basically like the reason that this will be confusing david is that like uh there's like old historical tests which is a lot of the tests like many thousands possibly tens of thousands of tests um were written such a way that like the setup was done in the current protocol version and then you like time travel backwards in time and do the tests in the appropriate protocol version uh so we'd have to go and fix that uh yeah so you're saying that right now if i create a new you're saying that right now if i create a new account i don't get an account entry extension v2 correct you you just have null extension now maybe there's an argument that we should go and fix our tests anyway yeah i mean that's why i was saying like it's a it's a trade-off right like can i write you uh can i write you like an xdr converter that will automatically i mean it seems like we could i mean do the tests have like specific like shot 256 hash values of ledger state is that the problem well they can't though because there's other there's other values like like the ledger number and stuff that aren't there so what so what specifically is it that fails in the test like maybe there's just like an xdr there's like some template magic invalid xdr at as of uh currently so if i just so if you just write a an unmarching function that will unmarshal uh a new uh account entry to to an old one by stripping off the entry extensions v2 and three then we're good right all we need is that one function uh no not really like i mean yes yes you could in principle do that but like in practice what's happening is like uh we have these like invariants that are written right like they check that like nothing is broken uh things that things only exist if they should exist in effect like no negative balances blah blah and in practice like you could imagine the sequence of operations is like you're in protocol version 19 let's say or 20 or whatever whenever we get this done uh you create an account it has account entry extension v3 you travel back in time you go and do some other operation you know you're not doing like raw xdr operations it's like literally a seller operation so let's call it like a payment it goes and does this payment uh it goes it loads up this thing it loads it happily because it knows how to load it it's valid xdr in the terms of like what the xtr is sorry but it is marshalled or it's unmarshalled you're loading up the bytes so you're loading you're just have a simple structure floating around you're loading up the literal bytes um but like this is happening like deep deep deep inside of cell record like not not in the test it's like you know in the actual production code then you like load this thing up it's happy because it's good you go through you do the operation everything is fine and then you hit the invariant and the invariant's like oh no you're dead because you have this thing that shouldn't have been there the right solution is just to fix the test so that they do the setup in the right version do you realize you guys are like massively making the case that i was making several weeks ago that like we shouldn't be doing our extensions this way right because like if there's any benefit to doing this horrible cascading nested thing that's wasteful of bites wasteful of like program or keystrokes and wasteful of your right-hand margin it should be that like this backwards compatibility stuff isn't an issue but like no but david this is not this doesn't matter like this is invalid uh this is an invalid byte configuration in existing critical version that's what uh john just said it's a we have invariants that check that you don't have garbage in the ledger right that's garbage like from today's point of view it's garbage right it's not bad but i'm saying the extension it has nothing to do with how extensions are set up right but which should i mean shouldn't that be one of the benefits of doing these cascaded xdrs is this backwards compatibility with sources not by quad compatible that's the point like it this is garbage from today's protocol i'm just saying like this is we have to rewrite the test for this but we would also have had to rewrite the tests if we'd done it the original way that i did the extension so i don't i don't see what we've won by this latest change that i've made because a lot of things have been written wrong in the first place but the production code doesn't have to change at all the production code all just works exactly the same um that's the thing let's see well whatever okay so do we have to write about yourself the issue here is just tests right like the in the production code the way that it works as proposed is good it prevents there from being like a foot gun but it requires us to to rewrite a bunch of tests is that correct yeah i mean like the so the reason going back to the question i was asking right uh the reason i was asking the question was to see how bad would it be if we were making this a flag right that's that's the question yeah and david it seems like it's it's about yeah it would be really bad so that means we need to go fix the test i mean that's kind of what you know okay cool fixing test is easy it just takes time like we just need exactly it's it's going to be uh a bit of a time sync but that's that's okay i mean if we're saying it's basically a non-starter to have a flag it takes either it takes time or it takes xdr trickery right so it may be like oh no no no no no the xdr trickery is going to be like it's going to be validation protocol that's why we can't do that so let's uh but let's yeah that's fine let's take it uh offline regardless it's test test hackery right yeah so yeah uh i wanna i wanna just exactly one thing about like if we do if we were to introduce a flag i think it would have an impact on the usability uh of this stuff as well because like you're saying like we would never be able to just create a transaction for an existing account that hadn't enabled the flag which means that if you have an account that's just sitting there on the network and you want to interact with it in this way and with some new contract that maybe doesn't require interactive setup initially you can't just go and use these features of the network which is sort of inconvenient like so that doesn't won't affect the payment channel protocol that we're hoping to use this for right now but it might affect some other future thing yeah and it's worse than that because we don't have spv so like there's no concise proof that an account actually has this flag so it means that the receiver side would like synchronously need to like query some trusted horizon instance in order to like participate in what should be an offline protocol um so okay so flags fix the tests yeah it's bummer for the test but okay what was the second question time point this one should be a lot easier yeah the unsigned thing so my question was like uh i don't remember what happened there but like uh making that change is there is actually not a lot of like the mention in the backwards compat section is actually a bit misleading it says that uh you know nobody cares um i'm actually not uh true i'm not so sure uh i i'm pretty sure we do have in historical data uh transactions with uh large max time and uh and the other thing too is that to this code regardless you know core horizon sdks they have to handle those large numbers so in a way like making that change just makes everything more complicated so i'm not sure it's actually delighted to leave it unsigned i originally had it unsigned and then i feel like people objected to that i mean all i want is like i think all our time points should be like a type def right so it's like the only thing worse i mean i think either signed or unsigned is fine it's just it's bad to have like a mix of the two right like we should just be consistent about sign and unsign because when you start comparing signed and unsigned numbers as we all know like you know bad things start happening so uh we already have now we already have a mix claymore balances you signed time down to use unsigned i mean we're there so oh yeah okay so i guess out of luck on this one so i mean i i so i i really don't care i just want to be the same as other things so i guess i'll keep it unsigned and you know we we can add we can uh regular transactions that's kind of the the concern i have here is that it changes regular transactions so um i'll make it unsigned again what make time point unsigned and we'll deprecate signed uh time points in future operations another another option would be to make the time point inside the new precondition precondition version 2 signed since that's a new that's a new field nobody's going to be using that yet we keep the old time point as unselling for backwards compatibility i know it seems not worth it to me but yeah let's keep it unsigned okay sounds good all right so time points remain unsigned where we got next next one is around uh the section on how transactions get forwarded so um basically says that they are like those two criterias a and b uh that allows a node to decide if it's going to accumulate basically this transaction in its uh in its queues and um yeah so like the first question is that so yeah so i think that the uh the criteria b [Music] talks about um lower signals uh it's actually not clear it's it seems to imply that you are actually allowing uh transactions to be accumulated if we receive them out of order and i think this is probably not the intent that's the first question oh so in other words i say don't forward it but you should it should be stronger than that it should be just like throw it away like should yeah like it should not be better that's a good point right e is actually uh it should be it shouldn't have this lower sequence number i think on the does that make sense wait what do you mean there shouldn't be no you like right now you're saying it's invalid if either uh you know the condition is not met so this is those are easy right the the the b is what i'm interested in like right now it says it's invalid if there is already a transaction with a lower signal sorry it's invalid no it is valid that's what your text says is the polarity a transaction with a non-zero min ck german sequential atmosphere is invalid enough forwarded if either a the appropriate condition doesn't hold or b there are pending valid transactions with lower sequence numbers on the same source account okay so wait so what's and you're saying b i should say and in case b should also throw it away instead of storing it in memory well it's in valid right so we are throwing it away my the question it's not no no it's not invalid it's not invalid in a it's in validity it's valid but they're things with a lower sequence number so let me give you an example just to make sure we're we're on the same page right so you have a transaction with sequence number two but uh but that could execute immediately uh because it has a um because it has like um a min seek noun that's less than the default um and you have a transaction with sequence number one right so you could just execute two in isolation or you could execute uh one but you can't execute them both in the same ledger no that understands yes uh like but here um so if you receive uh so in your example i have two right and i have two and that and then i receive one what happens uh then then one takes priority like you okay so this then it makes uh so then this is kind of broken right it's actually under specified first of all it's why is it underspecified well you're actually not saying that you're talking about um i guess it so yeah you're saying you're kicking out highest uh transactions with higher signal that's right like you'll still vote for a block you know you'll still nominate a block that has it but is that a good property i mean it sounds kind of weird we already have this it's exactly we already have this exact situation no we don't kick out transactions like this okay let me let me tell you a situation i believe is exactly analogous which is that you receive a transaction with you know a fee of 100 and then you receive another transaction the same sequence number that has like a fee of 200 right and so now if you've already of course forwarded the 100 well you forwarded it fine but now you'll forward the 200 and if you see both you'll only forward the one with the higher fee and so that's the same that's the same way we're basically like among multiple mutually exclusive but valid transactions you need a way to prioritize them and uh i'm saying here you prioritize the one with the lower sequence number now why do you need this question oh because because the second one might could later be valid right you're not yeah unlike the case of the sequence numbers you're not you're not necessarily completely invalidating the second transaction you're just it will have to execute like a you know an hour later or whatever the you know whatever the min seek age is so or men uh whatever the yeah yeah so um so uh so you know you might as well like keep them the most number of transactions valid i mean if you're if you are strongly opposed to this we could i i i guess doesn't really matter we could we could favor the other one but i don't i don't see i mean i like it sounds like kind of arbitrary so that's why i'm i'm asking like why the first one shouldn't win in this case in some ways it might be more useful if the second one is yeah because we often say that uh we often say that sequence numbers is how you invalidate prior transactions so um it sounds like if we say that the first one wins then you could never use a higher sequence number transaction with a min sequence number it was lower to invalidate a prior transaction but someone could always well they might not be able to submit it because they might they might not it might have a a timeout it might have a a min uh i'm in time right which is generally how this works so um so like you know the reason i did this is because like you know it seems more useful to have like two if you have two transactions then they can both execute it seems helpful to have it be such that both can execute and you know if you accidentally release if you accidentally send out the second transaction too soon like you know i don't strongly care if you want it the other way around i can do it around it has some implication right from a dos money because you can basically like if you have this rule right well you don't say first win first one wins um you basically can so with the example this will collect more fees right the the current draft will collect fees on both transactions no you're dropping transfer you know let me finish so with the uh the example you give you said it's the same thing when the fee with the fee you have to actually outbid right so you have to constantly like if you want to uh cancel a pending transaction you have to update it right with this one you don't have to update it it it can be the same fee um no you are you you said uh the the that transaction that was in the transaction queue gets uh discarded because i have a lower sequencing number i'm not currently discarding it i thought that's what you were suggesting currently you're just not forwarding it so just to be clear david what you're suggesting is like imagine that i have seen like currency numbers 10 i submit a transaction with minstic 10 actual seek 12 and then i later receive seek 11.

This session stayed glued to CAP-0021, the set of changes that enable high-volume payment channels on Stellar. The engineers walked through how the proposal tracks account `lastModified` data, whether that behavior should be opt-in, and how to keep historical tests sane once the new account-entry extension ships. They also revisited the CAP-0040 dependency and made sure the upgraded time bounds (unsigned timepoints plus richer preconditions) will not confuse Horizon, SDKs, or existing transactions.

Key discussion threads:

- How nodes should order and forward transactions that use `minSeqAge` or `minSeqLedgerGap`, so payment-channel submissions cannot DoS validators while still letting multiple valid sequences coexist.
- Whether to rely on protocol version bumps or per-account flags for new metadata fields, and the amount of work required to rewrite legacy invariants/tests in Stellar Core.
- Ensuring the new preconditions fully interoperate with existing fee-bidding behavior and that accounts cannot accidentally brick their queues when a higher-sequence payment-channel transaction hits the network early.
