---
title: "BN254 Host Functions and ZK-Friendly Hashing"
description: "Protocol discussion covering CAP-74 (BN254 primitives) and related SDK/cryptography needs, including ongoing feedback on CAP-66 and CAP-67, plus early design exploration for adding Poseidon-style hash primitives for ZK and Merkle-tree use cases."
authors:
  - bri-wylde
  - dmytro-kozhevin
  - jay-geng
  - siddharth-suresh
  - yan-michalevsky
tags:
  - developer
  - CAP-66
  - CAP-67
  - CAP-74
---

import YouTube from "@site/src/components/YouTube";

<YouTube ID="8UmxYfDkWLg" />

This session reviews several upcoming protocol and developer-experience changes, starting with CAP-74 to add BN254 (alt-bn128) primitives to Soroban for better compatibility with existing proving systems and EVM-style precompiles. The group discusses why “just use BLS12-381” is often impractical for existing ZK stacks and why native support matters for performance.

The call then shifts into an early design discussion around adding Poseidon-family hashing support for ZK applications (e.g., commitments and Merkle trees), focusing on how to balance interoperability, configurability, protocol complexity, and metering. Participants compare approaches ranging from high-level hash host functions to lower-level building blocks and guest-side implementations.

### Key Topics

- General review of upcoming protocol work and draft feedback (including `CAP-0066` and `CAP-0067`)
- `CAP-74`: BN254 host functions
  - Adds `G1Add`, `G1Mul`, and `pairing_check` for BN254 parity with EVM-style BN254 precompiles
  - Rationale: ecosystem/proving frameworks frequently depend on BN254; swapping curves can be non-trivial
  - Notes on performance: BN254 pairings implemented purely in-contract are prohibitively expensive
  - Introduces metered cost types for BN operations (similar in spirit to existing BLS cost modeling)
- Poseidon hash support discussion (pre-CAP exploration)
  - Motivation: ZK-friendly hashes reduce circuit/prover costs dramatically vs general-purpose hashes
  - Need on-chain hashing for state updates (e.g., maintaining/updating Merkle trees consistently with offchain proofs)
  - Three implementation directions discussed:
    - High-level Poseidon/Poseidon2 hash host functions with selected parameters
    - Exposing Poseidon “building blocks” (sponge/permutation primitives) and implementing full hashes in SDKs
    - Guest-side implementations using existing field arithmetic host functions (measured as too costly today)
  - Tradeoffs highlighted:
    - Interoperability risk if parameters (round constants/matrices) differ across ecosystems
    - Protocol maintenance burden and “combinatorial” cost-type/function permutations vs fewer primitive building blocks
    - Metering concerns and performance targets for Merkle-tree workloads (many hashes per update path)
  - Practical suggestions raised:
    - Prefer a configurable approach (override constants/parameters) if metering can remain sane
    - Align defaults with widely used proving libraries where possible to maximize compatibility
    - Consider limiting scope initially (e.g., focus on common arities like arity-2 for binary Merkle trees)

### Resources

- [CAP-0066: Soroban In-memory Read Resource](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0066.md)
- [CAP-0067: Unified Asset Events](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0067.md)
- [CAP-0074: Host functions for BN254](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0074.md)

<details>
  <summary>Video Transcript</summary>

[00:00] All right, I'll get started. So welcome everyone. today I'll be speaking about [CAP-74](https://github.com/stellar/stellar-protocol/blob/master/core/cap-0074.md), which introduces host functions for the BN24 pairing friendly curve. So as you may know, Stellar already has support for has host function support for the BLS 12 through 381 curve, which was chosen over BN24 due to growing support for it and security. But we've gotten ecosystem feedback, that there are existing use cases, that rely on B2 BM 52 BN254 and adding native support for it will make it easier to implement those use cases on Stellar. The other option would be to adapt those use cases to use the existing VLS host functions. But, that would be prohibitively expensive in some cases. Cases. So this proposal the main part of this proposal is, that it adds three host functions G1 add G1 malt and a

[01:00] pairing check, which gives us parody with the BN24 pre-ompiles in the EVM. Now there have been some discussions about extending this in particular adding a host function for G1 multiscaler multiplication. But this proposal doesn't include, that. At the moment we're just trying to support the existing BN24 use cases and this should be sufficient and for any new use cases I the recommendation is to use BLS the CAP also specifies new cost types for the BN operations, which are similar to the cost types, that we added for BLS they're just a subset. Because BN has a subset of host functions and Yeah. It's a pretty short CAP. We also define the field and groups and yeah are there any questions?

[02:00] If there aren't any questions. Oh, Tor's typing. Yeah, it's a pretty straightforward CAP. if. If anyone has any questions, you can tag me on Discord and we can have discussion. but. If not, I'll pass it off to Jay to discuss adding host support for Poseidon and hash functions. Can you hear me? Yeah, I can hear you, J. Okay, wonderful. Yeah, great. I just want to add on what Sid just talked about. So yeah the ecosystem technically they could use all these BRS functions. But in the proving framework including like this the circuit like switching those curves off is it's in reality it's more

[03:00] challenging than u than we thought. It's not just a simple curve swap. But sometimes those protocols can be evolved and circles have to be recompiled with different curve. And. Then there's also different type of issues with like different u like proving systems support one curve versus another. So BN254 is mostly for backward compatibility. And also we've also added a solorone example of importing the BN 254 inside the solar contract, which works. But it takes I think like 500 million instruction to do one pairing. So, that is also prohibitive. Just wanted to point out the like these two specific rational why this is needed. Cool. Cool. And yeah I will start on yes thank you an yes. So the poseidon hash

[04:00] function has also been one of the requested primitive to add into solar. So I've recently just looked into this I don't have a CAP yet. But I will lay out what I found and sort of the different approaches u like informally here and I'll work on the CAP probably be ready in the next couple days. So yeah, first of all, why is this also needed in the proving in the DK application? The the commitment scheme is a lot of commitment scheme is hash based meaning you hash something. And then you prove, that this thing has been hashed is without revealing it. So the hash function is critical. And then for the hash function, that's used is also important in terms of the performance of

[05:00] the prover side. So from what I understand not expert. But from what I understand is using the right hash function like Poseidon can reduce the number of arithmetic argu the arithmetic gates the arguments by an order of magn like two orders of magnitude. So this is a fairly big difference, that's why a lot most of the like the circuits use these field based hash functions and poseidon and pose. Then two are two of the most widely used ones. So the next question is why do we need to support in the host, although the proof is generated offchain and the verification of the proof is doesn't involve hashing the hash is needed. Because some applications need to

[06:00] maintain for example a mer tree of different coins for example. And then to prove the coin's existence they can prove without hashing. But to update it on chain or some any kind of state, that involves hashing to be proven it needs to use a hash to update. So to be consistent we need to make sure, that the hash function, that's being proven is same hash function as what's being used for contract state update. So, that's kind of a big u overview of rational and poseidon functions these are not one function it's rather a family of functions or it's a rather it's a it's an approach, that based on sponges. And then ways to connect it connect these

[07:00] sponges to provide different permutations with different input. So it's fairly generic. You can in terms of you can plug in different parameters like for example. If you require a higher security parameter. Then the round parameters will be larger and also depending on how many inputs you need to hash at once also how many output the throughput the number of runs needs to be adjusted. So. So in the Prooseidon paper there's different implementations of different versions of Prooseidon given on the requirement as well as underlying field. So here we the primary field what we have to support for compatibility is BN24 and also BS2381.

[08:00] So, that's a two requirement and based on these requirement some of these parameters can be decided. But some of them are still can be some of can be cho choices. So we need to really decide what level of flexibility we want to supported with. So in this discussion last the discussion thread the last post I've laid out the three approaches, that I feel we could support it. So these are in terms of u from the most high level to the most low level. So number one we support it as hash functions directly. So for, that we will support Poseidon 2 and the two curves. And then so yeah I think this is the most straightforward one. But the

[09:00] limitation is, that we are we need to kind of decide on the parameters internally like there's a. So so in the Prooseidon paper they describe how to choose these parameters and they choose it. They provide a script to how to generate these parameters and own guideline on how to choose them and in reality from what I know seems like different applications sometimes generate their own parameters. I'm talking about these internal like round constants like these matrixes. So so. If if someone from another ecosystem, that generates a proof with a different instantiation of Prooseidon. Then potentially here we could not support it. So, so. So there's a little bit of compatibility risk we have to decide. But I think for

[10:00] this one most parameters are fairly straightforward. And. Then we need to make sure, that the major prover can be supported like the circum or no and we just need to make sure, that whatever parameter we choose is compatible with a major, that wants whether we wanted to migrate to Stellar with so, that's number one number two is to expose the internal poseidon building blocks. So as I briefly mentioned earlier the prociding hashing is a sponge based like a block cipher it consists of absorbing the input per permuting them. And then squeezing them. So one of the ecosystem member Antonio suggested, that we could support

[11:00] the generic interface to provide these. And then users can just choose the parameters or choose the security parameters field and all, that u. And then we can expose these options through the SDK. I like this approach. But I think it's maybe a little bit it involves a little bit of figuring out the requirements for the libraries. And then the level of details we wanted to expose how to expose them to SDK. I'm not expert in the this part yet. So I will say, that this one right. Now I would say this is a less favorable option. And for I think one of the main advantage for this one is, that Osan and Poseion 2 they use very similar interface. So potentially this one is more

[12:00] cleaner, that we just support this. And then the two different variants can be supported like more uniformly. Doesn't add complexity station. Yeah. Yeah, I think yeah, this requires the user to understand what they're doing and how to instantiate the hasher with these options. Yeah. Yeah I think yeah I'll also talk about number three. Because I think exposing the host function is the most straightforward approach. But in reality it's just the different parameters we can support them all. But then with the internal building block it's possible, that we could let give

[13:00] more flexibility. But yeah I Think, that's kind of the main rationale. But in how to do it we have to think it more carefully wanted to say, that for approach two and probably three it's not like we have to put much burden on the users it's just, that we can build SDK functions right, that do the same cache functions for example. Because you have an option one. But there is a huge benefit of you know not introducing like combinatorial explosion of the code types into host, which I think is a really bad property of approach one right it seems like instead of just setting a few cost types we need a lot of them and. If you wanted to do something more complex we would need even more and this is I think a lot of

[14:00] maintenance burden and a lot complexity in the protocol, which I think kind of would be nice to avoid. So I feel like these parameters could be implemented in the SDK. So user complexity would remain the same. The only question is really performance at this point. Yeah, I disagree on the cost type part. Because I think doing two and three can reduce the amount of cost types potentially. Because these are just three building blocks. And then yeah to be clear I totally agree with you. I'm saying, that I do not like option one. Because in option one we need a cost type per hash and per whatever curve and perity, which is an argument of the function, which is what I refer to this explosion right we have like three

[15:00] different inputs to, that. So I think we're on the same page here I agree, that we probably want to have more limited and like number of cost types, that can be useful building blocks. Yeah. Yeah. Yeah. And by the way, also the RT it I think for a minimum we just we need to support RT 2 to support the Merco tree or binary Merkel tree. But we fairly certain we don't need four right. Now and. Then one maybe. So at a minimum maybe just a R of two. But I would need to confirm it. If this is just what we need. Yeah, I still feel like it is like a really hacky design, right? Like we have a host functions, it has an argument. But it can have only like couple of values. But I don't know. I would really try to stay with the building blocks and do work on the SDK side. If it is feasible

[16:00] from you know the instruction count standpoint. Yeah. Yeah. So number three is going a step further. To to do this without providing any Prooseidon host functions. Because the algorithm itself is fairly they say straightforward. It's more like applying arithmetics repeatedly in iterations. So in theory most of the heavy costs are in the field arithmetics, which we already provide for BS 12381. And then for BN we are going to provide them. So the question is can we just do this on the guest side. So I did a bit of experiment what I wrote yeah hash 2 takes

[17:00] about 17.6 million instructions. This is trying to like do the optimized implementation or I think it's with the current implementation, that's the best we can do and out of, which only like around three million other crypto arithmetics. The main reason is, that every like to do every irrespective you have to go round trip to the host. And then to do the bite to internal representation conversion. And then internal type for efficient arithmetic requires. If I remember correctly it's a Montgomery form. So it needs to do some arithmetic to convert the numbers into some form, that's efficient for multiplication or division for example. So there's quite a lot of these overhead. So the s the thought process is. If we can bundle these

[18:00] into some u like more efficient field arithmetic functions such as dot product and matrix multiplication is it possible, that we can reduce, that cost? I don't have a straight answer for, that. But my intuition is, that we can include we can reduce, that significantly. But maybe not to the level, that we require. For reference to hash a mer tree of a million entries we need 20 hash operations. So this would require at least you know 10 to five times reduction of, that number. So I think we can like reducing these operations. It's it's doubtful, that we'll get close to the upper bound, that we're shooting for. Yeah bit of rationale

[19:00] reason into, that is. Because even, though we can provide the matrix multiplication these matrix are fairly small like 3x3. So we're not bundling like a thousand operation into one we are just bundling like you know nine. And then the rest of it still like was code and these loops and, which will still have significant overhead, that's why I feel like this approach even, though it's more attractive it probably wouldn't work well and also it will require the user to handle their preciding implementation. So overall I think in my opinion number one is probably the best option to support it today. And. Then we need to think more about these parameters and choices

[20:00] any numbers for option one like how much more is it? Yeah, I yeah, in number three, I added up all the metered cost for arithmetic. They are about 2.5 million. So I would say number one would be much more closer to, that. There's still like some like extra cost of like memory allocation and like the conversions still a bit. But I would say it will be much closer to 2.5 million. Yeah, good point. Toma are the numbers in three like. When you say optimize is, that like what do

[21:00] you mean by, that? Is, that like a native call, that you tested 17 million? Yeah, it's not a native call. It's was contrast. So, it's basically implementing Poseidon cache in W was. But calling the host functions for BS scalar add multiply and these functions. optimize just means, that I try what I can or what I know to make sure, that these calls are all necessary. And then we're not wasting like unnecessary convergence and things like, that. That. Okay. Okay. The cost between one and two. Yeah. I don't know the in terms of CPU cost. I don't know how much they will be different. It's more like the complexity and the maintenance. So I

[22:00] would imagine. If done properly they will be pretty similar in terms of performance. But it's more like the question of yeah we want to expose, that level right again for the complexity I sure I get the argument like I think really complexity I said can be moved on the SDK right I think what is important here is protocol complexity and I feel like one is more protocol complexity just from the standpoint of maintaining the permutations of different input. So. If two is really yeah it's unique as the same. So. So yeah. If you had a number for two and. If you knew, that it's not significantly worse than one and I feel like two is much better option.

[23:00] Yeah. Yeah. I haven't done enough exploration in, that direction yet. Yeah, we I'll try, that in the update. Yeah. But even for two, we need at least Prooseidon and Prooseidon two. Because these spongy implementations are different. So, that we're talking about yeah like at least maintaining like six of these functions essentially. Yeah. But it just feels much better still. Because it's like at least finite and it covers like all the cases, right? Yeah. So as Nika points out like. If friendly isn't hard for coded. So you know something new needs to be done and can do it as a guest layer. Okay. Yeah I'll do a little bit more exploration to two and yeah. If I

[24:00] yeah I'll update on thread. Yeah, Alex, I think yeah, that's a agreement. I think yeah, two is more flexible. it's just little bit of complexity to do it, right?

[25:00] Yeah, I think In option two, even, though we expose these primitives, the internal parameters would still have to be like I think these interfaces don't let you specify the like the security parameters like the long constants matrixes. So

[26:00] yeah one thing one other thought I had was should we expose those or should we like let the user initiate the hash with set of parameters they want and how relevant would, that be for most ecosystem. But I haven't figured out answer to, that yet. So there's potentially they're doing two with maximum in top interoperability you could be more complex. Different parameters like would they impact the runtime or are they just No, it's just numbers. No, not runtime. Yeah, it's different. It's just different hash. The output will be different. But the runtime is just the yeah the width of the inputs and the number of runs. So yeah long time I think we with

[27:00] number two we can have, that metered with like per iterations. But the security parameter is just the choice of yeah like the choice of hash states, that don't provide different outputs. Yeah, I agree. Like. If we add a capability to provide configuration and it does not change host complexity much. Then we should do, that. Because okay from the hosting point I would be concerned about the metering. But since we can meter it all the same I don't see like why would pass in an additional vector or something as an input. But but we introducing too much

[28:00] complexity here. Okay. Yeah. Yeah. I think yeah mix yeah two would be a good yeah good solution for interoperability. I'll spend more time on, that. I think I saw someone typing

[29:00] Hey guys. Hey. Hey. Can you hear me? Yes. I'm in a bit of a loud environment. So, you know, you can hear me. yeah. So, I joined in the middle. So maybe I missed some things. But I think I kind of understood J's proposal. With a hardcoded option, an option, that enabled us to configure MDS and run constants parameters. Seems to me, that the configurable option is the is a good way to go. Because that still optimizes the hash function itself run faster after the initialization. But enable some flexibility. Flexibility. The one thing I think we need to

[30:00] ensure is and I don't entirely understand how it works is how often we need to initialize the potent initial initialization types like let's say for milling as instructions. So I think it would be good to understand whether say to deploy as a separate contract. And then poly to whether the initialization only occurs once deployment is done. So, that those are details, that are less familiar. So as long as we can guarantee, that the initialization of the hash doesn't often think abilities disadvantage yeah I don't know any specific questions lots of. When doing stuff. So actually guy was looking into, that as well yesterday he was looking into implementations from what we saw Tom

[31:00] when we did it with you. When we had the budgets it seemed So. If it's around for milling instructions. And then the hashes themselves are around 10 million for everything running wasn't right. But yeah as long as for instance those four million instructions happen in my limitation one positive, that's, that's not too bad. Sorry, could you repeat the part? What's the forming instruction?, that's the construction of the house. Oh, okay. Yeah. yeah. I think we Yeah, I'm thinking like. If if it's like a contract like every contract has its own the seat for like the RNG for example. Similarly, every

[32:00] contract can set its own the state. And then they can once it's set it should be yeah, that should be the initial cost, that yeah I'm not also familiar I'm also not very familiar with the internal working of like these hashes. So I need to look a bit into it. But I imagine the initialization is just one time and absorbing yeah. And then yeah you need to. And then to use you have to absorb it first. So, that would be like probably based on the number of inputs. Yeah. Yeah. So the initialization is just like reading the checking the conference. It's not a stateful or something, that. So as long as, that's done, done, you can hash. Yeah, that's right. Yeah, I guess it's per No, it can be per contract life. That's a good question, that. Then you

[33:00] need to serialize it somehow betweenations or. If you're invoking a method from another contract, that. Then I guess can just keep invoke getting cached and we can keep invoking, that. But hey I'm talking here about lesson. But but yeah I mean it's not for invocation it's How. However long you can do here questions. I have a question about what you wrote. So why would it matter whether other V projects have different configuration witnesses apart from unless you want some interoperability to be inter between different channels.

[34:00] Other than, that we can speak around for answers. sure. Makes sense. I mean, it's not it's definitely there's definitely an advantage to having the same parameters, that Yeah. More feature for sure. Yeah. Yeah. I think it makes sense. Yeah. U Yeah. Allowing the constants to be overwritten for Yeah.

[35:00] for different chains and different projects. Yeah. Makes sense. Yeah, good point. Thanks GPT. Okay. So I think, that's seems like

[36:00] that's the main questions and concerns is the interoperability and the flexibility parameters. So yeah, I will look into option two in more depth. And then I will update, that thread. And then CAP will follow. Is there any other questions? I guess also to add I guess it would be good to look at the parameters of the circum lead the standard the circum library and see what they correspond to in terms of other stuff in specific projects. Because I. So far I've replaced them with something, that works on interoperable between what I could, that work in cir and rust and m

[37:00] So, that's a riding stand library. If we can go back to the stand library and use the parameter, that probably, that simplifies C. Oh okay. Okay. So. So did you say you changed those parameters in order to Yeah, basic basically on both ends both on serum on the rough end basically parameters, that I keep from side implemented forum. But I need to check. If it depends on the fun library or from other library system, that I found. That's how it's hard to double check, that. If we could exceed to the default CD parameter, that would be good. Yeah. Okay. And probably they probably work on other project. Project. Yeah. So perhaps supporting right like supporting like a default set

[38:00] if. If it's not overwritten like default to like a circum or something. Cool. If no other questions, I guess hand it over to you, Bri. You want to close the meeting? Okay. Wonderful. Thank you all. See you later.

</details>
