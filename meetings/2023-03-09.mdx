---
title: "Fees CAP Update and Prioritization"
description: "Overview of proposed updates to the Fees CAP, focusing on deterministic resource pricing and a separate inclusion fee model to improve transaction prioritization, predictability, and user understanding in Soroban."
authors:
  - eric-saunders
  - graydon-hoare
  - justin-rice
  - nicolas-barry
  - siddharth-suresh
  - tomer-weller
tags: [soroban]
---

import YouTube from "@site/src/components/YouTube";

<YouTube ID="h0YscptJUw4" />

This meeting walked through recent revisions to the Fees CAP, focusing on how to price Soroban’s various resources (compute, bandwidth, ledger I/O, storage impacts) without forcing users and clients to reason about a complex, multi-dimensional bidding system. It outlines a direction for unifying Soroban authorization by replacing `invoker`, `soroban-auth`, and ad hoc schemes with a single account-abstraction model and standardized authorization payloads so contracts stay focused on business logic.

A central theme was separating deterministic, protocol-derived resource charges from a distinct inclusion mechanism that handles congestion and ordering. The goal is a model that’s easier to understand, more predictable for users, and less prone to unfair prioritization when workloads mix different resource profiles.

### Key Topics

- Motivation: Soroban resource accounting is inherently multi-dimensional (compute, bandwidth, reads/writes, bytes, events), and fee design needs to deter spam while keeping execution affordable.
- Dynamic per-resource pricing + prioritization was seen as too complex for both the protocol and clients to bid correctly.
- “Synthetic resource” (gas-like aggregation) exploration highlighted prioritization pathologies:
  - weighting different resources can unfairly penalize mixed workloads
  - small usage of a scarce dimension can dominate total price even when other capacity is plentiful
- Updated direction: deterministic resource fees derived from network parameters, so costs can be computed from a transaction largely independent of other transactions.
- Transaction ordering under contention shifts to a separate **inclusion fee**:
  - prioritization reflects user urgency / willingness to pay (the “social value” of a transaction)
  - decouples priority from internal resource dimensions
- User experience emphasis: users should be able to understand “what I pay to run” vs “what I pay to get in sooner,” similar in spirit to familiar fee markets but with clearer separation.
- Refund policy discussion:
  - conservative stance against refunds for highly contended resources to prevent gaming and idle capacity
  - framing: you pay for reserved/declared capacity (what you _asked_ for), not necessarily what you _ended up using_
- Edge cases called out for analysis/simulation:
  - preflight overestimation vs runtime path changes
  - “unused writes” / test-and-set patterns where a write is declared but doesn’t occur
  - arbitrage-style scenarios where state changes invalidate a preflighted execution path
  - whether limited refunds make sense when there is no contention

### Outcomes

- By generalizing authorization through account abstraction, contracts can treat classic accounts and programmable wallets uniformly, delegating signature verification, nonce handling, and policy enforcement to account contracts that expose a single `check_auth` entry point.
- Contract invocations are authorized via structured payloads that capture the full call stack. Preflight recording determines what will execute so wallets can construct correct payloads, while the host tracks nonces per account-root pair.
- The proposal includes a built-in account contract for classic accounts, recommends temporary or scoped storage (such as short-lived approvals) instead of long-lived allowances, and presents proof-of-concept patterns like timelocks, atomic swaps, and token approvals, along with notes on SDK and host implications.
- This approach introduces added complexity in preflight, larger transaction footprints, and new host responsibilities. The intent is to reduce ecosystem fragmentation, simplify wallet integration, and focus authorization logic within a consistent framework.

### Resources

- [Fees CAP – Updated Proposal and Design Discussion](https://docs.google.com/document/d/1J-J3ClTUkrsLiJag906OH4hmNkZI3Jk6_Y9ZYt_psAI)

<details>
  <summary>Video Transcript</summary>

[00:00] Okay I'll just kick this off. So hey everyone this is our weekly protocol meeting in which we discuss and trying to make the design decisions. I think we have only one thing on the agenda today, which is an update on the fees CAP and Nico can you take it yeah thank you and yeah this is basically like we had like a few conversations in the past few weeks some more recent updates in the last week based on the yeah some of the converts we had in Discord. So we have a like a round of updates, that yeah, that we, that I actually published yesterday to the CAP. But this is an incremental change on top of the piercing. So maybe what I can do is kind of give a kind of high

[01:00] level overview of what we are with this serve the updated theme Mode app. And then and yeah like people are interested and they can go and go read the actual CAP, that is has a lot more detail on each of those topics I don't know. If that makes sense. But like we should do, that okay. So yeah. So like the thing, that we're trying to do in this cup is there like a magical things in there. But like the one of them, that is basically like make all these changes, that are required to deal with is you know needs right like. So so like coming from classic the classic protocol where we have this flat fee pair operation the operations kind of the unit of a transaction right like we can have

[02:00] within one and a hundred and we have this really simple model for, that in classic in soroband the resources are a lot more complicated. So you have like compute you have the amount of a bandwidth, that you're using the io like you know how many reads on rights you're doing to you know to The Ledger and how much how many bytes. And then you have like even more complicated things in there like depending on the contract you have like events, that are. Then potentially, that to translate potentially to actual into real cost for Downstream systems. So like. When we look at all of this we have to think basically in how we can make it we don't have in

[03:00] particular like the spam type of traffic on the network. While at the same time we want to keep fees as cheap as possible on the network. So it's kind of trying to balance those things is what this Camp is about. So I think. When we left it off the last time we talked about this CAP the one thing we talked about actually was, that who are going to try to make the Ledger space something, that is actually priced dynamically and in particular we are looking at ways to limit the size of the ledger. So this is the topics, that we know we'll be having around how to be do we save data off-chain desk what

[04:00] can presented I think it was like a couple weeks ago or even last week. So this is one component of this CAP the other things, that we are, looking at was yeah I don't like the pricing model basically for all other resources. So like yeah compute and bandwidth for example. And so we've been kind of going back and forth it was like the first like big iteration around this was to try to come up with a way to do like pricing for dynamic pricing for every resource type on the network and as we kind of looked into this into multiple like it became kind of evidence, that it was kind of

[05:00] getting quite complicated to try to. So to manually to model it on the network itself is actually not. So bad I think the well things were getting really complicated is. When we try to think about ways to prioritize traffic basically like. When you have like multiple transactions competing for with each other, which one gets to be in The Ledger this is the ones, that are you know postpone to a future letter and. When you. So this is already getting complicated on, that front. And then there's the other aspect, that is. While this is happening on chain for clients it's also getting really complicated to try to basically decide how to what to bid basically in terms of fees right for each of those resource types. So those are like the type of things we've been thinking about in the past few weeks in more depth right like

[06:00] trying to think about ways to simplify this a bit and at first we're looking at doing something, that was trying to kind of come up with a like a more I think I call it in the CAP currently like. Because this is still you can still see it as part of a more like an appendix type of thing right like a alternate implementation yeah. So come up with a synthetic resource, that is basically an aggregation of the different resource types, that the specific transaction is using, that basically combines and comes up with some something, that is maybe like similar to the notion of gas, that are for example refining Ethereum, that work basically, that

[07:00] synthetic thing represents compute. But also disk IO and yeah like a bandwidth any resource really in the system is kind of you try to kind of fit, that into this synthetic thing. And then yeah. So we started to kind of explore, that and what we found is, that it was still fairly complicated to try to be fair. When prioritizing transactions like you have like certain scenarios. When you come up with like a recipe right for this synthetic asset where we basically for example you say okay I have like took to combine those different resource types I'm going to take some of the compute numbers, that I'm getting I'm going to give away to

[08:00] this and add to, that like with the different weight the I o cause and you combine all those things right into a single number, that ends up being your number of this aggregate resource type and then. When you do, that you end up with like very strange prioritization problems now. Because if you try to balance for example how to how would you compare a transaction, that for example does a lot of computation to a another transaction, that does almost no computation but, that has, that is very heavy on a hero I came up with those weird Trails where you have to really penalize one of those

[09:00] two types of transactions and it gets even more complicated. When you have like a transaction, that does a little bit of both. And then and. Then you end up with people overpaying a lot for basically getting penalized a lot for using a little bit of a resource, that happens to be in demand. While you're also using an expensive. But available resource. So this is like the type of problems we are running into. So yeah, which would actually happen like quite often like imagine. If you have like a lectures being filled with a lot of what the constraint it is let's say a computation where for whatever reason there's a lot of traffic where. When people are doing let's say like a trade right on against

[10:00] an AMA. So like this one is actually a little bit of IO. And then computation they're like maybe depending on the AMM implantation. But it could be like something fairly complicated and let's say you have a lot of trading at this happening you still have plenty of IO available to your on the network. But IO is going to always be expensive in with the way we want to kind of to model this. Because adding things to The Ledger is kind of one of those things where I think something to deledger is something, that has an impact on many systems right. So so relative to compute price adding data to the to The Ledger yes is all those are magnitude more expensive kind of like what you see in a

[11:00] in the classic protocol where the Base reserve is a lot more expensive than just like the transaction fee right, that's kind of the way to think about this. So then. If you ask people okay like you're in order to get into The Ledger you have to be let's say a hundred times you know the price of your aggregate results. Because of congestion on gas or sorry on compute asking people to pay a hundred times for Io in this case is kind of weird right it makes things very expensive for no real good reason. So anyway. So like delete this iteration what we've kind of looked at was how could can we make this problem go away and the current approach, that we are, that we can have landed on is to rely more on

[12:00] or pricing resources on something, that is more like network parameters or like automatic and automatic pricing right of resources similar to what was actually already in their form for Ledger space where basically. If you look at the transaction you can derive independently from other transactions the price of the of those resources. And then the type of market dynamics, that you have are not actually on the resources themselves. But on I think I called it the cost of inclusion in a ledger and I think this is basically Shifting the conversation there around

[13:00] why do you want to be ahead of you know. If somebody is a means transaction why, that person wants to be ahead right and I think the name, that is used in the literacy around, that is the social value of the transaction the social value has actually nothing to do with the resources like the amount of resources, that a specific transaction was using it's really you know based on whatever people are actually doing with, that transaction. So in some cases even, though you're your transaction might be doing a simple you know set one bit in on The Ledger it may be actually something, that unlocks you know like a huge value you know down the line right. So so there's like decoupling of the two is kind of interesting

[14:00] let's see and yeah. So like this one like the well this through to work in a way, that kind of makes sense the assumption, that we're making is, that we will be able to have like a same way and. When I say we here it's basically the protocol and validos right, that are voting for some of those network parameters such as how much does it cost to store you know like let me see like one kilobyte of data on natural like this type of pricing this is what we're talking about so. Because when you have the price of the transaction basically decompose it. Then into those kind of network derived fees, that are like I said like the cost of storing data for example on The Ledger plus this inclusion fee, that

[15:00] is an actual building per transaction and, that's the total fee, that you end up paying for and yeah so, that's kind of the Focus right. Now is to see how far we can take this idea or where the inclusion fee is unrelated to actual resource utilization so, that's kind of the thing we are looking into right now, which is doing like modeling and Analysis to see like the where this breaks and what are like the. If this basically holds us a as a variable approach to this problem like questions on this at this point yeah the one other note I want to make here is, that like I think besides just prioritizing

[16:00] transactions just from my user experience perspective I think it should be a requirement, that the user can understand what's going on here right and with all of its faults in Ethereum ecosystem at the end of the day you know exactly you know at the end of the day there's just like the gas resource and you're competing for gas. So like the question is with these new Concepts, that you're introducing what is the user experience actually this is very similar to what you've seen in there I mean it's a variation your experience is, that oh my for a given transaction you have actually two components you have the your guess price right, that you have attached to the transaction and you also have a I think we call it a chip or something for the validation

[17:00] that allows you to kind of you know get included. So there's like something, that is similar to this inclusion fee the difference is, that in Italian the inclusion fee is actually tied to the amount of resources, that your it's a rate basically it's not a flat fee it's not technically it's trying to do more of the dynamic price signals we saw of these aggregate resources as opposed to kind of stepping outside of, that and assume, that the price, that you actually have your base price for resources is relatively accurate. And then this prioritization thing is modeled adjusting fees based on like the

[18:00] yeah the use cases right as opposed to the actual like, which limit you're hitting in the system got it okay let's open this up to questions so. If anyone wants to ask a question please do this on the chat or just asked to be included in the stage Nico just one more question for you like what are the open questions, that you like is there anything, that you wanna consult a team with here right. Now in terms of questions, that you want help answering I think, that they're like there is one aspect, that is in the cup I mean around like the

[19:00] which resources we want to allow for refunds is kind of an interesting question right. Now on the in The Proposal I think we can only get refunds for I think it's basically like anything, that goes to dolphins Downstream systems like you know basically what gets into Horizon or sort of an RPC right. Now it's basically the cost of this of the meta outside of The Ledger country changes the reason for not giving out refunds for other resources is, that right now. If if validators make certain decisions right, that they are not going to include certain transactions. Because of you know

[20:00] we're hitting some limit let's say on a bandwidth let's say an Archie bandwidth is not a good example. Because we know exactly the size of the transaction. But like for compute right like. So let's say a transaction says oh I'm going to use 10 000 units of compute. Because they are using 10 000 units of compute, that means we don't include up to 10 000 units of compute from other transactions right, that tough maybe the same priority. And then later let's say, that transaction decides well actually you know I'm going to only use a thousand. But like basically by do by doing by using less it would give an incentive to just like yeah like

[21:00] people only just put like maximum numbers on everything. And then yeah their Ledger would be kind of idle on the process this one you know one entry. So I think this is like a the reason why we don't want to do refunds on the resources, that we think will be highly contentious. But like I wanted to hear like. If they are like any opinions on, that topic let's see. And then the other thing yeah is everyone really like the modeling of this of these prioritization based on the social value of transactions I think yeah people have maybe like more opinions on this, that would be great. Because I said things like a one of the thing, that is kind of new in this proposal. So yeah

[22:00] get can you offer a bit more information on the social value I know you mentioned it before. But it's a relatively new concept it's not new I mean it's not new in these in the crypto space right. So it's like the idea, that a low a transaction, that is the importance of a transaction is actually completely independent of the amount of resources it's using right like it can be, that you know maybe it's a simple payment you know could be like moving billions of dollars you know like. When you compare, that to a large transaction, that does a bunch of stuff you know the same thing right it could be you don't know is it doing something, that's not super useful or is it actually a transaction, that is related to like a payment channel right

[23:00] or a layer two type of transaction, that is extremely important right the value is the initial and inner and value of this transaction is actually off-chain anyway how did the user determine the social value of a transaction they're about to submit well it's kind of a it's the similar idea. Then you know. When you're saying okay I'm going to build you know 2X or whatever the base fee today right on the classic network it's a similar thing where at some point you say I'm willing to pay up to X for my for this transaction right it's the same idea it's just like here we're saying it's we make it completely independent of resource utilization

[24:00] that's the one difference and otherwise the same idea of like in terms of user experience yeah you want to you kind of you want to get people to think about how much they are willing to pay for a specific transaction in terms of not solid terms they look at it. Because that's actually not the way people think about it right like. When you have a you know you're trying to pay your at a store right like he maybe like the way you think about it's not in terms of like oh yeah like I want to be to think about it in terms of relative to the cost of, that transaction on this particular network is it's kind of hard right like

[25:00] it's in traditional systems it's going to be a fee a percent of your amount you know I guess, that's kind of a way to think about this like the, that's tied to the actual value the real world value of this transaction it has nothing to do with the cost of actually processing the transaction let's say on the Visa network right, that plat fee, that you can, imagine exist right is actually not visible to end users right in those systems and it shouldn't be. Because it has nothing to do with the value of, that transaction I wanted to say, that the problems, that we're talking about here are actually not specific to Stellar or blockchain or anything like, that these are exactly these are standard problems in multi-value optimization scheduling. So this is a thing I spent a bunch of time working on you know for my life

[26:00] so you got the usual problems you have to decide how is there a deterministic relationship between the things, that you're paying for and the things, that are available. So in our case it's compute or whatever. But then there's this other aspect, which is how much does somebody need the thing to be done and, that piece is usually not modeled within the framework of the scheduling. Because it involves a bunch of as you say sort of pieces, that are too complicated to be encapsulated and they have nothing to do with the cost of running anything. So to give you like a concrete example in astronomy you have scheduling your telescopes and you want to do something similar you want to put observations on these telescopes and it costs money to do, that. So there's a bunch of finite stuff, that you have to pay for. But then there's the question of this particular observation I want to make today how important is it to my science and, that question can't be encapsulated

[27:00] in a general model it's very specific to my actual use case. So the analog here is I have a smart contract and this thing is very important for my contract to execute I'm willing to pay more for it. And then so it's very normal to have this as a separate layer. But all the problems, that we're going to run into are the same problems, that are covered in every scheduling system right. So this question of determinism how much does it cost how do you do a trade-off between orthogonal variables how do you provide this thing in a transparent way. And then how do you deal with gaming of the of this social aspect like. If I have enough money can I dominate the whole system and basically distort the parameters. So these are like hard problems. But also they're standard problems I guess, that's what I'm trying to say exactly and, that's actually why we ended up where we are. Now is, that we didn't want to

[28:00] to kind of come up with, that aggregate resource right like, that is basically like what are the weights you know how much weight do I want to assign to each of those resource types to turn this multi-dimensional optimization problem into a single variable right and it seems like the most practical way was to actually really couple it kind of like using your example where you have resources, that cost real money right like to run a specific in our case right to execute a transaction it should cost a reasonable amount right, that is basically like you wouldn't have like junk transactions being executed on the network and after, that the second layer is more

[29:00] of a market for getting to, that queue. So it's basically like a kind of a almost like. If you're going to be I don't know like at the once it's like the another a good analogy would be yeah. If you could buy your spot in line the day of. But it's like those Black Friday sales right like you're outside the store you get to get in the line. But once you're in the store it's still the price of the store you don't get to you know you don't pay more. Because there are more people you know in line inside the store I mean and, that we redecoupled the two problems yeah. So there are a few fundamental questions, that I guess it would be great to get answered. So like. If the first question is these things, that we believe are like compute for example is it

[30:00] deterministic enough, that we could actually Define a cost for, that would not vary yeah I think so, that's kind of the we can the current idea is to yeah to give it a flat rate basically like the amount of computing you use would be a linear function right to the I mean the sorry the cost for compute would be linear to the amount of compute you're using and then, that will tune it over time I think we can over time maybe come up with more complicated models right, that the system can, that we can follow. But like right. Now we are using linear functions for, that

[31:00] and yes yeah and the Assumption sorry yeah is, that we should be able to on a regular basis have a vote basically you know between validators to see okay should we adjust, that's, that function. Because of the patterns we've seen right in the let's say the last month or something I was getting two, which is, that. If you have a multivariable optimization. Then what happens is it's tuned to the environment, that you observe and you know you treat these parameters like the simplest ways you have a bunch of variables you're sticking together with plus signs you put coefficients in front of them. And then those coefficients are tunable knobs, that you use to decide how to trade off the different orthogonal dimensions but, that can be tuned to a particular workload. But then. When the workload changes, that usually doesn't work

[32:00] anymore and you have to retune it. So a key question is as the kind of things, that happen on Stellar evolve how will we adjust or adapt to, that but, that's the thing I'm saying is, that the we are not going to prioritize transactions based on this combination you know of things right the instead we are prioritizing based on the kind of perceived right like the social value basically of those transactions I think, that's kind of the key element to this proposal is, that we don't try to be smart in terms of like the yeah trying to kind of boss like try to fit everything into this linear combinations of Dimensions. Because you end up. If you do it like, that you

[33:00] have a you end up in a situation where it's kind of like the you know. If you're like pizza by modal distribution right on your own you have two types of transactions right, that are on the network and you try to put a line in between them and no line is going to work like you just end up with basically you have to decide okay do I prefer the first group of transactions. So the second one and then. When you're outside of, that your fees are just completely broken or your prioritization is completely broken I completely agree with, that the other aspect of this is the refund thing, that you talk about I think, that another way to think about this is, that to use your analogy of waiting to get in the Black Friday sale you're paying for the privilege of

[34:00] having the spot in the lane or the queue you're not paying for what's actually going to be able to buy. When you get in the store so. If I you know pay for 10 000 compute units. Because that gives me the space and I actually only used a thousand well I paid for ten thousand. Because that's how I wanted to you know justify my position in the line right. So I think it is consistent to not offer refunds. But maybe you can frame it differently as really what you're paying for is not the usage at runtime it's for your expected usage exactly yeah any more questions from the audience. So Nico I understand, that there's

[35:00] probably another draft of this coming request, that's open Dima, that is the other person like you didn't have time yet to merge it. But yeah there should be I'm hoping to get more feedback from people like it would be nice. If we can get some help on yeah playing with, that proposal in terms of the you know like simulations right like a c what happens. If are there like situations where it would behave in ways, that are really not great like you know like the example I used with. When you start to combine things right where you end up with certain transactions end up being penalized or not and My Hope Is, that this proposal doesn't do, that

[36:00] that but, that would be yeah very curious to see. If they are like things we missed basically in this one and there are probably situations where the thing doesn't work right. But like having a better understanding of those situations would be super useful got it and are there open questions or is the proposal complete as it is right. Now or are there open questions in it I mean it's mostly yeah it's mostly there I would say they open questions like they are more like the minutia of you know transaction set like what is maybe the like going back to like the refundable stuff maybe we want to have the value data or actually be able to say to give a hint, that. If the transaction set let's say was put together and there was no contention on

[37:00] anything. Then maybe we should be able to give refunds to people like there was basically like queues we are kind of empty. So you know there's no reason to basically penalize anything. But like I don't know. If that's you know. If this will actually happen in practice. Because we tend to see more of a you know cues actually have a bunch of stuff and it's never enough capacity to do anything. But at the same time like I was saying like earlier like mainly the contention is all on compute and not on iOS then. If people don't use all their eye or like let's say they. Because some of the problems here, that I'm talking about as the imagine you have a test and set type of contract right a contractor basically does a read. And then in some conditions going to update The Ledger entry well in this proposal regardless of

[38:00] of what the contract is going to do. If you said you're going to write and you don't write. Then you're paid for the right, which is a bit sad I don't know. If it will happen or not but, that's something, that I think may happen quite a bit. If maybe in certain like trainings is it the type of trading contracts or something like, that for AMMs I don't think it will happen. Because we always have like those tiny adjustments to the results. But maybe different kind of yeah I mean like I said it's a test and set type of situation. So I would imagine it should be fairly common in the in kind of the general case. So this is specific for situations in, which you know let's say pre-flight

[39:00] determined, that you're going to go in one code path. And then you know the state changes and. When you actually go on the network it takes a different code path yeah like and this situation is like. When you have like an Arbitrage opportunity right like you have people say oh I can trade. And then so then. When you pre-flight they see, that yeah I can trade and, that folder they are going to submit the transaction. But then. When their transaction gets executed. While the trade was already taken. So it's a no right so, that's kind of what I'm thinking I guess in the AMM. Because that's exactly what will happen is, that you don't update the results in, that case. Because the swap is just not going to do anything. But you said you were going to swap. So now you're paying for, that. So yeah

[40:00] so in these kind of cases one lens, that's kind of useful to look at it is you have all these things to do and you can't do them all, that's why you have prioritization right. And so really the question of your algorithm is who loses who is going to lose and not get in answering, that question deciding what you would like to happen in those situations helps to inform the structure of your optimization right. So it could be, that what we're aiming for is optimal use of compute and I O. And then the ability for people to really push for it. If something seems important to them and you know and. If you have, that if, that's your thesis, that's the lens, that you're using. Then you can make a decision about whether it makes any sense to charge someone. When it doesn't actually happen or not. Because maybe it achieves your goals right. So I think, that's like one way to think about how to move forward on this yeah I mean at the same time I think the current gap on, that front is

[41:00] conservative version right similarly. When you have like a. If a contract traps right. Now we basically say you don't get any refunds. If you trap. Because you've been wasting this clip you know you had a promise it was going to be a super useful transaction. And then it didn't do anything. Because it crashed yeah it's not bother right trying to basically it's kind of going back to what you're saying like we want to encourage people to not submit transactions, that are crashing or doing nothing. So maybe the current proposal is the right one okay was there many more questions in the chat or something, that we should be looking at

[42:00] foreign I don't see any more questions in the chat. So I think, that unless there's something else, that you want to bring up today Pico I think we can call it a day no I think, that's. So like yeah. So we'll continue conversing in the live stage or the live chat. If anyone wants to keep talking yeah you know, that's on the regular Dev. So people want to boost, that too all right thank you have a great day

</details>
