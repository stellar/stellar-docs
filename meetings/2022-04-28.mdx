---
title: "Open Protocol Discussion"
authors: [justin-rice]
tags: [legacy]
---

import YouTube from "@site/src/components/YouTube";

<YouTube ID="HTK-DJ31QzA" />

- hey everyone welcome to the open protocol meeting sorry for the slightly late start just a quick technical glitch as per usual um so the stellar protocol meeting in these meetings we discuss and plan for uh upcoming changes to the stellar protocol and today we're going to talk about something very exciting project jump cannon which is going to bring smart contracts to stellar um so just quick intro as most of you know stellar was launched in 2014.
- at the time there was a very deliberate design decision to keep things simple right so only support a fixed repertoire of transactions but at this point after a ton of feedback from the ecosystem it's clear there's a need for more flexibility so developers they're interested in building applications they're relying on submitting custom turing complete contra code right to run in the transaction execution phase of the network so essentially people want smart contracts so in march we officially kicked off project jump cannon and there's a link to the announcement in the meeting description and after a very thorough examination of the existing smart contract landscape we made a decision to build it on a webassembly run times wasm for short so if you want to know more about the selection process there's also a link to a blog called project jump canon choosing wasm and that will sort of help walk through that decision the evaluation that led us to where we are today but today we're actually going to start to get into the protocol changes necessary to like accommodate that decision so we're going to start by talking about the core advancement proposal cap 46 webassembly smart contract runtime environment which as you can probably guess by the title um specifies the lowest level code execution and data model components of a wasm-based smart contract system for the stellar network um once we talk about cap 46 we'll also start to ask some general questions about how smart contracts should interoperate with the network this is as per usual a technical discussion so if you want to keep up i suggest taking a look at the cap as well as the discussion thread about it those are both linked to in a meeting description and then if you're interested you can also join the conversation about smart contracts you can do that by participating in that thread that's linked to here or by joining the stellar developer discord which is where we're having all the jump cannon discussions so that the work is open the participatory we're doing you know can really follow along on the stellar developer discord okay cap 46.

This Jump Cannon kickoff focused on CAP-0046, the Wasm smart-contract runtime vocabulary. Grzegorz and the core team explained why the CAP looks unusual: it introduces the types, host objects, and XDR scaffolding that Soroban will lean on without yet wiring them into any user-facing transaction. Establishing that common language now keeps the follow-on caps smaller and lets client teams prototype against a stable ABI.

They also unpacked the host/guest split, detailing how contracts run in a deterministic guest environment while Stellar Core enforces resource limits, storage access, and serialization in the host. That discussion covered the value type hierarchy, how immutable objects flow across the boundary, and why the data model needs to be generic enough for future fee schedule updates.

Key discussion threads:

- CAP-0046 as a building block: defining XDR for Wasm entries, handles, and host functions while deferring transaction plumbing to later caps.
- The host-versus-guest contract boundary and how deterministic execution depends on a clear line between developer code and Stellar Core.
- Structuring SCVal and companion types so contracts can exchange complex data without breaking compatibility with existing ledger serialization rules.

<details>
  <summary>Video Transcript</summary>

[00:00] Hey everyone, welcome to the Open Protocol Meeting. Sorry for the slightly late start, just a quick technical glitch, as per usual. So the Stellar protocol meeting. In these meetings we discuss and plan for upcoming changes to the Stellar protocol, and today we're going to talk about something very exciting: Project Jump Cannon, which is going to bring smart contracts to Stellar. So just quick intro. As most of you know, Stellar was launched in 2014. At the time there was a very deliberate design decision to keep things simple, right, so only support a fixed repertoire of transactions. But at this point, after a ton of feedback from the ecosystem, it's clear there's a need for more flexibility. So developers- they're

[01:00] Interested in building applications. They're relying on submitting custom turing, complete contra code right to run in the transaction execution phase of the network. So essentially, people want smart contracts. So in March we officially kicked off Project Jump Cannon- and there's a link to the announcement in the meeting description- and after a very thorough examination of the existing smart contract landscape, we made a decision to build it on a webassembly. Run times wasm for short. So if you want to know more about the selection process. There's also a link to a blog called project jump canon- choosing wasm and that will sort of help walk through that decision, the evaluation that led us to where we are today. But today we're actually going to start to get into the protocol changes necessary to like accommodate that decision. So we're going to start by talking about the core advancement proposal, CAP 46- webassembly smart contract runtime environment, which, as you can probably guess by the title, specifies the lowest level code execution and data

[02:00] Model components of a wasm based smart contract system for the Stellar network. Once we talk about CAP 46, we'll also start to ask some general questions about how smart contracts should interoperate with the network. This is, as per usual, a technical discussion, so if you want to keep up, I suggest taking a look at the CAP as well as the discussion thread about it. Those are both linked to in a meeting description and then, if you're interested, you can also join the conversation about smart contracts. You can do that by participating in that thread that's linked to here or by joining the Stellar developer Discord, which is where we're having all the Jump Cannon discussions so that the work is open, the participatory we're doing, you know, can really follow along on the Stellar developer Discord. Okay, CAP 46. So CAP 46 came out on friday. I think there's been a lot of back and forth on the mailing list, though over the past few days a lot of questions asked, but I'm going to pass it to graden grading, I guess, to start off with, is there anything that you want to tell us

[03:00] About CAP 46 and or about any issues that you have that you'd like to discuss about it today? Thanks, yeah, there's lots to discuss here. I want to give a little bit of background, because this is, in some ways, an unusual CAP. Often times when we write CAPs, they're directly changing the protocol or they're proposing to directly change the protocol that people are using, and CAP 46 is a little bit weird in that it contains protocol contents. There are new xcr definitions like there would be in most CAPs, but none of them can actually be used. This is a building block for other CAPs, and so if this CAP, for example, were accepted as is tomorrow, there will be no new messages that you could send on the network yet. So this is just a building block CAP. It's a piece of vocabulary that we want to talk through the potential uses for in the future, but without it, without actually committing to a specific transaction

[04:00] Format, specific ledger entries, anything like that. This is a vocabulary in particular, for interoperation between two environments. So the way to think about this CAP is that it's describing two different places in inside of Stellar core where code can run: the guest and the host, and so that division between guest and host is a key concept that's being introduced here, and most of the CAP is a discussion of how the guests and hosts are going to relate to each other, both their calling relationship, with what values can be passed back and forth between them, and then the types of data that will be stored. In this particular proposal, the way we're discussing data storage actually involves a split, and it's a split that's brought about by idiosyncrasies of the wasm runtime interface, which is that you can't really pass complicated data types back and forth. There's a few other reasons for this.

[05:00] It's actually there's a there's, large rationale section of the CAP that tries to lay out our thinking as we explore different options here. There's an efficiency argument, code size, there's a compatibility, the ability for third parties to browse and interoperate, for contracts to interoperate with one another. There's a whole host of different reasons for splitting data the way we are. But really the way to think about this CAP is- and I've had this conversation with a few people so far- to picture in your mind a sort of a four quadrant diagram: upper left, upper right, lower left and lower right. And in the upper level you've got the host and guest environments on the left and right. Okay, so those are at runtime while code is executing. There's these two environments that are communicating with each other and

[06:00] Sharing access to a data model where much of the data is stored on the host side, but the guest has these little handles that reference into it and then in the lower two quadrants you have corresponding to each of those types of data, what we would call the values, which can be handles, and the objects. There's an XDR layer. So in the upper two quadrants of this diagram you've got the hosting guest at runtime, where values are in memory, and then and the contract is executing. In the lower two quadrants you've got the XDR representation, which is sort of data at rest, and in fact quadrants are quite the right description because the entire lower layer of this diagram is essentially all XDR. But there is a, there's a correspondence between values that are accessible in the guest side in valve, then the sc valve XDR type that's presented in the CAP. So the CAP introduces these value and object types and it introduces the split between the host and the guest

[07:00] Environment and that vocabulary is a sort of background of what we're trying to get laid out here now. we have a prototype implementation of this. We actually at this point have two prototype implementations because we we've done a version of this in c4 plus and version of it in rust, and we're fairly confident this is a structure that works well in that it allows a very small and highly interoperable guest code to run in a you know a wasm runtime that is connected to a host that has these host objects, and so most the discussion around this CAP so far has actually been like which host objects to start with, because there's a potential repertoire of multiple types of host objects and a little bit around the value representation and bit packing and stuff like that, but there's not a lot of.

[08:00] You know, in many CAPs there's semantic rules to talk through in terms of a sequence of events that occur in response to a transaction or an algorithm that's implied or something like that. There's not a lot of verbs in. This is really more of a nouns CAP. Right, it's laying out a vocabulary of things that will exist in memory and or on stable storage and xtr or being sent over the wire, and so you can imagine all sorts of operations happening. All the actual operations that will occur on this data model are essentially left to later CAPs. They're things that still have to be worked out. We're still sort of experimenting with that. But because smart contracts are such a big project and there's so many different parts to smart contracts, we wanted to try and split out meaningfully digestible pieces of the problem and, you know, review them, talking through, have community input on them

[09:00] And ultimately, as a software engineers, you know, implement and merge them piece by piece. And this is the first piece, so that sort of gives a little bit of background on it. There was one other thing I wanted to mention: gradient. I actually do have one high level question for you. I know you've you go into this in detail in the CAP, but can you just like give a brief overview on the specifics of, like, the value object split, because that's something that is very unique in the world of blockchains? I think that elrond is the only other blockchain that we saw that does something similar. Yeah, for sure. Yeah, so like, what is the alternative and why is this better? Yeah, totally so- an analogy that a lot of people have. This was actually the thing I wanted to talk about. I just remembered, so I'm glad you brought it up. There's this analogy that a lot of people have been using while we're talking about this that I thought it would be good to bring up here, which

[10:00] Is that if you've used a web browser, you can really think about this in terms that are going to be very familiar. So, in a web browser, you program your web pages in javascript, but the web browser itself is a very large piece of code that is not written in javascript, right? So, like, some of the front end is written in javascript, but a lot of the web browser is written in c plus or rust or something, or c or some other low level systems language, and it's compiled ahead of time and it's essentially a platform for the applications to run on, in the end, the javascript applications. If you, if you've written javascript, you'll know that you often have object references that aren't references to javascript objects. Right, you can have a reference to a dom node or a window, or a media container or a, an xml http request or something like that. And these objects, they're not like the other objects, right, you. They're not like the javascript code that you have. You can't inspect them, you can't find the source code to them, they're just sort of out

[11:00] There somewhere. Where they are is they're in the host environment. They're supplied by the c plus platform that you're running on. They're much more efficient. They can do things that the javascript code isn't capable of doing. They're often much larger pieces of code, and so if you had to ship them over and over again with every application, your application would be gigantic. And so there's a sort of the. By being part of the platform and the environment in which your javascript is running, they are almost like a library that you can call of very fast, very reliable, very common features, but that you operate at some distance from right you, if a function call goes into them, you know you don't get to break on your javascript debugger in the middle of that function call right, it comes back to you and then you get control back in your guest code when it returns. So that we're approaching this

[12:00] Model and, as you said, it's the same, this that I think the lra model, uses, in a similar fashion, where we're coming up with a set of objects that the platform will provide, that are implemented in cpu plus or rust and they're kind of baked into the platform. They're things that all, or quite a lot of smart contracts are likely to want and so, ahead of time, the Stellar core developers, ourselves and anyone else who wants to contribute to it, would have created this repertoire of extra objects. And those objects are again fast. So they're gonna- you know they're not gonna- be written in wells and they're not running on the virtual machine. They're written in native code. They're much larger. Typically there's a. large code footprint that supports them. That will not be included in your smart contract. You don't have to include code in your smart contract. Your smart

[13:00] Code in your smart contract just calls them, and so your contract code is much smaller. But you operate them at a distance, so you have this reference to a host object when you're working on it, rather than you know, running in the memory of your smart contracts. Your smart contract has a little linear memory. It has the virtual machine has its own memory, and so you can write code in whatever language you're writing, and I think most of our smart contract source languages are going to be- we're looking actually at mostly rust there as well, interestingly enough- and so you could write a data structure in rust and have it running in the wasm virtual machine, just like you would have a, you know a javascript array or something running inside your javascript program. But we're also going to try and provide almost every object that you want as a host object, so that you don't actually have to compile anything to your contract except for a handle. And so this handle, which is essentially a pointer or a certain quasi pointer it's

[14:00] Not actually a memory address, it's just an integer number that starts from zero. It counts up as we allocate host objects, but these typed handles that you'll be operating on and passing to host functions refer to host objects but they don't actually hold the host object in the guest's memory, and so, again, there's a variety of benefits. One of the benefits- I haven't mentioned yet so much, but it's in the rationale section and we've talked about it a bunch while we were working on this- is that corresponding XDR form. And when we've looked at a lot of smart contracts, most smart contracts spend most of their time from what we can tell, if they're not doing cryptography. Obviously there's the special case of doing cryptographic operations, which we'll also get to, but a lot of them spend a lot of their time serializing and deserializing their data

[15:00] Store. So the smart contract is invoked and it's given a byte buffer and then it spends all of this time in its virtual machine running in virtual machine instructions. are just like inspecting a byte buffer and copying values out of it into a data structure in memory, then operating on the data structure in memory and then re serializing it back to plate buffer, and that's a little bit weird for a few reasons. It's not a good, efficient use of computational resources because that's like compute, expensive work, and you're doing it on the virtual machine instead of the host where it would be on in native code, and it's also it's very likely to be shared or shareable right. If you were using a data structure that is similar to other data structures that other people are using, the idea that you would need to do custom serialization, deserialization, as opposed to just reusing a library that does it, is a little funny. It's sort of it's making every smart contract ship

[16:00] Redundant, duplicate contract code that does the same thing as someone else could do. And on that note, with respect to commonality, the more the data types are common between smart contracts, the more you can interoperate between smart contracts. So if smart contract a wants to call smart contract b, it's going to want to pass arguments, right accounts and amounts and maybe vectors containing things, maybe large numbers or cryptographic data types or whatever, and in order to pass data from one contract to another. I mean a contract is just a program, and for two programs to interoperate they have to have a common data language. And so if you assume that you're going to have this interoperability requirement between contracts where they share some kind of data vocabulary, then necessarily the serialization and deserialization code has to be shared. And so factoring that serialization, deserialization code out, having it be part of the platform and having

[17:00] The user not actually have to ship serialized code but having the XDR pulled out of a ledger entry and turned into host objects and then just handing handles to those host objects to a contract, saves the contract from shipping any of that serialized code. It's is the contract from having to deal with compatibility issues because everyone's using the same data model. It just seems like a win all around you know every time, We sort of thought about this problem from another angle. We found another way in which it seems advantageous. Third party browsers, for example, would be able to browse the stable data format. As opposed to many smart contract systems, every data value that the smart contract saves into the blockchain is just an opaque byte blob that no one can inspect. If we have a common data type such as the one that's presented here, all of the ledger entries will be at least structured so you could browse

[18:00] Them. Now you might not be able to make total sense of the contents of it, but at least have some structure that you'd be able to browse, which would make diagnostics easier. It would make writing third party adapters to consuming events coming out of the system easier. It would make testing easier, creating mock data of attaching fuzzers to it. There's all sorts of advantages to using a common data format, so I tried to lay some of them out in the rationale section here, but it really does seem like this is a huge key to a better design for smart contracts than what we've seen in a lot of other platforms, and so again, that's sort of- why this made up the first building block CAP is because if we do adopt this approach, we'll be will be deeply structured by this decision and obviously, if we don't adopt it, if there's really strong community feedback. This is a terrible idea. Nobody likes it. If all the technical review says this is impossible, it won't be able to make it work, or it's

[19:00] You know there's no way. You can never come up with common data types that everyone would find agreeable. That's really important information to know because it does seem very appealing. But if it's not going to work, that will also change our strategy very dramatically. So I've talked a lot right now. I don't know if you have any other questions or other things that you wanted to discuss about it. There's some detail in the CAP. Most of mostly conversation we've been having so far is just like around missing detail in the CAP or debating a set of objects. That's one of the big questions is like: which objects do you include as your sort of mvp first pass. What host objects do you include as your baseline? So I actually have one follow up question before we go deep into the details, which is: how do we encourage people to use these managed objects rather than to do something, you know, very offensive on the like the source language side, just because they can? Yeah, so this does not this, of course, this does not preclude, you know, shipping

[20:00] Your own encoder and decoder and just storing. There's a, there's a storing, there's a data type in this CAP called a binary, which is just a raw bite array. and so if you want to store a rod by right, and you want to ship the serialized, deserialized code yourself, we're not gonna be able to stop you. I mean, it's a touring complete environment, right? So that's like trying to prevent someone from computing a particular function. It's just not, it's against the whole point of the platform to try to prevent that. But I think you'll have a fairly strong disincentive just from the fee model. If there's any type of pricing of resources here, which you know there has to be in order to make to arbitrate access to cpu and disk resources on the validators, it will be a lot more expensive to do it that way, and so I think you'll just. My hope anyway is obviously this won't work very well if the fees turned out the other way, but my hope and my assumption is that you'll be saving a ton of- you know, whatever- gas metering fees. The system is charging users by using host objects because they're so

[21:00] Much faster and efficient. I mean, is it time to start digging into some of these details, or does anyone? I guess my first, the first question is: in general, do people feel pretty good about this model? I mean, so I have kind of a meta comment, which is that it seems to me, it seems, you know, having, you know, been involved in like a few standardization efforts, it seems a little weird to be contemplating a change of this scope without like a requirements document first, to reference, so like I have a bunch of nits, but to some extent it's gonna be like who knows? Because, like we don't know what the requirements are and aren't right. So I have, like I have huge concerns about the use of floating point values, for example. It just seems like I can think of like a million bugs that like really

[22:00] Catastrophic bugs that are that could happen right, like certainly in my lifetime. Like literally, hardware has implemented ieee floating point incorrectly. Right on top of that there's like from one release to the next of, like the compiler runtime, there might be small changes, like that they might use like a different, not a number, representation, because there's like tons of ways of representing not a number, things like that. You know positive, negative, zero, so, but you know, maybe we need it, maybe we don't, but like this is just without a requirements document to go back to. Like how do we know whether some of these things are good ideas or not, or whether they're gonna serve our purposes? So David, we've been, you know, we've been like the one thing that we have going for us right now is that there's a lot of prior art in the world of smart contracts and we have made a list of like sample smart contracts that we

[23:00] Are interested in seeing. Like that should be like a SEP or something there should be like this should reference like a document saying like you know, like these are the requirements for our for like smart contracts on Stellar, right, okay, that makes sense. I can work on that maybe in the meantime, if you have specific concerns, like the floating point thing is sounds like something we might want to discuss, I can speak to that a little bit. I mean just very briefly: wasm as a spec does include instructions for floating point. This CAP doesn't specifically preclude them. We've talked so far somewhat seriously about the possibility of actually filtering them out, of saying that all the floating point instructions equal invalid contract.

[24:00] Just again, to sort of to allay fears, because you're not the first person to use expressed fear is your own floating point. Now, personally, myself, I'm a little bit more of a floating point believer, so I I'm not as concerned about that. There are two sources of what we might consider non determinism or wiggle room in floating point behavior that are left open in the wasm spec. In all other respects, wasm just delegates directly to ie754 and if you do not implement 754 correctly, yeah, you're in error. That's that, that's that. And 754 has not actually changed in 40 years. So I mean I think that's actually a fairly stable thing to point to. Yeah, but it's not. the standard so much as like implementations of it which have been buggy. Or there's been like there have been like two cpus shipped in my lifetime that had bugs and they were like very high priority fixes. So I think saying like that,

[25:00] Saying like okay, like, but these are like exactly the cpus that would be like running Stellar core right, so this would be like catastrophic for Stellar core. So again, if we have a requirements document and say here's like 10 contracts you want and like six of them need floating point, then we need floating point. If zero of them need floating point, then it seems crazy. I agree that we can decide whether or not to have floating point. I think referring to the f div bug as a reason that floating point is not a reliable piece of software, is hyperbolic. I don't think that's a fair objection. Floating point is very well defined at this point. What about compilers that, like you know, use 80 bit when it's in a register and 64 bit when it's been spilled to memory? Right, like things like that? So a 80 bit floating point is not a an accessible format in lesson. You only have access to the 64, all the operations. But I find it like there's like a bug in the run time that it would like accidentally use 80 bit, but you're saying like that it's not available. It's literally not available

[26:00] On the target, the wasm target. does not have extended, floating point. There is, at the same time, to like figure out if there's a requirement for floating points before getting too deep into what might go wrong. I think it's the right one. Okay, so tell me, you're making that, you're gonna make that awesome sound. Yep, okay, are there other? You know? So floating points is we're putting a bracket on and it may come up, and it may not. We can have that discussion. Are there other like concerns like that we should get into now? Well, I think, like the big one is concurrency, right, like do we require? Like, if the requirements include sort of performance, then we need to be able to run, you know, smart contracts and multiple cores in parallel, which entails one set of requirements, like making sure that we don't run conflicting smart contracts in parallel.

[27:00] If we don't need performance- that you know- then we don't need that. But it seems like that again is something that we need to decide pretty early and it needs to be driven by requirements. Yeah, I can speak to that a little bit. That is definitely something that we have been extensively considering and have, in fact, a prototype planned for. As with everything sort of above, the single contract, single vm interface, it's not specified in this CAP. So this CAP doesn't, for example, talk about ledger entries at all, and so any concurrency issues relate to access to the ledger. There is essentially no, there are no concurrent host objects in this model and I, I'm happy to spell that fact- that these host objects are isolated to a single vm, the single vm, single threaded,

[28:00] Or sorry, to a single host context, which is may have multiple vms but they are executed on a single thread in serial. So there's no concurrent access to host objects whatsoever in this CAP, right? So this seems potentially not workable, depending on our requirements. Let me finish. Concurrent access to ledger entries is planned, so the ledger would be the shared concurrent data structure, the thing that it's meaningful to talk about concurrency with respect to, and that's something that we will be discussing in later CAP, because the transaction format for invoking transactions that we have planned includes a sort of- I guess a trick or a standard pattern from the deterministic database literature where transactions carry static read write sets, sort of staple to the transaction. So you know,

[29:00] The semantics are strict serializability, with the caveat that it's implemented by, you know, deterministically partitioned read write sets, especially. There's no actual contention. There's no requirement for concurrency control because the concurrent executions are all on disjoint data. I think so. An account ID, for example, it's a type that doesn't exactly respond to an actual account, it's just, yeah, it's just the public key or whatever. And then the contract literally can't see any data that it hasn't pre declared as part of its rewrite sets. So there's a, there's essentially a static data structure on a static schedule for each transaction set that partitions it into non overlapping partitions and then run concurrently. So I agree, it's a concern. It's something that we have been thinking quite a lot about. I don't think most of its contents show up in this CAP. I think they show up in that the.

[30:00] I think they show up in that the CAP that talks about the transaction life cycle and access to ledger, which will be coming later, but I can reiterate in this CAP that there is essentially where we're not going to be supporting the any of the wasm multi threading proposals that are floating around in the future for running inside one of these vms and that the multiple vms that exist inside of a host context that are described in this CAP are intended to be strictly serial semantics and that all of the objects would be private to that single thread that are described in this gap. So far, okay, cool, and so everything else other than floating point is like completely well defined in the wasm spec, like if you shift a 32 bit number by more than 32 bits, like that, that's like what does that do, for example, yeah, that that's that is well defined in the lessons. Back the. There are, as I said, there are two floating point idiosyncrasies. They're actually not the ones you're talking about. There's some

[31:00] Nan normalization, which all the interpreters we've been looking at. Have some option for normalizing bands after every operation is just expected to do and the state of the floating point environment flags. You have to. You know there's a hardware environment, the floating point environment, which control controls, the rounding mode and the exception propagation of the exceptions are eager or quiet, and that is assumed, that something. It's something you have to set and as a host environment you have to set it to a particular state before you invoke your wasm code. But there's no interface for changing it from inside, wisely code. So you know, so long as we specify what this, what the settings of the floating point environment are, it would be deterministic with respect to that. It's just that wasm as a spec doesn't define what you will set, the floating point environments settings too. So what happens if you right shift the, a 32 bit integer by 32. I don't know off the top of my

[32:00] 32. I don't know off the top of my head. You'd have to look at the spec. I don't have the glass inspect memorized, but it's it. It's very well defined. It's one of the most well defined vms out there. I think probably that's ever been done. There was something else you were asking about, though. Oh yeah, everything else he is in wizard is very well defined. The big caveat in my mind is that there are no host functions specified here, but there are a bunch of host functions implied by the data model, right like there's a map and a vector and a big num, and you know you only have those data values if you expect to have functions that operate on them. And a completely reasonable objection, that caveat that one might have to this CAP is I don't think it's possible to specify functions on this data type unambiguously. So you know we should leave it out, and I think that's particularly when we're talking about cost models. That's something I'm somewhat concerned about is making sure

[33:00] That it's that we're only including data types about which we can plausibly believe that we would be able to construct correct or at least worth case cost models for any of the reasonable operations that would be implied by the presence of that data type. So you know, big numbers imply there's going to be big number multiplication. Can we figure out a reasonable worst case cost model and make sure that that's correct. I think we probably can. That's why I include big numbers. I think big numbers are reasonably well studied. But you know if that strikes at the heart of fear of non determinism or fear of impossibility of bounding cost models, I think that's something that would be a very reasonable sort of point of debate on this. CAP is like please leave this out because it's too scary itself, like actually doing an exercise to create and enumerate on any of those in the CAP itself, or is that something that's just a bunch of unnecessary work?

[34:00] I don't. I mean the thing is we don't really. We don't have- at least I'm not, so I'm not really expert in CAP writing, but it seems to me that we don't have a section in CAPs that's sort of like miscellaneous discussion or speculation. And that's really what we'll be doing there. We will be speculating forwards to future CAPs and saying- and that's what's unusual about this app is that it is really incomplete. It's not a whole feature in and of itself. I say in the preamble to it that there's actually nothing new that a user can use here which is a little bit weird for CAP, and so it might make sense to include in that preamble, or in the context or justification section or something like that, a little bit of forward speculation about. You know, we assume that the following things are going to come. They'll probably look a little bit like this, but we're not specifying them here. It's just like for context. If you like, I'm happy to add that. No, it's okay, I think we are going to have those other CAPs, like the host function CAP, for example, is one that we need to

[35:00] Kind of lay out as well, right, and we have a different CAP. I think that would be around the cost model and things like that, limits and cost models. So it's all, it's fine, it's more like: yeah, it's one that's like being covered in separate CAPs right now, yeah, like we started to do that with feedex- actually the whole like split up, you know, like an actual protocol, into many pieces, so that we have like parts that we can think about discuss, and there will be some of that here as well, of course. I think we want probably, yeah, now is going to say real quick. Like yeah, I think we want to leave some time to also talk about the other topic for today. So yeah, David, you have another question. Oh yeah, what?

[36:00] So I guess I'm also trying to. understand like, so you can have like a 30 pin number, either as a value or as an object, a 32 bit number. There's no object type for a 32 bit number. There's only a version embedded in value, because it always fits in value is the 64 bit type, with the tag union on it. So there's no reason to ever box it. Essentially, sorry. So you have this part where you say like the only the data values that are shared are 32 and 64 bit numbers floating point in integer. And then you have these like tag types that include a 30 a 63 bit positive number and like a 32 bit unsigned integer and 32 bit signed integers. So how do those like what's the relationship between those? And like the fundamental values. Then I see, okay, yeah, sure, happy to talk about that. So the point that you're reading that says there are exactly four types of data

[37:00] Values shared between guest and host. I'm maybe being splitting hairs in terminology here a little bit. These are essentially the data values mandated by the wasm interface. So these are the only possible data values. There's no way for us to talk about a data value that is not one of those four. When we're calling a function, for example, and passing arguments, the only argument types are those four. So well, I see what you're saying, We don't have, for example, a 64 bit integer, like we, even though we can pass a 64 bit integer, we always interpret it as one of these tagged things. Yeah, so what comes later on is- and I should actually clarify sort of that layering here- is that we're picking just the 64 bit type. We're actually only using the in n64 and we're saying every value we pass back and forth is going to be an n64, and we're going to use it as a tag union inside of itself to carry a bunch of different stuff, so some of which can be an object

[38:00] Reference, which can be a small symbol. There's a bunch of little values in there. Well, should we move on and talk about the next agenda item, which is interoperability? There are a couple of questions here that I think yeah, I think we can ask more questions. on the dev meeting list, on the, runtime. All right, cool, let's switch topics then. So, excuse me, on the topic of interoperability, my questions kind of come back to the same kind of thing that David opened up with, which was like: what are the requirements? I've been thinking about this for, you know, the last like 10 days or whatever at this point, but it's really vague. What we actually want and one of the big questions that we keep coming back to, that keeps coming up in conversations I'm involved in, is, like, what should a smart contract fund seller be able to do? And one of the examples that

[39:00] You know keeps coming up is, like you know, one of the things that becomes very centralized on seller today is managing the authorization for an asset. You know like what if you want to have, like, a daily transfer limit or something like that. Like these are things that are really annoying to do because it all has to be done to like a central server, etc. But a smart contract could fulfill this role in theory. Do we want to make it easy for smart contracts to do this stuff where basically they become like a gatekeeper to classic, or do we want to not make that easy and basically say like, hey, if you want to build these kinds of things, just build them entirely and smart and get the features there. And these are the kinds of questions I'm interested in the high level and there's more to like how this is structured. But first let's just open this up like: do we think those kinds of things should be possible? Or should we just say like hey, just like do that in smart.

[40:00] And to help me like understand that, the actual question on this, like the low level type of you know super granular access control example, like the question there is like should people be able to do like a normal, like classic looking payment and it still ends up being gated by some smart contract? Is that what the question is? I can supply an example, but I mean understand the use case. It's more like in terms of the what is the question on the how? Is that really related to classic? I guess I guess the way that I'm imagining any of this stuff working is like anything that comes through, like anything that a smart contract is involved in, originates on the smart contract side. So you'd imagine basically saying, okay, I'd like to make this payment, but then the smart contract does everything, all the operations and stuff. It's basically just a gatekeeper. It's like, okay, like you can do this. Then it goes and you know, issues the allow trust

[41:00] And then it issues the payment and then you know it issues the revoked trust and etc. And it does all of that on the native, on the classic side, basically controlled by smart, so you don't submit a classic payment anymore. But everything is kind of happening classically, including all this allow trust stuff, which adds a lot of complexity, as we know. So I think like the payment alone is kind of an essential building block. You can't have classic, you can't have smart and classic like not even be connected by payments. That like that wouldn't make any sense. But the other stuff, you know managing trust lines, managing signers, managing authorization, all this other stuff. Do we want to allow that or do we want to just say, hey, I can't do that from smart? I mean, I think that, yeah, this is exactly getting to the core of like what, why I want the requirements that can be because, like one thing that like so definitely like, managing trust lines and allow trust is like a big pain it's, like something you might want to do is write a little smart contract says that, you know, if so and so has authorized you

[42:00] To like hold their asset, then like, you can automatically hold my asset, right? So, like, is that the kind of thing we want to support? And if so, that requires like a fair amount of, like a fairly wide interface between smart and classic. Right, you know my bias a priori would be to say that we actually want that because, at the end of the day, we want- you know, we want as much, we want transactions to be as cheap as possible, because that's always been kind of the Stellar way, and so the more we can kind of like leverage stuff that's implemented in c plus and it's potentially sort of optimizable through maybe even future things like speed x, like the better. It also, of course, makes it easier to debug. It's, you know, makes interoperability better because everyone's speaking like the same language using the same objects. But again, it boils down to requirements. So I can you know, while we don't have this document of requirements, I'm happy

[43:00] To throw some out there. You know a one, of the things that are very important for our ecosystem is that existing services and existing stakeholders don't become deprecated. So we're talking mostly about exchanges, about issuers, like circle. We want to make sure that their asset is still viable and fully functional with, you know, the new smart world. Now, what extent is it just like a user, just like you know, moves their value into the smart world and then, like it's a whole different primitives. I don't know, that's kind of like what we need to figure out, but we do want people to be able to issue smart assets as well. That is, you know a lot of people, a lot of issuers are using things like SEP 8 today to do things like you know, various velocity limits or like minimum balance on their native asset,

[44:00] Limits, and today that it requires a lot of finagling. It would be great for people to be issued, to be able to issue them, similar to how erc20 tokens are issued, so, but we could keep step eight. So, in other words, like there would be a new signer type which would be like the smart contract endorses, and then you could just kind of like do it through the smart contract, but like we would keep the same framework or not, right? Yeah, I think we're like I think you're getting into, implementation here. I just I'm getting into the how you choose. This actually affects CAP 46, like whether certain things are a good idea or not, or what base objects we might want to have supported, and so you know, like, for example, one thing that is not in here is any kind of capability right that I can tell. So, like, if, like a smart contract wanted to like invoke some privilege or sign some other

[45:00] Transaction, there'd be no way to do that. Maybe privileges, or whatever you want to call them, need to be some a kind of first class thing. My privileges here do you mean, like a contract has the privilege to do a certain action on a certain account that is not the contracts account, or it has a certain signing weight or something. Yeah, exactly, yeah, this gets into the like the second part of my question in the document, which is like the relationship between my contract signers, accounts and, like lee has proposed- this is lee here, I don't know, Yes, so leah's kind of proposed this model where, like, maybe a contract should be a signer in some sense, like, if a contract can generally control an accounts, trust lines, data entries, whatever the account

[46:00] Itself, then it should be a signer on that account and for a variety of reasons, maybe it should be the only signer with any weight on that account, so it has like exclusive control. But in this world, like you could still imagine the kind of case where you want like a one off right, like I want to allow this contract to like withdraw funds from my account right now, a certain amount that I believe is going to be withdrawn, like 100 or something. And this gets like a little weirder. It's like, well, what do you say? Like okay, like the transaction that runs the smart contract invocation, like the account signs that transaction and that's what gives it the authorization. But how do you be certain that the con that the smart contract invocation, at the time you actually run it is going to do the thing that you thought it would do? It's a little different from, like you know, a seller contract where you're like this is a payment for fifty dollars signed, and that's where I think these kinds of privileges come in, like either you give

[47:00] The account like one off control of your entire account at that signing weight to do anything. You know you say medium. Well, I can do anything at medium, whatever it wants. Or do you need some better control? I don't know, What do you think about this, David? I mean, yeah, I think that it cannot sound like a broken record, but like there are many possible answers here, you know, in a priori, without having the context requirements, might my kind of inclination would be to, you know, to make privilege something people tend to run into problems with, like ambient authority right when it's sort of like any time you do something, it's like if there's any possible way you're allowed to do it like you, can do it right. Think of all these like time of check the time of use bugs and stuff that happen in unix, and so to have some notion that a smart contract has privileges and then it needs to explicitly invoke particular privileges, like maybe there's a smart contract that has

[48:00] We wanted to have power over two accounts and so it has two different privileges and when it's doing something we want to literally specify which of those two privileges it wants to do to avoid, you know, a kind of confused deputy problem. So, without knowing the requirements, I would say like, I would like to: I it seems to me like maybe a good idea to have privileges be like a really explicit thing. But again, it's a little abstract right now. Yeah, definitely, if I can just chime in on one thing with respect to vocabularies and CAP 46- this is just a minimal prefix, right, this is this the set of host objects we can think of right now so you get to add new ones in the future, if we don't have to have a complete list for this, that's all I'm saying. Sure, but you know, getting the sort of

[49:00] Privilege model right from the start is probably a good idea. Like I don't know, there's, I mean there's- no concept of a privileged operation here, because there are no operations, so we don't. Yeah, all I'm saying is we don't have to worry about the weather. Privileges are properly modeled in this CAP. We can say: that is a thing we have to decide but doesn't necessarily hold this gap. One thing on the topic of privileges that I think is relevant here is like the bigger we make, the like interop surface area, the more complicated the privileged system has to be. If the privileged system basically amounts to, like you can only make payments, then it's like okay, like how much payment can I make from what account to what account, for what asset? That's like the whole space. I think it's sort of. unless that's right, it gets a little bit, yeah, more complicated about that. And, like you know, do we say that you can just do payments, or do we say that you can do payments at frequency? Or like had the number of cases, like we're

[50:00] Almost saying that permissions are almost a contract that you can implement. So, like we've talked about privileges and permissions before, but I don't think we've really talked about how do we make it so that people can innovate on them? Because you know, we could define some basic privileges but then people will be stuck, sort of what they have today with classic Stellar, that they'll be limitations that they're trying to like work around or, you know, they end up just going and building their own erc20 like contract just to completely replace the entire system because the permissions don't give them access to what they want to do. I mean, I guess one of the things I'm saying is that Stellar actually does already have a notion of permissions or a privilege- that's called signing weight, and so we haven't really sort of formalized it or maybe like expressed it this way. But you know the, you know with without knowing. You know, as a first

[51:00] Draft, we probably want to, like you know, use that exact same structure and not introduce something new. Like, where things tend to go wrong is if there's like two different- you know ways of talking about- two different privileged systems that are kind of operating on the same objects. Then you get like weird loopholes where people can you know? There's like a gap between the two that can maybe be exploited, so- but the signing weight is it's a really weak privilege system. That's what I was talking about at the beginning of this, where it's like I'm authorizing a contract to do stuff to my account at medium signing rate. What am I authorizing it to do, though? Like, unless I've audited the code, the contract might do anything. It's way more complicated than looking at a set of opera listeners. Contract is code, so this can only do what the code can do. Right, so sure, but I mean like what it might do could be complicated. It might actually even be very difficult for me to predict at the time that I

[52:00] Signed the transaction. Like, imagine a contract where it has two functions. One function is hey, set a number, and the other function is hey, whatever number was set most recently, extract that amount from my account and send it to the contract. I. There's no way I can know what the contract is going to do when I sign for it. But at the time you add that contract, at the time you give that contract signing weight on your account. There's presumably some reason for that, right? I mean you decided you wanted to this contract have access to your account, sure, yeah, but like I don't necessarily want to give it unfettered control over my account, right, or even very strong. The contract is code, right, so the contract does and you decide whether or not you want that to have access to your account. Right, if the only thing a contract does is, you know, manipulate the

[53:00] Authorized flag on trust lines, then you look at the code. You say great, like, I don't have to worry about this draining all my lumens by signing like huge account fees. What if the contract is mutable? Well, okay, so that's something that needs to be driven by the requirements document. Do we need mutable contracts? Right? General consensus in this room is yes. What that question there's general consensus on in this room and the answer is yes, okay. Well, I need to be convinced, like I'm not saying that you can't, but don't show me the requirements that tell us we want that what we want cannot be achieved through, like, multiple releases of a contract. It's just like having eval in an actual contract, right. But if you have multiple releases and a point of indirection- which is the pattern people have when they only have immutable contracts, if they have a point of direction, like a proxy or something, and then releases, you still have the possibility of the requirement, in fact, of people delegating authority to

[54:00] The indirection point with permission, and saying I give permission to this indirection point, whatever it happens to be pointing to right now, to do something. And so you're right back with beautiful contracts. People will work their way around, which is something that is behaviorally equivalent to a mutable contract that has whatever permission you've given them. They'll either investigate another question on top of mutable contracts or via whatever indirection system you build. But I just want to say we are pretty much out of time. So if this feels like a great last question, I'd say ask it. If not, maybe we hold off. Well, I was just saying like you can have your contract, not have direct access to the account, but just have access to another contract. That only does certain things like, not the things you don't want to do, but anyway. So it seems like a requirement. We just keep coming back to this requirement. Stock that you're requesting would be the thing that would help guy guide us, figure out the answers to these questions. Okay, cool. I'd also like to propose perhaps moving this meeting to the dev Discord and having it weekly instead of every

[55:00] Other week, because there's there are going to be a lot of questions that we need to answer, and do it quick with John cannon, cool. I mean, I think that we should ask that offline and just verify that works for everybody and look at calendars and I can do that after this meeting. Awesome thanks, everybody. See you next time.

</details>
