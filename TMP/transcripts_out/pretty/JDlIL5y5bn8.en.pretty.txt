 the first is partial stay archival.Cap 62 and then in memory Soroban.State for CAP 66 and no Tom I will never.Stop using in Centric Linux distro cool.So I guess before I get started guess.A little bit of background so.Protocol 23 is kind of where the.Rubber is going to start hitting the.Road as far as state archival is.Concerned so kind of some you know.Background to you when soron launched we.Of course had the interface for state.Archival with rent and all those sort.Of stuff with the intention that.Eventually entries that have run out of.Rent will be archived and then removed.From validators in order to free up.Space so you don't have you know the.Issues that come with large amounts.Of state that have to be.Maintained and so that's kind of.Where we're going now today the.Interface is such that you still pay.Rent you still have to issue restores.And all the sort of things things but.The data is not actually yet removed.From.Validators and so that's where we're.Going so initially the plan was for.Protocol 23 was to have what we're.Calling full State archival and in full.State archival what happens is .Entries once they have run out of.Rent be removed from the live State.And then they are added to this.Temporary data store called the hot.Archive and the hot archive is still.Maintained by all validators but it's.Just a separate database that just.Maintains entries that have been.Recently archived the thinking being.Was that eventually this hot archive.Would become full and when the hot.Archive is full what you would do is you.Would create a Merkle tree of that.Data validators would maintain the.Merkel rout and then delete all the .Information in the hot archive and then.You just repeat this process iteratively.So essentially you evict entries from.The live state to the hot archive state.Eventually that hot archive cach will.Become full and then you'll actually.Delete and remove those entries from the.Validator and then the restoration.Process once an entry has been archived.In this way if it no longer lives in the.Validator there's like a Merkel style.Proving scheme to which you are able.To restore an entry back to the live ler.State so that's kind of what we consider.Full state archival which is where.Entries actually get deleted from.Validators but thinking about this.Problem a little bit more and looking at.The current metrics of soron it seems.That we're still a little too early for.This full C archival I think long term.If you look at smart contract.Platforms that have large amounts of.State there are significant issues with.Maintaining all that state you have .Lots of you know Hardware.Requirements on a network like salana to.Maintain large amounts of cashes and.Then you have a networks like.Ethereum that don't have large hard.Requirements but they're very slow just.Due to maintaining these very large.Databases so long term at scale I think.It's still very important to have the.Full State archival solution where.Entries are deleted from validators and.Then restored VI proving schemes but.The reality of the situation is we're.Not quite there yet and I think that.Currently there is less than a gigabyte.Of soron state currently live Stellar.And so going through all these hoops.And adding all this complexity for.This proving scheme just to delete a.Small amount of data isn't really .Worthwhile at this point and so that's.Why for protocol 23 instead of going the.Full cival route where we actually.Delete entries we are doing something .Called or I'm proposing something called.Partial SE archival and this is what cap.62 kind of explains and so in partial.State archival what we do is we do kind.Of the first half of the full state.Archival so we still maintain two.Different databases on the validator you.Have the live bucket list which contains.All of your live state which is the .The Ledger that exist today and then you.Still have a what's called the hot.Archive which is a cache of recently.Archived entries and so what you would.Do is that whenever an entry runs out of.Rent it would be evicted and removed.From the live State and added to this .Hot archive database now the key.Distinction here with partial stay.Archival is even though you still remove.Things from the live bucket list and add.Them to to the hot archive you never.Actually delete the hot archive the.Hot archive never becomes full such that. the entries are never actually.Removed from validators and so it's.Partial St archival because you are.Still kind of storing live state in one.Database and storing archive state in a.Different database but you're not.Actually removing any state from.Validators and so I think my current.Proposal would be in protocol 23 to.Implement the partial state archival.With the intention of later on in the.Future extending this to the full State.Archival solution the only reason is.Is that I.Think that for the you can the the.Size at which the the hot archive.Becomes full and becomes deleted is.Configurable and so I think we could.Do something reasonable such as we could.Implement on this St archival solution.But we could set the the capacity of.The hot archive to something very high.Like 50 GB such that it would take a.Long time and a lot of network activity. to actually start deleting State and.Then you know if the network was to grow.That much such that we had 50 gigabytes.Of archived sorb on state then it.Would actually make more sense to start.Deleting State and requiring proofs for.All the operational benefit that we get.There and so that's kind of the.Current proposal of 62 is we're going to.Still maintain all information on the.Validators but we're just going to move.Archived information from one database. to a different database now the.Reason that we want to do this this.Separation of archive State and live.State is that it actually opens up a.Large number of optimizations and so.That's what we get into in CAP 66 which.Is inmemory Soroban State and so we.Can because we have the system where the.Live State or the live bucket list.Holds all classic information and all.Live soron information and we have a.Completely separate database that stores.All the archive State now because of the.Rent system and because of the the.Way that we do write fees you know where.A write fee is a function of the total.Size of the bucket list we actually have.A way to put a soft limit on the amount.Of live soron State at all times the.Reason being is that you know with the. the current bucketless size if you.Were to add enough life State such that.You go beyond the target bucka size.Rights become very very expensive such.That the network users are.Incentivized to allow entries to run out.Of rent and become archived and so.Because of the way our fee system works. we have a way to essentially have a.Soft limit on the amount of State in the.Light bucket list at all times and so.What I'm proposing is to change that fee.Slightly such that instead of the.Sorbon right fee corresponding to the.Size of the entire live leer of both.Classic and Soroban entries it only.Applies to the life soron entries and so.Essentially the the buckus target.Size instead of being a buckus size.Would change to just be the the life.Soron Target size and I think this is.Much more fair given that classic.Entries don't actually have to pay rent.Yet and so it's a little unfair that.Adding classic entries actually changes.The WR fees and the rent fees for Soroban. and especially as the network exists.Today classic State dominates sorant.State size and so changes in sorant.Usage don't actually really affect soron.Right fees rather changes in classic.Usage affect soron right fees and so by.Changing the The Bucket List Target size.To a Soroban state instead of just all.Total State we have a much more fair.Fee system but what that also allows us.To do is to prioritize live sorup on.State above arive state so what do I.Mean by that so if we change the the.Way that we calculate fees to only look.At sbon size we can use the fee system.To enforce a maximum amount of Life.State at any time so for instance we.Could set the target soron State size to.1 Gigabyte and then the fee system would.Ensure that there's not much more than 1.Gigabyte of Life Sor on state at a given.Point now you could maybe you know go a.Little bit above that if people are.Willing to pay expensive fees. but the way that the fee growth works.Is that you know you are reasonably.Capped to a small amount of state and so.Because we have the system where the.Amount of live sorb on state at any.Given time is fixed what we can actually.Do is just store all Soroban state in.Memory and not have disk access at all.And so that's the current proposal in.Cap 66 is to prioritize all live .Soron state in memory and this is.Made possible because we store live.Soron state in one database and archived.State in a different database and so by.Splitting the state into two separate.Databases we can very easily just.Iterate over the the live database and.Store all that sorab on state in.Memory and so that's kind of what's.Happening behind the scenes as to.What the the validator is doing .Now we're able to do this because of the.Maximum soron State size if we didn't.Have this and if.Sorban LIF state was able to grow.Unboundedly this would be a very.Dangerous optimization because.Validators might run out of ram but.Because of the St kival system we can.Actually fix the amount of Life State.And so there's no runaway R risk and so.We can very reasonably store all.Soron state in memory and so there.Are some changes we need to make to the. developer experience and the user.Experience to make this possible so.First we are going to to change some.Of the resource types A little bit So.Currently today we only have one read.Resource which is read bites and read.Entries and this assumes that all the.Information you're reading is on disk.And so what we're going to do or what.Cap 66 proposes is to split this into.Two different resource types so they're.Going to be an explicit inmemory read.Resource and then an explicit on disk.Read resource now the reason we're doing.This is that even though all Soroban.State is or all life soron state is held.In memory Soroban contracts can still.Access classic State and classic State.Needs to be on disk now because classic.Entries aren't subject to State archival.They have the runaway Ram risk and so.We can't store classic entries in memory.And so Soroban contracts will still.Have to pay disk fees for for classic.State that's exist additionally we're.Only storing live state in memory and so.If you access archive state for example.A restore operation then you would still.Have to do dis reads and so there's a.Dis vew for that but essentially what.Would be changed is that you would .There would be a network limit for the. maximum number of on disk read.Entries as well as the maximum number.Of inmemory read entries now that being.Said because the inmemory reads are a.Lot cheaper than the on disk reads we.Can actually pass aot that savings down.To the user so in this proposal .There would actually be no in memory .Read bites limit so essentially the.Read limit for Life s on state would.Just completely go away because in.Memory reads are cheap and so there's no.Reason to limit that now we would.Still limit the total number of entries.Being read but the bytes being read.Would not be limited additionally .Because we're not doing dis access .There would no longer be a read fee.Associated with accessing Sor on State.And so because you you still have to.Pay like a instruction like CPU .Count and things like that to actually.Process large amounts of data but.Because we're not going to disk there.Doesn't need to be an explicit fee or.Resource for that and so essentially. for live SW on state you don't have.To pay for reads and you can read as.Many bytes as you want you still have.To pay for the CPU though so it's still.An implicit fee but there's no explicit.Read fee and so that's kind of the.First Advantage to the inmemory versus.On disk resource now the second thing.This allows us to do is is also.Implement autor restore functionality.And so previously when we first.Launched Soroban we weren't sure what the.Final State archival proof system was.Going to look like and so while from a.Technological or from a technical.Standpoint there was no reason to.Require a separate restore operation.And a separate invoke host function.Operation we did that just to give us.Flexibility later on in case the proof.System turned out to be very involved .But in CAP 57 we've actually outlined a.Pretty lightweight proof system that.Works with invoke host function and so.What we're going to do in CAP 66 is.We're going to allow automatic restore.And so what this means is that you no.Longer will have to issue a restore.Operation prior to your invo host.Function but actually your invo host.Function operation will just.Automatically restore any archive.Keys that are in the footprint and so .This you know reduces the transaction.Count required reduces fees and should.Just offer a much better user experience.Now the the way this works in resources.Though is that like I mentioned before.The live Soroban state is all cached.In memory in one database and archive.State is uncached and on dis in a.Separate database and so if you call.Info Coast function and every entry.You're using is currently live.Then you would have the free inmemory.Resource bites and you wouldn't have to.Pay for dis that being said if you're.Using automatic restore the entries.Being restored would come out of the.Disk read bytes and would be charged .Disk fees because again for the the.Entries that are archived and live in.The hot archive database those do have.To be read off a.Disk and so I think that's kind of a. kind of at the high level of what.We're proposing kind of you know the.Tldr except been talking for for a.Little bit is that you know C the.Archived entries live in their own.Database and live sbond State lives in. the separate dat or a live database. we are then going to Cache all the.Sbond state in the live database in.Order to pass that savings on to you.There will be an inmemory rebite limit.And an on disk rebite limit in fee.And then finally there will be.Automatic restore to you know.Essentially remove the need for the.Restore operation in most.Cases so I guess are there there any.Questions or any conversation points.We'd like to touch on.More looks like there's a question in.In the this in the chat the chat box.But I think a lot of daps and .Extend TTL by default will that still be.Necessary.Ah yeah so I think so just because we.Have automatic restore doesn't mean that.You don't want to still manage your TTL.And so like I managed before if all the.Entries that you're using are.Currently live then what're or then.You don't have to pay read fees and.You have much larger read.Limits and so you are still.Incentivized to pay rent also so but.The issue is when you restore when you.Restore something you have to pay right.Fees for the restoration and you also.Have to pay discre fees for the.Restoration and so I think from a .From a fees perspective if you're using.An entry a lot it's still in your best.Interest to extend the TTL to save.Money as you know even BEC just.Because the restore is automatic do not.Make mean it's free and so you still.Have to pay for that restore and even.If it's the same invo Coast function an.Invo Coast function invoking a.Function that only accesses live.State is significantly less expensive.Than invoking a host function that has a.Automatic restore on the front end of.That so we still definitely want to.Extent.TL. yeah let's.See oh so for OrbitLens will it be.Possible to tell in advance whether the.Entry will be automatically restored.During the simulation yes and so this.Is kind of more of the implement.Details which are included in the CAP .But what we're doing is captive core has.Recently added a couple of HTTP n.Points for querying Ledger State that.Will be used by RPC in order to.Simulate transactions correctly and so.Essentially this endpoint is a high.Performance you know multi-thread HTTP.Endpoint that has a similar.Performance to a SQL table queries.And so it should be appropriate for for.Production use cases and what this.Endpoint will do is it's a key value.Search where for every key you provide.It it will tell you if that key.Exists and then if it exists it'll give.You the value and then it will also.Give you meta information about that key.And so it will give you the Ledger entry.It will tell you if it's live or.Archived and then it will also tell.You you know what its current TTL.Value is and if it's in memory or on.Disk and so the captive core endpoint .Is kind of Ed to be the new kind of.Entry point for this information and.So you should be able to query the.Current archival state and the current.In memory versus on dis state of any.Entry directly via captive core again.There's also meta that we're emitting.For all these events so if you wanted to.It's theoretically possible to injust.Meta and maintain the state of Soroban .Entries that way but if you don't.Want to do that and create your own SQL.Table and Pipeline and pipeline you can.Just use the the captive core htpn.Points so will automatic restore.Become automatically available for.Existing contracts yes so the this is.All handled at the RPC level and so.The essentially what's changing is that.With protocol 23 and this is detailed.In CAP 66 specifically.Is that we are changing the footprint to. have this field where you distinguish.In the footprint if a sorond key is.Either in memory or on disk and so.Essentially what the validators will.Do is that for whenever they receive.And apply an info Coast function they.Will look at the footprint and for every.Sore Bond entry that is marked as.Being on disk AKA marked as being Arch. before running that transaction .The validator will essentially restore.Those entries automatically and so.The actual contract and the contract.Logic will not change which means that.All deployed contracts are automatically. compatible with this now the.Invocations to those contracts will.Change slightly because of the footprint.Changes but again this will all be.Handled by RPC and so pre-flight will .Will do all this automatically. let's see other.Questions oh so ler streaming mode .I'm I'm not sure about the context .But.Behind enabling or disallowing .Metast streams on validators versus.Captive core instances I imagine it.Has to do with performance reasons where.You don't want ingestion to make a.Validator fall out of sync and.Essentially that config setting is an.Opinionated way of saying that validator.Should be high performance and never.Get blocked whereas like a watcher node.That's not participating in validation. would be more appropriate for.Observing and adjusting the meta because.There's not it doesn't depend on a.Downstream system where if the meta.Stream gets clogged because the.Downstream system isn't adjusting fast.Enough you wouldn't want to lose sync.And have a validating node fall off the.Network because of a a downst stream.Issue.Cool so I guess..I'll from George about the CAP mentioned.Somewhere that autor restore won't.Always be possible can you elaborate on.These scenarios ah yes okay thank you.For pointing this out so there are a.Couple of edge.Cases where an invocation will still.Require an explicit R operation. sorry and so essentially. because the inmemory reads are so.Much cheaper they don't have .Limits like the on desk read the.On just do while there there is no.Read byit limit at all and while.There is an entry read limit the.Expectation is that this limit will be.Significantly higher than the dis limits.And so just for you know example.Suppose that a in protocol 23 the.Transaction in memory read limit is 40.Entries and the on disk read limit is 20.Entries and so say you have like this.Dex you know trade that will access.40 soron entries now if all of those.Entries are Al then you know the .It's within the limits the invocation.Works no problem but say that all 40 of.Those entries are archived now even.Though the inmemory limits are large.Enough for that transaction to succeed. you can only the the automatic.Restorations will come from the on disk. limits and so because you have to pay. disk fees and are subject to the dis.Limits for the restore operation you can.Only restore in this example 20.Entries automatically even though you.Need to have authority to be live to.Complete this Dex trate operation and so.In this scenario you would need to to .Still manually submit a restore.Operation just because the way.That the limits are set you can't fit.That many restores in a single .Transaction now that being said .Especially given some other exciting.Work that's happening in 23 we expect.To raise limits pretty significantly.Across the board and so I suspect that.This Edge case will not affect most.Transactions it will only affect very.Expensive transactions that are doing.Stuff and so for instance if you have.A DEX trade and it's trading assets.That are mostly live you won't be.Affected really you're only going to be.Affected if you have like a DEX trade.That's crossing a ton of orders and for.Some reason all those orders were.Archived so you mentioned that the.Restore op could be deprecated .Because of the automatic restore but.This Ed Case requires you to keep.Something something like that around.Right yeah so I think I mentioned.The CAP that we met deprecate the.Restore op and that's just because.That if the footprint is automatically.Restored then having both the restore.Op and the extend TTL op is kind of.Redundant because for instance say.That you just want to restore something.You don't actually need two operation.Types you could just essentially use the.Extend TTL put all the keys you want to.Restore in the footprint and then just.Set the TTL extension to zero and this.Is functionally equivalent to the.Restore up and so when I mentioned .Deprecating the restore op I don't mean.Deprecating the ability to restore.Transaction or to restore entries via an.Explicit transaction but just mean like.You know mechanically do we need both.The restore op and the extend TTL op.Where the extend TTL up could now you.Know in theory at least both do a.Restoration as well as.Extend okay yeah that makes sense Nico.Had a question about how the Soroban.State size is initialized at upgrade.Time it's it's not specified in the cap.Yeah I think I need to expand on this.A little bit more so I think part.Of this CAP is that we are changing .The semantic meaning of a network config.Setting so so in particular The.Bucket List Target size will become the.Sorbon state size now the issue is.Currently the bucket list is like 11 or.12 gigabytes and so we all of our.Network settings are assuming that.The your target size is like 13 gigs .But now the issue is if we you know.Do a protocol upgrade protocol.Upgrades previously have never actually.Changed config settings and so if you.Just do the protocol upgrade all of a.Sudden instead of your Baseline .For fees being 12 gigs with a target for.13 gigs because we're only tracking.Sorbon State your target is still 13.Gigs but now your Baseline is like 400.Megabytes because there's like a lot.Less soron State compared to life State.And then you have this dos attack where.Until you upgrade the network confix.Settings you essentially have no read or.Write fees for both in memory and.On dis State and so you could have like.A Doss attack where someone writes like.Tons and tons and tons of temp entries.And like you know spams The Ledger for.Essentially zero fees and so I think.What I'm proposing is that you know.Currently there's like an operational.Lag between upgrades because core.Validators can only cue one upgrade.At a time and so we'd have to get all of.Tier one to arm for the protocol 23.Upgrade and then after that goes through.Have them all arm for the network config.Setting upgrade and in between that time. you have free free reads and free wrs.Which is a huge security risk and so.What I'm proposing is that because.Protocol 23 is semantically changing .What this config setting means the.Protocol upgrade itself should also.Change the value and so you know this is.Slightly different implementation wise.Than what we've done previously but I.Think it should be relatively.Straightforward implementation .Whereas like the protocol 23 upgrade .Both semantically changes what the Buist.Target size means as well as it resets.It to a initial starting value that's.More reasonable given this new.Interpretation of the data.Okay so we've actually updated.Settings on protocol upgrades before.That I think we we know that works cool.Okay great let's see a couple other..Questions okay so for OrbitLens the.Storage for the hot archive yes so .The hot archive and the live Buck list.Are both part of ensus so we need the.Hash of that state and so for that.Reason both of the the live database.And the hot archive database are both .Bucket list DB.Implementations and that's just.Because they we have to meriz those.Structures then Buck list DB is pretty.Fast these days now with respect.To offering tables to buckless DB we.We don't really have any plans to do.That and the reason is it's a very.Difficult structure to add tables to .So it's a it's a log structured merge.Tree which is kind of a a variant of.Like database used by like rock CB or.Level DB and it's also completely.Made inhouse like we didn't Fork levels.We didn't Fork rocks or anything like.That and so kind of we we have it.It works very well for query types.That the valers require and it's very.Efficient at those but we have to.Essentially like hand write C++.Optimized code for those specific.Queries and and so it would be both a.Very significant undertaking to allow.Like you know arbitrary index types .For Downstream and it would also.Probably not be a very efficient.Database just because it's a lock.Structured merge treat and so a SQL.Style index query would not work very.Well on it and so I think what I'd like.To do with this is you know we've.We've for arbitrary key value lookups.We have exposed end points that are.On the same scale as SQL queres but.Again they're just raw key value stores.They're not like you know indexes or you.Know really tables and I think .There's been a lot of work done by.The platform folks on like the the.CDP and things like that and so I.Think given that the complexity of.The database of Stellar core is.Increasing a lot and for a variety of.Reasons we only support Buist DB now.And no longer support SQL I think.That any sort of raw database.Access needs to move more in the.Direction of utilizing Downstream.Utilizing met ingestion using CDP and.Not rely on direct access to course.Databases just because you know nowadays.With buck DB the core database is very.Specialized and is not suitable for.Generic queries.Cool I.Think there's a couple people typing so.I'll let them finish or if anyone else.Has any other questions if not I have a.Third CAP that I'd like to introduce. I'll give it a second and then we can.Move.On all right I feel like that's we've.Had enough time oh answer about.Slp1. dial would you mind linking that.Question again I'm not quite sure what.The slp1 question is.Oh yeah the new limits sorry.Yeah cool so I guess now I'd like.To move on to CAP 65 the reusable.Module cache and so like I mentioned.Before we were doing all this.Optimization stuff for a memory State. and essentially in addition to .Saving all the contract data in memory. we can also save all the contract.Code and by extension all the.Contract modules in memory because.You know we have a way of EX of.Archiving contract instances and.Contract code that hasn't paid rep.Recently and so with that I think.Gr's on the call if you want come up and.Talk about CAP 65.I don't think gr's on the call I I.Believe we were going to speak about CFE.65 next week right oh sorry I guess I.Got a I gave youall a little teaser for.Next week then my apologies got a.Littlee of the gun but so yeah so. I don't want to steal grain thunder.So I'll just you know leave you with a.Teaser that we can you know have lots of. this not only helps optimize the the. read limits but also optimize CPU.Utilization as well but we'll talk about.That more later.All right unless there are any other.Questions. we can conclude this.Meeting thanks great Garen it was a.Great.Talk all right thank you and you know.The dis if youall have any more.Questions or concerns you know there's a.Couple of discussion tabs on the Caps or.Just ping me on Discord.
