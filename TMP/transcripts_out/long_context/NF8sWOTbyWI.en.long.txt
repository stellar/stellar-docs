Okay so I think we're gonna get started and hopefully david will soon join so hey everyone welcome to another. Protocol meeting I'm filling in for justin today I am seeing this so in these meetings. We discuss potential protocol changes these changes are outlined in these documents called caps or advancement. Proposals and the big change we're working on right now is project jump cannon which are. Which is a feature to introduce native smart contracts on Stellar so we've divided this massive change. Into a set of composable caps and the agenda specifically for today is we're going to talk about cap 53. Smart contract data this was recently published by graden we're going to talk about cap 52. Smart contract interactions minimal which was recently introduced by john and we're going to talk about the smart. Contract life cycle cat 47 which was recently updated by siddharth and requires some . For the discussion so let's do this graded can you kick this off with a review of cap53. Yeah just give me one second all right got it yeah sorry I just I had the pull request open and then I actually. Wanted to switch over to the merged version of it so this is a fairly straightforward cap. It's not it's not really introducing anything that probably will be a surprise to anyone. Here it's just formalizing something that was left out or left sort of for future caps in the modularization that. We've been doing splitting off conversation into different pieces so that we can work on. Them separately and land them separately but it's fairly tightly related to the data model that was presented in cap 46. So a lot of the motives in cap 46 around the data model implicitly talked about how . How that data would be stored permanently so there's there's there's concerns that that bear on the. Data model that are sort of interacting with it while it's in memory and then there are concerns more. Related to its long-lived accessibility over over multiple invocations of a smart contract well. It's stored on the blockchain so some of the requirements that are sort of rephrased and and brought into the. Foreground here have to do with interoperability where we we want there to be something a. Little bit a little bit more general or I say sort of a less general more interoperable more generally understood. More widely understood structure to the data than just a byte buffer a lot of smart contract platforms essentially. Only provide a byte buffer storage service to smart contracts which means that nobody really accepts that exact. Version of the smart contract code can necessarily read any of the data that's stored there and that that. Produces interoperability problems if other third parties want to access it offline you know browsers that want to. Take a look at the data it also creates versioning problems because it means that you're. Originally locked to the schema language or serialization format that the contract used it means the contract. Wants to pass data it has to from one contract to another it has to transform it so there's a whole interoperability. Angle here which we wanted to address in in the cat 46 data model and we're carrying that forward here and I think a. Lot of the the concerns only make sense when considered in terms of persistent data but this is the. Persistent data cap so so here we're just talking about basically what the ledger entries. Is gonna store things looks like and a handful of host functions for for accessing it they're very basic. Functions they're just key values to our access functions they're point access functions they're not range range. Functions they don't include iterators or range queries or anything like that they're just get put. Does do we have a key and delete the key very simple host functions the interesting thing really is. The choice of granularity which is left to the user so this is a little bit different in in that . Many blockchains provide a this is this is different than many many smart contract systems you'll see many. Smart contract systems provide a key value store which is keyed by a byte string or some some kind of a prefix. That goes into a merkle tree or something like that we do not have we essentially don't expose any interior. Nodes of the mercalli storage that we use to use this anyway we just provide a single bucket list. Hash the fact that our data structure has internal localization doesn't really apply here anyway. and structurally it wouldn't make sense but  what we're what we're doing here is also. Allowing structured values as keys rather than rather than byte string so of course you. Know you can serialize any value and you will in the case of using it as a string here but the api is encouraging. Users to have fairly structured values so they can have fairly rich keys . And implicit to all of this is that there's there's a parallel access and consistency model. that's discussed in this cap which is that we're we're trying to encourage the possibility of executing. Smart contracts in parallel and if you have parallel access to a data store you have to talk about what the. Consistency model is what is it what does it mean when two different users access that that model. In parallel so we're specifying here that it's a serializability consistency model which is the strongest possible. It says you know equivalent to the exact order that the transaction sets specified the transactions executing in. That has to be the observable side effect model and parallel models parallel consistency. Models imply the existence of some kind of a concurrency control mechanism how how you actually enforce that. and in in this cap we're talking a little bit about a very strong mechanism for. Concurrency control it's what's it's what's typically called deterministic scheduling or non-conflicting. Concurrency control the idea is that every transaction that enters the system will pre-declare. A footprint so there's this thing called the footprint which is the the set of keys that a transaction is going to. Touch whether it's going to read them or write them it actually marks whether it reads or writes each key in. Its footprint and the footprint is is static information that accompanies a transaction so. This cap doesn't describe exactly how a footprint is encoded or accompanies a transaction location because we don't. Even have a cap open right now that has transaction invocation or at least we haven't settled on one we. Have several caps open right now but when transaction invocation occurs it it's going to need to provide. A footprint in in this cap this cap is asking that that footprints are available and the. Footprint defines the keys that are that the transaction is allowed to perform these data access operations on. So if you try to perform a get again something that's not in your footprint the get will fail even even if the. The value is there if it's not in the transaction's implicit footprint it's defined as failing similarly for. A put or even has a point query anything like that you have to have it in the footprint so. So for simple transactions this is fairly straightforward you can tell what they're going to read or write and so. You just put things in the footprint that they're going to read or write that's fine. For complicated transactions that have a highly dynamic behavior maybe maybe it's. Not even clear what they're going to read or write because it's it's you know subsequent to a transaction . It's it's determined by an earlier read in the transaction these are what are called . Transactions with dynamic footprints the recommendation in this in this gap . And what we what we're prototyping is a fairly standard technique from the literature which is often called. Reconnaissance queries I think I'm using them here I'm using the term recording footprint recording here which. Is that you just run the transaction offline before you submit it on on a read snapshot and that gives you. A a fairly good guess and an approximate footprint that you can then staple to the real transaction when you submit it. And it will succeed if that footprint still matches so it essentially pushes concurrency control. out of the the transaction processing loop and into the user's lap and so the the user is now racing. On divergence between read snapshots that they use to construct their footprint and the footprint that they. Actually submit a transaction with and so theoretically if there's a very very highly contended key and it's a very. Different query they may have to retry multiple times because if they get if there's any significant divergence. Between the the recorded footprint and the footprint they submit their transaction could fail. But the database itself doesn't have to actually perform the concurrency control so in. Some ways this is shedding load from a concurrency control mechanism inside of a database out to the users. and that has turned out to work very well for for maintaining a very even high throughput. on existing databases that adopt this technique so we're trying to adopt that technique as well. So those are the the two sort of main topics in here that the fact that the user has control over granularity i. Should go back and talk a little bit more about granularity just for a second which is that the the granularity. Control that exists here it has a natural tension in it so it's so doing a point read on a key value store. Necessarily has some overhead it has it has data framing overhead it has serialization overhead it involves going. To the I o system at all it involves touching the disk doing a seek doing a read all of that overhead is.  potentially quite high and and so it's it can be worth trying to amortize that. Overhead and read more than one item if you are going to access more than one item you don't necessarily. want to to pay that on on a bit by bit or bite by bite basis you want to bring in a bunch of bytes at a time when. You do an I o and so that amortization tension pushes you towards larger ios in a larger granularity of storage. But then the flip side of that of course is that if you read or write data that you don't actually need if it's if it's. Wasted and you actually only wanted to change one byte in the middle of a large data structure that's waste and you're. Paying for that waste in terms of you know fees or cpu time or io or whatever so that that pushes you in the opposite. Direction of having fine grained data and  that problem actually just magnifies. Itself when you start talking about parallelism because again your footprint is a unit of contention and so if two. Transactions contend on the same data value they can't execute in parallel basically that's that's that's what the. Footprint is is doing is that it's giving a static scheduler the opportunity to partition execution into separate lanes. And then those lanes will run with no coordination but those lanes necessarily are serial. Themselves you only get parallels between them and so if you have a whole lot of transactions for example. That all touch some common data value in their footprint they will all be scheduled to run in serial. And so to exploit parallelism it is it is in the favor of the user to have a finer grained footprints so. So you have this sort of two different directions of pressure it's a natural trade-off between. Fine-grained and coarse-grained data access and so we don't specify what what the granularity is here we try to. Be very open about that and and so that's why the key type is is literally just an arbitrary value. I think that's all I really had to say about that there's not a lot in this in. This gap it's actually quite small and it it kind of just does exactly what you're expected as a key value type. Awesome can you just quickly talk about the rationale for why there is point access only. yeah so range queries essentially aren't compatible with static footprints . Because you know we don't we don't know how far they go that's that's the simple version . We we could theoretically but we would lose parallelism so yeah awesome so we are. Kind of like actively trying to deter you know contract developers from creating these like . you know creating like a need for rangers with some you know like for example like a classic or the book is. Probably like not a great fit for this which is okay with us yeah and I mean there. It's a good point which is that in in in in a broader sense a static footprint actually bounds the i. O you're going to do it allows us I mentioned this in in the contract it it it allows us to. Essentially have no surprises the contract is not going to be interrupted in the middle of the contract in order. To actually go touch the disk dynamically everything that it's going to read it says upfront and therefore we can. Just do a bulk read at the beginning of the contract just in fact we'll integrate into a. Single pass through the the storage system all all of the reads from all of the contracts in a given. Parallel execution lane will just read all their data at once at the beginning of a transaction set. Execution and then write it back at the end so that  that kind of thing is is naturally. Incompatible with something like dynamic range queries but that said because you can store you know arbitrary. Values if you want to store a map that's that's completely reasonable one of the values that you store it doesn't. Have to be just a small string or a number or something you can store a map that has a bunch of stuff in it . And then do a range query on that map it's just that when you do an I o you're going to get the entire map is going to. Come off the disk so you have to sort of navigate that trade off yourself maybe shard your map into a bunch of different. Sub maps or something like that if you're interested in not loading and storing the whole thing every time. When I tried to to use a very early version of this design like a month ago or something. One of the kind of like annoyances that I quickly encountered was like when I wanted to. You know partition my namespace I basically was like okay well I need some kind of key that is a tuple. And so I just used like the sc valve option and I just like pumped a vec full of stuff and then use. It as my key that's I got like a petition namespace the thing was like doing that seemed like kind of. Inefficient because it's like okay like I need a three like you know a three tuple as my. Key so I like go I create a vector host function I push into it post function I push into. It again host function I push into again host function and then I call the like you know get function host. Function again and it just seems like a ton of work to get a single piece of data. So do you have any thoughts about that off hand I guess I'm I'm I'm not sure that it is a ton of work. Like it would would be my first reaction in the sense that  I don't know. So so so for example you know we could we could make a contract put one contract put two. Contract put three that takes three values as inputs three three keys four keys five keys you. Know we could we could reflect those usage patterns in function signatures as conveniences but I'm not. Sure they would do any less work and I don't think the calls in and out of the vm are actually all that. Expensive I think you're only talking about one extra op code and a couple of like like a push and a call. So from a user perspective I think you have a good point and I think if the sdk can't make that pattern. Fairly convenient in terms of putting you know sort of a superficial porcelain on top of it that makes it. Makes it look nice then perhaps we should expand the functional repertoire to provide. Additional support for that I think one thing you might be able to do just responding to your comment about. The sdk is you know make it easy to use things like tuples like trying to make it easier to use things. Like vex already and maps you know tuples might just that just might be one thing we could we could. Have yeah that's that's kind of what I'm expecting is that you can you can do the. The kind of thing that that you know I hate to use this as precedent but but the the raw standard library does. Something similar here where it just says you know the people use tuffles up to about five. Or seven or twelve or whatever so like it just you know macrogenerate enough support for all the basic temple types. That anyone's like likely to use and and just have them as conveniences and then you only wonder how to use this. Arbitrary vector sort of approach if you're if you're doing something weird yeah I mean as as long as the cost of. Doing all the push functions isn't particularly high then it it doesn't really matter to me. Because you could always put sdk support to do this indeed I just built my own thing that like I could pass the. Functions to and inside the parameters too and it would through the vect back out at me so it would look a lot. Less disgusting we could generalize that of course as long as the cost isn't high at the. Protocol level so I think so I think the cost of a function call is is fairly small function call and I again. Absolutely it's the case that if if we measure this and it's miserable I mean the other thing is that I don't I don't. Honestly think there's masses of I o operations in the normal contract path right I think you're only. Talking about a couple of point accesses per contract call anyway so I'm I'm not super concerned about that. Path but if if if we measure it it turns out to be expensive we can absolutely revisit this and try to you know add. Fast pass or optimize versions for this braden d do you think they could be contracts that will be vulnerable to. Moving footprints so you mentioned about the situation where dynamic footprints is an inconvenience or you know you have. To do reconnaissance queries and they potentially could be out of date but I'm wondering if there's an angle here where. That actually makes the contract vulnerable in the sense that you know one participant of that contra contract. Could prevent another participant from interacting with it yes absolutely this is. As far as I can tell this is basically always the case with concurrency control if you have any kind of concurrency. Control mechanism somewhere you can create a starvation you can even you can survive. One party by by just hammering on a contended resource in this particular case the user has the. Contract developer has a fair amount of control over it because they can change the granularity so if a contract. Developer feels that this is a risk or sees this happening or something like that. They can re-architect the contract to essentially sacrifice concurrency . To get rid of the ability to have that kind of concern so so you know at the extreme end your footprint is. The contract data there's only one contract data everyone who talks to this contract. Always accesses the exact same contract data and that means that everyone knows exactly what their footprint should be. It's always just the contract data there's only one element everyone specifies the same thing and. They all get serialized and so there's no you can never you can never have to to have your footprint invalidate because. Your footprint is always correct so you can do that if you find that's happening. It's just the worst case right so you you move away from that if you want more more concurrency but if if you're seeing. That people are able to able to and and actively exploiting you know some kind of of starvation . Concurrency starvation situation then then you may have to move back towards that and. I don't I don't personally know a way to avoid that I think if we did any kind of. Dynamic locking we would be in exactly the same situation where someone could just flood the system with with . Transactions that take a lock and and deny anyone else the ability to make progress. And we would be in a worse situation because dynamic and currency the the thing that's really good about static and. Currency control as an approach is that you you have a guaranteed sort of throughput that the the. Things that you have scheduled will complete one way or the other within their allotted time slice right. They will they will either finish or they will abort and so your abort rates go up. But the system continues to run in in this particular strategy the other strategy would be. More like we would give people the ability to drag the entire system down so a transaction set would would. Potentially slow down dramatically because people are contending on a hot resource so. It's there's there's there aren't a lot of free lunches in concurrency control and and I kind of feel like that's a. Natural trait of you that answer the question I know it's not like a fun answer no yeah I think I think that makes a lot. Of sense the fact that the proposal really gives the contract developer a lot of control. and doesn't define the level of granularity that they have to use I like yeah it's good. well great it looks like you've created one of the least contentious caps that. Has ever came to life thanks for that great cool so let's let's dial up on the. Contentious or the contention levels john I think this is probably the third iteration of smart contract. Interactions so for those of you who are here at last week's meeting you might recall that we. Had a pretty big debate about this and I was in the interest of actually agreeing on something I decided to just. Remove all the functionality from the proposal which sounds a little backwards but . In the context of smart contracts you can kind of put all of these authorization questions. Down to contracts and let them do them do everything themselves and we had been kind of moving in that. Direction on cap 50 anyway with the introduction of like the invoker signature none. Option and stuff like that so basically at a high level of what's in this proposal. There is a just like in the old proposal there is a new operation sorry a new transaction type and a corresponding. Envelope type called invoke contract transaction or invo contract transaction envelope. And this and this contains the normal stuff like before source account sequence number fee. It contains the contract that you're invoking you know the id the parameter the symbol the parameters. It contains the read write set that you would need for cap 53 as grading was just talking about. and then that's pretty much it so how does one actually use this there are some examples in the cap which were. Pretty instructive about what what the universe would look like if we actually did this. there's a whole example section where I hacked up like two versions of an erc20 type. Contract but they look quite different from your normal erc20 because there's not really like a. Reliable message.sender that you can use in this context but basically the only other thing that's here. Is just a few a few host functions that are useful for actually doing some of the things that we discussed last. Week so there's some access to thresholds from accounts there's access to getting the signer weight by account key. By signer key the signer weight for an account by signer key kind of hard to say I added a verified 25 519 function. Which I think is also in cap 51 which is being written at the same time and that's that's pretty much it. So any questions about this so I'm I'm just just trying to get into this can you talk a bit about. Like the implications around like accounts and you know we were talking about about this a bit last week like. What does this mean for like you know classic multi-sig accounts on the on the smart side. the beauty of it is that the proposal means basically nothing for those things. because the contracts get to make their own decisions so for some context like if you scroll down. Almost all the way to the bottom the last example is like a sim a simple token based on account signatures. And this builds on the classic Stellar multisig mechanism basically works exactly the same. With two exceptions no pre-signed transactions here oh sorry no pre-auth transactions. And no hashtag signers but it works exactly the same and it works at medium threshold and everything. Kind of is exactly what you would expect but right above that there's another example that uses the like the single. Key version that I was proposing as the invoker signature last week and so this this framework basically. Lets contracts build whatever they want if you want some kind of you know support for seller multisig. That'll really be up to contract developers and ecosystem standards and stuff like that. My intuition is that those things won't really materialize because they're not efficient structures. On the blockchain but they might they might materialize from case to case something that immediately jumps out at. Me with these examples is that it may be difficult to write these functions some of these sorry I'm looking at. The simple token based on account signatures example you were just referencing and the second code block has a check. Function it says internal function is that something that the network is providing or that's an. Internal function that the contract provides that's a contract function that's not. Exported so I can imagine so i've had to write code like this for for our sdks when we were. Implementing sept10 and I was yeah I think it was septum and one thing that is quite difficult to get riders. Iterating over a set of signatures for a message and determining a set of weights. Because there's different things you have to do like you have to make sure that you don't. If somebody includes the same signature twice you don't use it twice to get you know. Double the weight different things like that so do you think by going this approach. Expecting people to implement their own authorization we're increasing the chance of foot guns. Where people are going to implement what they think is Stellar maori sig signature authentic authorization. Verification but it doesn't actually exactly line up with it that that's definitely possible. I mean my like kind of ideal universe here in the sense of like what I hope people. Would do is probably somebody would deploy one contract that has like a unified key structure a unified signer. Scheme basically you pass it some kind of opaque blob the beginning of the opaque blob is a discriminant saying. Like hey what kind of signature is this is it a single key ed-25519 is it a single key ecdsa. Is it a is it like a Stellar multi-sig is it some other scheme that I'm not thinking. Of like some kind of like quantum reset resistance scheme who cares and basically like the entire. Ecosystem relies on this contract or sorry another example would be like I know lee you had requested like aliases. we could have like a single ed 25 519 alias version all of that implemented in. One contract that everybody kind of relies on as an ecosystem standard you don't have to rely on it but if you do. You kind of get compatibility across the entire universe for free that's what I would hope would happen. Instead of everybody rolling their own but like yes at the very worst case everybody rolls their own and if you. Don't know how to roll your own for example like I didn't account for the for the repeated keys in this example. working too fast you can get yourself in trouble and just just to follow up on that. Part of why I'm a big proponent of single key signatures and doing everything else is like you know secure. Multiple-party communication computation is because there's a lot less ways to. Blow yourself up on chain a single signature is easy to verify in fact my argument would generally be. That if you want to write a good contract that is really safe and easy to audit you should use the simplest. Authorization scheme possible which is that all right can I ask a follow-up question. Is that I'm I'm a little bit well i'll be honest I'm a little bit behind on on this entire aspect of the. Interactions  if you're dealing with a case where people do use the simplest and safest. Approach but you know suppose you're a smart contract author who's trying to be conservative and you don't want to do. Anything too elaborate and you're using this interface am I correct in reading this that you are. Probably you're probably not going to have to include an awful lot of code in your. Contract to make this work right is that correct that the the sort of the number of calls that you have to make to. Host functions is not particularly huge you're talking about in the case of like a single 80 25 590 right that's right. Yeah in that case like it's very very simple that example is in the first one and like the code is basically like. Check the nonce hash your hasher you know message do a do a 80 25 5 19 post function call. That's pretty much it and everything just traps if the wrong thing happens and you could probably write this in like. Five lines three host function calls or four host function calls pretty pretty lightweight all told. And it's pretty hard to escape all of like some of these parts no matter what you do like at some point if. You're going to do the authorization on-chain you probably need to do at least one 80 25 5 19 signature. Verification or ecdsa signature verification so I it probably could be like a little. Lighter than this but probably not significantly lighter than this well I guess this. I'm I'm just being my typical trying to shave things down approach this feels to me like. Even the minimal version is a blob of code that will have to get stapled onto every single smart contract. And they will all run you know even even if they all wind up being conservative and they'll take your. Advice and be conservative this is all in vm rather than extra vm there's no there's no way for them to. Say fastpath may just do this conservative thing so yes and no because like even though I think that everybody will. Be conservative I still think the ideal universe of everybody being conservative is them all using a single. You know contract that implements this all so that you don't end up with the same code cloned everywhere you just. Have a cross-contract call you probably think that's worse than it is from a performance perspective. But it doesn't end up with like 10 000 or a million copies of the same code everywhere on the blockchain so it's the. Plus the the second part of it though is that if there is a lot of ecosystem adapt adoption around some kind of. Standardized signature verifier we could always deploy a native version of that that's. Super fast I see I see so so so you are I'm not I want to make sure I'm not promising you that that's ever going to. Happen no no no no I'm not I'm not hearing your promise I'm just trying to understand. What level of code reuse you're assuming is going to work and also so you know calling calling a third. Party to do your authentication for you definitely gets us into the question that is the other thing we're going to. Be discussing today which is mutability of contracts and like you know versioning your dependencies like i. Think if there's anything someone is going to not want to trust to a third party it's it's the authentication path. unless they're 100 sure that that third party is you know immutable and like the code that they. Audited the last time they read it I think another option is you know you can it could be a cross-contract. Call to this one contract that's living in one place so we're talking about reduced wasm size. it could also just be the library code that everybody's sharing so people understand. There is no mechanism for library sharing besides stapling this like including the code into the contract. Yeah yeah it's all right so obviously there's no space saving like all these contracts. Are going to have the same code within them but addressing the the concern of people. Implementing these things correctly if everyone's using this common piece of library code. that has either been audited or people generally have more trust in then then. Then they don't really you don't really have to worry so much about the mutability concern because they're. Choosing to build that into their contract at build time there are some trade-offs there like. I think it would generally be a thing that would would would occur that people would probably provide some of. These like very standardized off functions like single key or you know based off of seller accounts or stuff in. A library that you can use but if you want like a stateful system like lee you were talking about aliases. And that's why I keep coming back to this like the stateful system is only really useful if your state lives in a. Centralized place that that people can rely on you know like it would be really annoying for me to. Have to go and set my alias in every single contract that I use like I could but it just that just seems really. Irritating I think people would much prefer a system where if that's an option. There is some global contract for that state limits basically I guess well I guess people could you. Could have a really simple contract it's just like an aliasing contract and you could have library code that uses that i. Don't know there's a lot of options here when yeah like it is to me super interesting like is that. So like what how do we think about that like when you say like when you make so this is like the smart. Wallet type of like situation where the smart wallet is is kind of shielding or separating the . Whatever key you're using at that time from your persistent id on the network I wouldn't necessarily call it like a. Smart wallet it's kind of tangentially related I guess it would be what I'm really saying. Is like I sign using key x but my public key always stays as y and I can change x to x prime or x double. Prime or x triple prime but my public key always stays y yeah so for context I think the aliasing. Came about because we were talking about how do we replicate what exists on Stellar today in the smart world. And what we have today with mo like we often talk about Stellar multisig but actually the other component of stella's. Multisig that we get is aliasing because you can have an account identifier and then you can attach other. Keys to it and so Stellar accounts provide these two concepts aliasing and then multisig. And I think you know there's been the concern address presented that you know we shouldn't. Just implement the multi-sig that exists on classic over on smart because there's a lot of trade-offs with doing. That but the aliasing alone is is like a feature that I think that's worth worth us exploring like what will that. Look like because it allows people to do things like rotate their keys or have multiple. Devices or using the same key or using the same address and if I understand correctly john. You're saying that that aliasing capability could actually just be a contract yeah that's exactly what I'm saying. Any other questions on cap 52 I think because it's so fresh we probably need a bit more time to. Get into the weeds john could you elaborate a little bit on how you see replay prevention happening. So I see in the cap that there's this announce that that concept exists yeah could you elaborate a little bit. With how you see contracts would typically do that yeah I'm happy to do that so this whole replay prevention thing. Gets kind of annoying in this proposal that's one of like the big downsides of this approach that I pointed out in. Cat 50 when I said like why we shouldn't do this which is basically like every contract. Ends up implementing their own replay prevention when wherever it's needed and this means that like things get. Pretty annoying fast for example like on Stellar you like consider stuff center today. You might like submit a transaction and you know you have replay prevention on it because the sequence number and you. Also have like you know a a deadline effectively you know the max time and you know that if you get to that point. Everything is done it can't execute or it has already executed but like if you want that functionality. Here you also have to implement the deadlines in your contract and all these other things. and everything just gets kind of annoying fast basically now again same kind of thing that i. Was just talking about you could actually because like in this approach because everything is done by signed. Messages you can actually delegate all of this to to like some other contract that. Deals with it so you can imagine implementing Stellar's times you know time downs. And ledger bounds and all that other stuff in a contract and reusing it if you still want it or you can rebuild. In your own contract as well but basically there's no generic nonce here and the cap goes into a little bit of. Detail about like why you can't use the sequence number and they're they're like my original. Proposal here actually had an example where the sequence number was like the transaction sequence number. Was used as an us but it had a couple like kind of annoying details about it specifically. Like such a contract is like really vulnerable or such a design is really vulnerable to . What's it called confused deputy problems and if you try to fix the confused deputy problems then it becomes. Impossible to use the sequence number as a replay prevention tool so there's a lot of trade-offs here. Basically like I can imagine an argument where we just say like hey like people should be cognizant of their. Confused deputy problems etc and we make that an option again I don't know if I would personally feel good. About that because confused deputy problems are like a very difficult foot gun to deal. With I think like they're an easy thing to overlook so I don't know but basically yes every. Every contract is building their own replay prevention or relying on it from somewhere else on chain. Got it I think one nice side effect of not exposing the transaction source account on sequence number two the. Contract is that contracts are getting really set up for that common relay pattern that we do see in other. Ecosystems where people design their contracts so that the message that's getting. Signed to be used like the contract call that's getting signed to be used on chain. Is independent of the participant who's actually submitting it and paying the fee. And that that that participant could be like a third party that has you know is playing that role of. Relaying making sure that the transaction is on network so in some ways it's nice it sort of sets. Up contracts to to really work well with that because if a contract is written to use the source. Count you don't get like you would have to then modify the contract to make it work. With a relay yeah definitely you mentioned this to me like I don't know a week ago or. Something and that idea really kind of stuck in my head when I was writing this so I totally agree with you that that's. A huge advantage of this design I think something that i've i've heard I think maybe grading like raises a. Concern is if we encourage people to write their own replaying mechanisms which I don't. Think we can actually really get away from so maybe it's not worth having this conversation but. if we encourage people to write their own replay mechanisms people may write replay mechanisms that are really. Inefficient say is storing data on chain forever type of inefficient do you think there's anything that we. Can provide that'll like maybe some utilities that we can provide in the sdk or even in the hose functions that might. Help people write replay prevention mechanisms that are more efficient that you know use the. Ledger in a less aggressive way I haven't given that too much thought honestly but like. I mean my general kind of perspective on this is you know it costs money to use the. Blockchain and people will be incentivized to do things that cost less money so basically if there's a reason to do a. Really inefficient replay prevention mechanism because it makes the rest of your contract much simpler or maybe it's the. Only way to even do it then I think people will do that but in the absence of that need I think people. Will favor the super simple mechanism that's cheap whether I can guarantee that i. Don't know and whether we can provide some utilities I'm not really sure I mean like a really. Simple replay mechanism like a sequence number is basically like you have a map you look it up you check you increment. That's it it it could be hard to make it much simpler I mean like we could provide. Some like library functionality that literally does that exact thing but the thing is if you have an account. That already has per user data you would probably want to of like wrap the non-sin with the other per user data. And then the helper is not actually helpful in that case so that's kind of the main perspective. There but I have been thinking in general this is like a bit of an aside that it would be really helpful if the. Sdk provided some types like for example like there's the sc val map type which is like a map. In the sense of like a conventional map but i've also been thinking like sometimes it's like you want to look at. The data as in like I have a bunch of data stored in different ledger entries and be cool if there was a like a map. Type that did that very easily instead of having to use like the contract put contract gap etc in cap 53. So maybe there's some interplay between that and a replay prevention mechanism that we could learn from. Yeah I mean I think that yeah all those things are going to like as we develop like even basic. Applications will factor you know like this type of basic functionality in some traits right that that people would just. Use I'm not actually too concerned about yeah people having to write it because we are going to write it. I think for more like maybe like different type of like replay prevention. Like I think that's kind of the nice thing about this proposal is that I know in. The past we discussed like you know potentially doing very different things like where you. Have like those like ephemeral type of you know like things that only work in a specific. Time period right so that you you could in theory like replay in a specific . Window but in some design it's actually acceptable and then you end up with like much. Simpler client-side code so yeah and can I ask it don't question but you have a. Function in here called knots of how does that work what does that do it's just a contract internal. Function I don't know if the com comments emphasize that they don't it's not a host function. Basically it just it just reads the data I just read the larger entry and find the nonce in that. Would probably just be a single you know integer sort in a lever entry non-sub in those cases is user. Maintained data associated with an address yeah exactly contract maintain did I want to say but yeah. Okay in in general I mean I I'm a broken record I don't want to waste too much time with this but I'm i. Am I am extremely nervous about suggesting that users roll their own authentication mechanisms I think this. Is just this is just asking for disaster but I understand that we've been around this. Like a lot so you don't need to convince me I mean providing the really really simple. Authorization that mechanism is the only one I would strongly favor that approach. this just this just feels like it's going to be a disaster you're going to have people who completely fail to. Because this this data this code path if you get it wrong is came over for everything and it's so easy to get it. Almost right and your tests pass and you deploy it and you think everything's fine and then. It's not so I'm I would love to not have users writing this code but okay so you know obviously I think we need to. Dispense the value in this proposal in the meantime we have 10 minutes remaining and i'd love to hand it over. To siddharth to talk a bit about the changes to the smart contract life cycle and potentially any. remit open questions that we need to answer yeah so the most recent change was a. A small one about how the contract id which is which is now a hash is calculated and you can we can look at that. Change it's pretty simple where the it's created from a transaction you hash source account a user provided. Salt and if it's a contract created within another contract you hash the parent contract id. And assault provided by the contract I mean if there are any questions there we can talk about it but I think the. More interesting thing are these two other points I want to bring up one is mutability. which is do we plan on adding like initially the cap right now does not have mutable contracts but the. Question is should we leave that question open for the future or should we just say. Contracts will always be immutable and the second thing is we allow contracts to be removed so the. Cap has a host function to remove the contract code entry so I think we can start with. The immutability question right if so if we do allow mutable contracts in the future a big question. Was how do we deal with versioning and I was taking the approach that let the contracts deal with it so for. Contract a calls contract b and contract b is mutable contract may just trust that. Just trust contracts bees creator or right so I think grading had some issues with this. graham you want you want to talk about this well I think they're just I keep coming back to the. General sense I have that cross-contract calls are something like dynamic linking or or. Package dependencies in software in general right that smart contractor software and this is this is a general. Software versioning problem and in general software has like natural tensions around. Versioning that people frequently want to lock to particular versions but they also frequently want to get the newest. Latest and there's a concept of newest latest that is compatible and a concept of newest. Latest that is not compatible that is often expressed in major version numbers or or separate. Apis or separate names for things and I'm concerned that we are not reproducing any of the infrastructure. That would be normal to support points on that natural tension so I think I think it is. Worth trying to provide some of the building blocks that people are going to provide themselves anyway because. It's it's bad enough to have like versioning it's worse if there are multiple versions of the versioning system and. You have to like opt into different versioning regimes depending on which ecosystem you're. Adhering your contract to like I understand there's just there's this natural tendency in our conversations. Here to try to push everything to the ecosystem and let the ecosystem figure stuff out let them let them develop. Patterns in the smart contract space that just solved the problem however contract. Users would like them to but that that is not actually as much of a solution as I think it sounds that. That really strongly introduces the possibility of totally incompatible regimes developing in parallel or. Inadequate regimes that miss some important aspect of the design because they were. Cobbled together in a hurry so I wouldn't mind us spending enough time to be able to provide the basics which is. Like I want to pin to a version I want to pin to a major version and only get security. Updates or I want to follow you know any new features and additions that people had including modifications. Upgrades whatever I feel like there's there's got to be a future where those are those are. Things that someone's going to provide and it's it's our position to potentially furnish. Them maybe it's not but that's what it feels like to me but like at our layer like is it. Is it just having a way for to have like committable versus mutable contracts and like the the versioning is. Metadata basically and it's up to when you write a contract you know to decide how you want to use this metadata. Okay like when you make a cross-contract call at the moment a cross-contract call. Only identifies a contract id right right and it does not it does not say call this. But give me version five or give me version seven or whatever like there's there's no version information in. Cross-country calling right now which means we're essentially always dynamically linking to either. Immutable exactly the same thing or immutable whatever the person up to updated that. Contract with the thing is that I mean you have a bunch of of things that feel like if we if we do. That at the kind of protocol layer we're kind of printing those like for example like if. You're you're talking about different versions right of a specific contract like you have what is . Like there are a bunch of questions around like you know you have a 1.0 but maybe the 1.1. Is actually deployed by some somebody else right like it's not even the same author. Like how do you deal with those type of situations like who do you trust to be 1.1. I don't think we have the notion of oh like a of actual like or like you know the organization or. Whatever that is the the publisher right over have a contract yeah I agree we don't we don't have any. Notion about that I'm I'm I'm advocating for us to come up with a notion rather than. saying but that notion like I think it becomes I think in that space I don't think you can. Necessarily come up with a one size fits all because it's not like in you know in. In like normal I mean they say like normal software like you have a company and they ship their their their thing. And and that's kind of it like here and also like if you depend on on a specific version right as a as a. My installer basically is going to just grab cause the os right to grab that version. That I depend on only in a blockchain type of situation if that other version like the cost of. Of of keeping that other version around is actually on the on whoever deployed that contract. So if you say like oh I want to pin all version like everything is always pinned I think that that the implication there. Would be well okay the publisher is now has to keep around all versions of of their contract. Which is kind of you know weird okay so is is is could you make a a concrete proposal. Here are you talking about you would like all contracts to be mutable immutable not immutable but mutable so. You can mutate them and if I ever want to have a pinned version I vendor it is that what you're. Saying not necessarily so I think it's like yeah you could have always vendor of. Course I mean that's a solution and I'm I'm okay with that I just I think we have to. Think through the scenario is what I'm saying and I think if if what we're saying is we're not going to give any. Thought to the scenarios whatsoever and then we're going to tell everyone to proxy every single call they make. Because that's the only that's the only place they're going to have any ability to. Enforce policy I think we're kind of losing a good chance to to shape the system I think it's more like what are like the. Things that are like support like a that you get with tooling that you know we can provide. Versus things that are actually baked at the protocol layer like I think that if you have a way to. Say because you know you'll also also have the other problem right of contract discovery on the network like. You know which net which contract do I trust you know versus the ones that I partially trust versus the one I don't. Trust right there are some that were basically you trust you try that contract that. Even if it was mutable you trust that they are not going to or you're actually fine with with. Them modifying it in other situations you do want to pin because you have like a you know an actual. I mean maybe it's a stability thing or whatever right there you have like other. Problems there so so some of these data yeah like the mutability aspect I think that's actually yeah. That's a property of the of the contract so that you know basically can I even directly depend on this from my contract. Or is it potentially going to change under me but then you have a different problem I think that. Is kind of like when you do you know like with you know when you have your manifest files when you're when you. Decide that you're going to pin your dependencies right in your own program that decision. Is something where I think we have to just develop the the right tooling but it's not something that actually the. The you know the network doesn't shouldn't have I think an opinion on on you know like the this. Even the schema of of how you pin things like I said I guess I'm saying that the. Network has to provide whatever is necessary to support it so we we come up with what we want we come up with what. The network needs to support it and I'm I'm not seeing that developing in our conversations we we we talk about. Like bad things can happen and then we throw up our hands and say obviously we can't. Solve it like no no we have I think we don't fight this one I agree we just try to figure out what the pattern is and. Then figure out what the network needs to actually support it right I think it's we need to have to kind of to solve. Those problems what I'm saying is that we don't need to  because like the things that i've heard. So far they are in the context of a cap and in the context of the cap we are saying this is going to be like. We kind of forced a specific model at the protocol layer oh and I see a raised hand who is that. I think I think it needs to be in a cup like it needs to be in the design rationale. For this cup like if we're saying that we're going to provide this limited set of functionality and you can go and do. Whatever you want we still need to provide in the design rationale this is how we expect it will be used this is. How we expect it will solve this problem of versioning I mean I think like at least I can. Already see like there are some gaps here you know if we say that you're going to do. All contracts are immutable so with an eye and you're going to do versioning yourself data migration how's data. Migration going to work because like right now we have cap 53 and contracts can't access other. Contracts data so how is contract you know v1 going its data going to be migrated over to v2. And then if we say that you know v1 and v2 are gonna coexist at the same time you know how do contracts do that. That seems rather complex yeah and especially yeah and actually like yeah in the context of cap 53 I agree that it's also. You would change your like if your id on the network is your contract like your you know the contract is your id type of. Thing you don't want to be changing your id like if you upgrade that contract we got a request to speak from the. Audience I know you don't know how to take them I'm not I don't think after right. It's android question hello can you yep we can hear you great thanks appreciate the conversation and glad. I was able to hop in I'm going to keep it short because it's going to be slightly off silo of what you're. Discussing I am a week away from dropping a tokenized community with a coin that I'm. Bringing over from raleigh into solana and I want to develop on Stellar and i've looked up online there's some. People that you know help you punch I you know I'm just trying to understand based on what I know. With moving forward I mean who can I connect with so that I can understand the liquidity and how the. Stellar network works and how I can make sure that that same liquidity I'm probably going to lose it. But how I can transfer over to the Stellar network and really make sure that I look at all aspects of where I'm. Launching so they don't have to wrap and do it differently in a month do you know. What I'm saying yeah cassandra I appreciate the question this specific conversation is about. A very like specific topic technical topic and you can go to the to one of the other channels support. For example ask that question and i'll be happy to help you there okay thank you I'm. Just looking for a personal contact I'm not bringing in the conversation I just I can't find anyone and i've left a. Couple messages in the chat but I'm not sure who to talk to so who is just speaking and then i'll tag you. Okay so we're we're over time and I think there's some really interesting discussions here that we probably need. To continue either on the jump cannon dev channel here on discord or on the mailing list. So I think we should go with that thank you all for joining and tuning in and have a great rest of your day. You.
