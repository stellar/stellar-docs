WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:59.999 align:start position:0%
Protocol 23 we are introducing the hot archive bucket list where we will actually actually store archived entries in a separate database and what this allows us to do is to store all live sorb on state in memory as well as store andan module caches in memory and we can do this safely. Because the rent system is St archival. So what we were talking about today is an update, that we made since the last time we talked particularly about the way, that we calculate the what today is called the target bucket list size. And. So in Protocol 22 whenever you pay rent or write an entry to The Ledger this fee is variable based on the current size of the bucket list, which is just the size of the you know network's database on disk and essentially we have a Target size and. If this Target size is exceeded. Then the cost of right and R bums increase
00:01:00.000 --> 00:01:59.999 align:start position:0%
Very rapidly and essentially this allows us to have a soft CAP on the current size of the bucket list or the the network database from a fee perspective. So you can technically still write but'll just be very expensive to do. So. So people will stop writing. And. Then eviction and styal will do a back pressure to overtime reduce the size of the bucket list. Now the thing is previous previous to Protocol 23 this was all measured in database size. Now there were two issues with this the first one being, that this is a sorond based fee and most of the sorond state or most of the core database wasn't soron state classic State significantly dominated the size. And. So we had this weird system where even, though Soroban took up very little space in the bucket list it was being charged fees whenever classic entries
00:02:00.000 --> 00:02:59.999 align:start position:0%
Would make changes. So, that's kind of issue number one, that you have classic influencing the cost of Soroban State. Now the second issue is, that with Protocol 23 we. Now have a bunch of storage or all the Soroban state, that we actually store in memory instead of on disk. And. So it would our kind of goal with this setting is to make sure, that the protocol can CAP the maximum amount of memory, that Val to use it at a given time and. If we were to continue to use just the disk based metric this is no longer able to actually CAP the amount of memory, that you need to store. Now, that we cach everything in memory. And. So the update to CAP 66 is, that we change the bucketless target size byes to soron LIF State Target size byes. And. So what this means is, that instead of using the entire size of the database to calculate rent fees and write fees we only use the
00:03:00.000 --> 00:03:59.999 align:start position:0%
Size of the live Soroban state, that we actually have to store in memory. Now there's a couple of details here particularly I want to talk about contract code. And so. When storing. So the plan is to store all contract data and all TTL entries in memory. And. Then to store instantiated contract code in memory. Now contract data and contract TTL the thing, that we store is the same size as the entry on disk. So for instance like. If you have a contract data on diss, that's The Ledger entry is you know 64 bytes. Then we store 64 bytes in memory. So there's a one to one ratio for data and TTL for contract code this is not the case. Because of the module instantiation cach changes or the instantiated module cache we are not actually storing just the contract code bytes in memory. But we're storing an instantiated model and this model can be up to 40 times the size of the on disk
00:04:00.000 --> 00:04:59.999 align:start position:0%
Wasm bites in the worst case. And. So what we're doing instead is, that for contract code in particular instead of using the size of the contract code entry for fees, which is what we' been doing up to this point you're going to instead use the size of the memory given by the instantiated contract code module. And. So in the worst case this is a 40 times increase. But in the average case this is only a 10 to 15 15 times increase over the size of the contract code as it's calculated today. And so, that's change number one is, that essentially. Because we need to account for the in memory size of state. Now instead of the on disk size we need to make this adjustment in the contract code size calculation. Now the other adjustment we're making is with r fees. So for rent fees essentially you are renting under you know Protocol 23 you are renting space in the in
00:05:00.000 --> 00:05:59.999 align:start position:0%
Memory cach of the network, that's essentially what rent is doing. Now. And. So we the rent fee will remain unchange how we still have like this target live State size. And. Then the rent fee will you know increase very rapidly. If the of Life State increases this for right fees doesn't really make sense to have the right fee a function of the current amount of Life State. Because we're to using memory based bounds instead of dis based bounds in the Life State we a dynamic wrry doesn't make sense. And. So what we're proposing is, that we still need to have a right fee. But you are not it doesn't need to be based on the current size of the bucket list rather it just needs to be based on the computational cost of doing a right. While you're applying the transaction. And. So we're making a
00:06:00.000 --> 00:06:59.999 align:start position:0%
Change, that right fees are. Now a flat fee per BTE or per kilobyte rather. And. So instead of having like this curve the rent fees will still have, that curve. But the right fees there'll be a network config setting, which is fee per 1 kilobyte R. And. Then this will be applied based on the size of the entry you're writing and this will be applied to both Soroban entries you write as well as classic entries you write. So, that's, that's the primary changes essentially we are changing the way we calculate contract wasm size respect to fees rent fee is still variable based on the amount of Life state right fees are. Now flapped any questions or or concerns
00:07:00.000 --> 00:07:59.999 align:start position:0%
Morgan's question about the the cheap storage we don't it's not. So much, that the storage is cheap. And. Then non-e it's, that before you hit the target the storage is reasonable reasonably priced. And. Then past the target the storage is like very very ridiculously priced. So the idea is, that you know we still even before you hit the target we still charge fees and the intention of this fees is to dissuade people who aren't using like who aren't legitimate apps using the space. But essentially the reason, that we have this target is, that we don't want a Dos angle where an attacker could just write you know gigabytes and gigabytes of state, that we all out store memory. And. Then oom kill them nodes. And. So I don't think the distinction is cheap versus non- cheap it's you know reasonable versus like ridiculous pricing, that we only you
00:08:00.000 --> 00:08:59.999 align:start position:0%
Know resort to in kind of the to protect ourselves from malicious attack see any numbers for the threshold I think exact numbers are TBD for reference we're are. So currently the we use bucket list total size. And. So I think it's like 12 and a half gigs or something like, that the target something in, that range. But. Because we're switching to only meter the life Soroban State it'll probably be something on the scale of hundreds of megabytes just. Because today the total sore on
00:09:00.000 --> 00:09:59.999 align:start position:0%
State size is like 40 or 50 megabytes. So, that still gives us you know lots of growing room. But is a very small you know value requirement as far as memory. But again you know we we still need to think about these numbers a bit more as it's kind of you know on the range of what we're looking at yeah to add to, that since vasm kind of takes more space. Now than it used to take in the database yes we need to re-evaluate this in memory State size including the module cache and I don't think they have done this yet. So. But the it is I don't think it will be significantly bigger than tens or hundreds of megabytes and threshold to be set I think quite High compared to, that probably it can easily be a few times higher, that you
00:10:00.000 --> 00:10:59.999 align:start position:0%
Know we didn't get, that much dat in a year I don't think like. If you said it to 2x 3x of the current state I don't think we'll run out of space anytime anytime soon yeah and to just to make it clear for for Morgan's question like we like the purpose of these limits is not to you know limit good users. So you know. If we see a dApp, that has 100K daily active users I mean, that's not going to happen overnight there's going to be a ramp up. But we would definitely probably you know introduce the slip SL SLP to raise those limit. So the intention is not to you know reduce actual good good usage of network
00:11:00.000 --> 00:11:59.999 align:start position:0%
Yeah and I guess Nico pointed out a good point, that I forgot to mention is, that. Because we are switching from on disk metering of contract code to in memory metering the size of the current instantiation model is protocol dependent. And. So for instance. If in the future we change to a like a g instead of interpreter. Then the size of the instantiated model will increase. And. So I didn't mention this. But well for fees we are for the rent fee in particular we are using the inmemory size of the contract code. But for limits and for the right fee we using the on disk size and we have to do this. Because for instance like we have like a a maximum contract size config setting and. If you can assume, that you know a contract today has the maximum size we wouldn't want want to break, that contract in a future
00:12:00.000 --> 00:12:59.999 align:start position:0%
Protocol upgrade. If the inmemory size just happen to change. And. So yeah I think, that's, that's a good point I forgot to to mention is, that only the rent fee is dependent on the contract in memory size and, that means, that like a and, that's and the target sorond life State size is also calculated using the inmemory size of contract code. But as far as write fees and transaction WR limits and contract code size limits those are still determined by the wasum and we have to do, that. Because only the actual on disk you know wasm size is consistent protocol to protocol actually. So my comment was actually a little bit different like. Because I had a chat with grer about this and it sounds like the current P request we have
00:13:00.000 --> 00:13:59.999 align:start position:0%
For CAP 65 is actually caching per host basically. So like. If you have like two host like core can be configured right with multiple host to support multiple protocol versions and right. Now we keep in memory the version of the WM basically like the the pre-processed version per host. So it it gets basically like. If you have like two H in memory is going to have two versions of the wesm cache per contract and, that's kind of a to make it easier to to to reason about. But at the same time, that means, that the overhead in memory is actually dependent on how core is is compiled yeah I think this is I agree there something to look out for. But I think this is primarily an implementation detail at this point. Because I think in the yeah no it's totally is it's just like
00:14:00.000 --> 00:14:59.999 align:start position:0%
That's why I said there needs to be an SLP to to kind of discuss, that. Because the your memory limit basically, that you you pick is has to take into account the fact, that you have basically a overhead of two or 3x for you know for the resident wiom, that maybe is not as trivial as you know. If you look at calibration. While like. If you're asking one host how much memory you know are you using right. Now, that's actually not the truth you you need to to basically lie through the network settings, that you know you actually are are going to count was them in memory let's say with a 3X you know a multiplier on top of what's actually using per per host does, that make sense it's basically the yeah the calibration settings yeah yeah I think
00:15:00.000 --> 00:15:59.999 align:start position:0%
Longterm like a like. So longterm. When we actually have like large amounts of States say like in the gigabytes. Then I think we can probably avoid this issue by doing something clever like you know like. If we are armed for an upgrade. Then we can like you know like do the compiling for the new protocol version in the background laely. And. Then serialize it such, that we don't have like the double memory overhead. But. But I agree as like as far as like short-term and medium-term plan goes I mean I think like the state size is still small enough, that like we can set limits like with these assumptions it' be be fine. But yeah I agree, that we should have these these this like 3x factor in mind cool I guess. If we don't have any other questions or comments about this we can I'll hand it off to the next
00:16:00.000 --> 00:16:59.999 align:start position:0%
CAP right thanks Garen for presenting this and yes the next thing we have on our agenda today is CAP 6 to7 and specifically the issues, that concern handling of transaction memers and maxed accounts in the event not sure. If CAP is even an appropriate link to share right. Now. Because most of the revant stuff is captured in the the discussions to the CAP and I think the the point of contention during the previous meeting was how exactly can we
00:17:00.000 --> 00:17:59.999 align:start position:0%
Enable maxed accounts in soran and after spiking a few options considering the fact, that it is likely for pretty much any custom token to be interested in being listed in centralized exchanges and as being compatible with custo Vols, that centralized exchange may use for multiplexing multiplexing it seems like this is something, that most of the tokens will want and I think this is one of the key requirements, that kind of made the whole discussion pretty hard to converge on. But since kind of came to an agreement, that this is probably a reasonable feature to have and contracts will need to deal with Max addresses addresses anyways the current preference is to
00:18:00.000 --> 00:18:59.999 align:start position:0%
Go with an option of add in simulus support of Max addresses to the SDK and what tokens extend well not extend. But update the transfer function interface to be able to accept Mark addresses I don't know you do want to add something we di into details you asked to speak yeah I think maybe it's just worth calling out for people who listening of the conversation last week I think an assumption we were making to be really clear it was an assumption, that this needed to be an extension and I think you know to has sort of pointed out, that it's safe to assume, that pretty much every token would be interested in being listed in an exchange you know. If if, that was. to happen. And. So there's
00:19:00.000 --> 00:19:59.999 align:start position:0%
Little reason to make this an extension where it's sort of targeting a very small number of tokens like really just sort of all tokens should should be able to handle the case where they're given a Max address or a memo. And. So much of the complexity I think in some of the spikes sort of disappears once we don't try to make this an extension right. So to summarize like what we are currently going to do with a protocol is, that we will add a new object type to soran specifically for handling maxed addresses max accounts currently But I'm actually not sure. If you want to do contracts or not. But we could we wanted to and the interesting thing about it is, that since it's in the
00:20:00.000 --> 00:20:59.999 align:start position:0%
Protocol well the primary reason for why we are doing this work is for the tokens to be able to support this basically any protocol will be able to use them. If they want to. So. If custodial Solutions are necessary some other protocols basically the solutions for single address, that can have multiple sub virtual sub accounts they will be able to implement this and I think this is one of the benefits of this it hasn't been discussed before even, though like we don't have limited obvious use case. But know folks may come up with something I definitely recall having recall seen some discussions here on Discord regarding virtual accounts for multiplexing support
00:21:00.000 --> 00:21:59.999 align:start position:0%
so yeah we we had this new new object type and also at the SDK level we make it. So the regular address type and this new Multiplex address type are wrapped in the same SDK type, which means, that for example. If contract just operates on the addresses and it doesn't know exit your token started except in multiplexed addresses for the transfer as will break. So for example. If contract a calls a token contract and passes a regular address non Max address to it things will keep working even the token contract updates to this new proposed feature, which is to allow transfers to have multiplexed destinations and sources and this is what what has
00:22:00.000 --> 00:22:59.999 align:start position:0%
Been spiked and this seems to kind of work and in terms of complexity on the token side it doesn't seem like there is too much it's few additional lines of code to convert from multiple addresses back to normal addresses, that can do all the interesting things, that addresses can do, that's kind of a hell level thing I am not sure. If they need to go too deep into details right. Now I guess the conclusion from the discussions for is really, that seems like we have a way of making this work in a non disruption non-disruptive fashion meaning, that the existing contracts will not be broken and it is also possible for the clients to discover. If a contract reports multiplexed addresses at all or
00:23:00.000 --> 00:23:59.999 align:start position:0%
Not, which may be relevant in some context right. So I think this part is more or less clear part is still unclear and I wanted to talk about a bit more is how exactly are we going to represent the multiplex destinations and the events and the option of just putting them into topic is problematic. Because it would break index. If they don't do anything special this Multiplex addresses break in a sense, that they will have too many virtual destinations, that they really shouldn't be caring about. So in the link I posted yeah thanks Le for posting other discussions yeah in the discussion the da post ly has listed different
00:24:00.000 --> 00:24:59.999 align:start position:0%
Approaches approaches to actually how to handle the events with mlex destinations and I think we haven't reached the full agreement on this. But again it seems like from my own preference and I see Alex has commented on this this seems like what we could do is you could just converge yeah I say want to talk. But I guess the current preference is to converge all the possible memo, that we currently have support in the transaction converge everything into the single Multiplex address data structure. So, that for the classic transactions you will be able to generate Multiplex destination based on the transaction memo even of this transaction mem is non ID and for s b
00:25:00.000 --> 00:25:59.999 align:start position:0%
Use cases you only support ID MERS to kind of ruce the potential amount of confusion I know Alex. If you want to okay Alex doesn't want to talk I don't know. If you want to yeah no I just you know my comment was basically my preference just as one point of view on like, which one we should use I guess I do have a question. Now thinking about it like would this cause any breakage to how people parse M addresses. If we were to expand M addresses to actually cover all types of memos well it depends on where exactly we put it in the sketch I've posted above the above in the same discussion I'm actually only extending SC address
00:26:00.000 --> 00:26:59.999 align:start position:0%
Address type, which means, that classic Max account data structure will stay as is and the reason to keep it as is is, that it's kind of over the place in the protocol like a lot of transactions have maxed accounts as sources or destinations and yes there is really no good reason to kind of retroactively Plum all this memos into the classic Max account type and yeah this m will just remain in address and it will be just yet another special SC address as the remainder of with CAP 67 we introduced like chable balance address and liquidity po C address and both can only appear in the context of this unified events sources of or destinations of payments and this is basically the Third special address kind
00:27:00.000 --> 00:27:59.999 align:start position:0%
That only appears in unified events coming from classic I cannot say this will definitely not cause any breakage. Because well we are kind of in order to achieve this we need to not well kind of break right the token events by converting the data field from a single integer to a map there is definitely this breakage and you know. If someone there something to address they may or may not be broken. So PR definitely some cost to it. But it's not really specific to this proposal of adding this this maxed address with memo whatever new type. Because we kind of already have have this issue. So yeah I hope the breaker scope is really minimal especially. If like we support this iny libraries and whoever
00:28:00.000 --> 00:28:59.999 align:start position:0%
Is using string key library to just convert to and from a c address they will just need to update the version and hopefully everything just works yeah George you turn stage yeah yeah I just wanted to add, that yeah I 100% agree, that we should minimize or we should try not to make any changes to the actual mxed account XDR address or like the M string key format. Because there's deep assumptions in a lot of places Downstream both in platform products and Beyond in the ecosystem about the M string key specifically having the integer as the ID. So yeah. If we can isolate, that to SC address, that sounds great right, that is option four right or
00:29:00.000 --> 00:29:59.999 align:start position:0%
Option yeah four right yeah or it's it's more like it's not option three I think option three is the only one, that modifies the string key yeah I think option two is the closest yeah like using M wherever possible. But not trying to shoehorn text and hash into an M address as long as we're talking about the stry representation not some other representation yes yeah I think, that's right yeah I understand, that concern I personally. When I look at these four options and I think there's more than these four options. So I think you know. If people have other ideas like please post them to this thread these are just the first four, that came to Wine the attractive thing about the first option and the third option is, that it's very consistent with what you see going into a transaction for I think for
00:30:00.000 --> 00:30:59.999 align:start position:0%
exchanges at least or for legacy users. So. If somebody puts in a memo, that's a string it comes out as being labeled this is the here's the string in in exact like it looks exactly the same. So. If somebody's using developer tooling they see they decode a transaction they see this transaction had a particular memo they decode the event they can see the memo right there like they look exactly the same. And. Then the same thing. If you know. If the mammo is an integer it looks exactly the same and. Because we need to decode the M into a G for the topics I don't think it's such a stretch for option one to to like break it apart and for even in the MX case the integer to come out at least there's some consistency there the concern I have with the two case is, that. Because it's sort of a little bit less consistent you can create a transaction with a Max
00:31:00.000 --> 00:31:59.999 align:start position:0%
Address and you get an m on the other side, which makes a lot of sense. But. Then you create a transaction with a g in a memo and some memos result in an m and some memos don't result in an m. So yeah this might just be maybe this is an edge case we shouldn't worry too much about. But just, that inconsistency seems surprising to me I think it will be surprising to somebody just to clarify real quick isn't it normally the case, that. When people use the ID for differentiation on like Omni bus or custodial accounts, that they would use the ID form like text and hash don't seem like they would apply necessarily there. So it might be like an edge case, that you know they're attaching it as a piece of text, that is supposed to like display something. So putting, that into a
00:32:00.000 --> 00:32:59.999 align:start position:0%
Memo would be it's not intended to differentiate yeah we should I mean we should use the big query data set just to validate just to make sure we got these numbers exactly right. But. When I've looked at this in the past I have seen plenty of text usage actually. But a lot of the text usages exchanges placing numbers into text form. And. Then using the text the memo text I see. So kind of a misuse of the text form yeah I think Jake has just commented on, that I think just our comments about what most exchanges are doing we just need to validate, that. Because I know like one exchange, that actually does use MOX counts well they support both moxed and non-med for the non-med they use text. And. Then for the moxed they're obviously using the ID, which is interesting
00:33:00.000 --> 00:33:59.999 align:start position:0%
I think one of the advantages of option three, which modifies the M string key format. So, that it can contain more information information is, that it sort of pushes everything towards, that MOX address format I don't know. If that would really change adoption of it probably probably not. But it does create like a single unified View and the data, that comes out the other end I'd be interested in Simon. If he's here on like you know what the perspective is from like a data consumer perspective like a future data consumer perspective assuming, that the network will always have more users tomorrow than it does today yeah like, which of these approaches makes the most sense
00:34:00.000 --> 00:34:59.999 align:start position:0%
For future users and future consumers hello I would actually say for I guess from like a big data or like olab perspective I don't think any of these would cause a problem for scalability yeah I'm not sure. If that's helpful or not. But I think the amount of users, that unless it gets into I guess like the billions of something range, which I guess is the like possible won't be an issue for like the next decade or. So I don't think this would be a problem from like an olap perspective
00:35:00.000 --> 00:35:59.999 align:start position:0%
What about from the perspective of your a data engineer trying to represent this data. And. So you're looking at a lot of the data has just a single value for this destination. And. Then in some cases oh this value is actually a combination of multiple fields or or something like, that does, that make it more or less difficult. When integrating into other systems or would, that be like a concern or something, that could be like a foot gun like something, that'd be easy to make a mistake with I think for our use case I don't really have a concern with, that I think the concern would be more for whoever is ingesting from like RPC or creating like some Horizon like end point. So I don't know. If I'm the best to speak on, that
00:36:00.000 --> 00:36:59.999 align:start position:0%
Yeah from from Horizon. So from Horizon's perspective. Because we already support M addresses in their current form it would be like the format itself would break right. Because you would need a way to distinguish what kind of memo it is. Now. And. So anybody who's relying on the current string key format would know longer be open be able to use the same string key format right any existing you know queries or lookups or parsing routines anyone who's trying to find stuff in Hubble right they would have to reformulate their M address as far as I understand it I mean it depends on how it gets formatted in the XDR I guess or how the shinky definition defines it. But yeah it seems like this would cause a lot of pain for Downstream. If we extended it to be more than just strictly integer
00:37:00.000 --> 00:37:59.999 align:start position:0%
IDs I think it can. When I had to look at I did a quick Spike having a look at what would need a change about the M string key and it's 100% extendable without breaking existing string keys. So without confusion. So like existing string Keys would continue to decode to the exact same value and for any existing decoder, that follows the back any new string key wouldn't overlap with any existing string key. So, that every new string key, that didn't follow a different format would definitely fail like say like. When I say new I mean like the text the return and the hash typ of MOT types. So I think we definitely could do, that. But without breaking existing systems. But you know whether, that's the right way still to do, that is another question you know based
00:38:00.000 --> 00:38:59.999 align:start position:0%
On on there will be systems, that probably won't upgrade to the new format and they might assume, that there's nothing to change. And. Then they become broken yeah I don't know I'm interested to hear like Nico you were just talking about exchangers will crack open the M address for case three. So, that's strictly worse as a use case could you unpack, that a little bit yeah I mean it's basically like you know in in the in their inje system what they are looking at is deposits to their hot wallet. And. Then they. And. Then the memo, that's how they you know ingest the data like I don't see like why they would want to basically track like M addresses as the kind of the the deposit key for for you know separate from the hot wet wet basically yeah, that's a good point also for for exchanges, that use Define
00:39:00.000 --> 00:39:59.999 align:start position:0%
Those identifiers like per customer too like you're you are really interested in, that identifier whether it be an ID or a string I think what I hear you saying is exchangers actually don't really care about the M address after, that import other than using it as an input. So, that users can just enter, that one value. When they're ingesting syst doesn't really am I guess you can still argue, that as a someone who's we're basically deciding what is going to be P published as an event. But you can always go back and forth between the M or the address plus memo right and you can abtract, that away in the SDK or even like as an indexer was actually ingesting this data and converting and serving at. However you want right. So does it really matter I think the point about breakage, though is very important right CU I feel like you first
00:40:00.000 --> 00:40:59.999 align:start position:0%
Said it wouldn't cause any breakage. But for anyone who is parsing currently M current M addresses and they don't upgrade their implementation to the new thing. If they see an address, that is using the extended version they would probably break right yeah in, that case they're not going to be able to decode it. Because it's it'll be a different format yeah I think it's really some confusion. Because I think we might be reading this proposals differently I do not think any proposal assumes didn't shink keiss anywhere in the events yeah, that's actually exactly what I was about to ask like what. When we say from M and to M right in the transfer topic from G and 2G is an address yes basically basically in my mind from G2 g means, that from SC address account ed25 whatever to C address account and
00:41:00.000 --> 00:41:59.999 align:start position:0%
From M to m means address maxed account, which I have introduced in my Spike rate and address Max account variant has the max account XD payload U, which is existing Max account, which it doesn't even have to to be frankly it could be just you know Ed plus ID there is no additional level of neration and the same goes for this new memo account from z x j point it can be just a variant of a c address, that contains G well ed25 key and memo, which is just the transaction memo tapee for example. So this key discussion is rather like how how do we
00:42:00.000 --> 00:42:59.999 align:start position:0%
Like like. If we want to convert to string key or not. But you know the event structure does not change I think well I think there is an impact here. So yes string keys are not part of the protocol and they're not part of the XDR. But they are part of the developer experience and how we structure this will impact it to a degree. So you know we you I agree, that you know we can bundle these two pieces of information the address the actual address and the the memo separately or together in different structures the same structures. But we do need to make a decision in the event. If it's a top like. If it's. If if this event the data section is going to become a map is one of these fields going to be something, that we expect to be a single unit or we going to expect them to be separate units. And. So and, that affects how it's going to render in things like the developer Tooling in the RPC Json API. Because
00:43:00.000 --> 00:43:59.999 align:start position:0%
That's yeah like, that's where we actually do map things to string keys and they either map or they don't map well. If if we make them like separate fields in the data nothing, that we built today for developer tooling is going to be able to map those things to a string key we want them to be a string key. If we put them in a single field. Then we have, that option. But, that may or may not be a good idea and we're also talking about redundant data too. So does it you know. If the G is in the topic does it really make sense to spend another 32 bytes and actually keep, that g in the data as well, that's unclear to me right yeah yeah I just want to point out, that like basically for the exchanges I don't think any option is specifically like bad or inefficient. Because like still have a somewhere in the event. So they you
00:44:00.000 --> 00:44:59.999 align:start position:0%
Never need to like par this out of strink key as for the overhead yeah I think it's a valid concern yeah I think like number one I think niik sort of pointed out, that that was an option, that was is like low risk of doing the wrong thing with like option one is. So simple you know, that everything's pulled apart you've got everything in the event the really only downside of option one where everything's broken apart is the developer experience isn't quite the same. So. When you're looking at a human readable version of an event you're going to see this memo and a g address you're not going to see, that M, that was in the original. But this already happens everywhere you know. When you go to `stellar.expert` or other explorers and you drop in an M address it immediately drops you into a page about the G address. So I don't actually think we need to have complete consistency with madress goes in madress
00:45:00.000 --> 00:45:59.999 align:start position:0%
Comes out yeah yeah I guess I just generally say I'm generally for option one I think it's simple the messages smaller smaller yeah yeah I think this may be fine and also like for the consistency part like at least like. If you can have M addresses in the contract invocations things are immediately much less confusion. Because you know. If you wanted to check your your transaction like there is a very good chance, that block Explorer will correctly say, that you actually have performed the transfer to an M address and you know not some pair, which was my concern for for the input. But for the events I agree it may be not as important and events are generally much less human reable. So maybe yeah it's not worth to optimize for exactly the same range range as rendering as we would have expected
00:46:00.000 --> 00:46:59.999 align:start position:0%
From the signature of the function. So yeah I think option one is probably fine okay. So it sounds like we're leaning towards option one no one's opposed to, that if. So we can move on to the next topic yeah I'm good all right the next thing I think we should discuss is what to do about the TX memo. If we should admit, that as a separate event. Because you know for example. If you're replaying. If if an exchange is replaying using Classic Events and someone sent a you know a payment to coinbase with TX memo and the M and a
00:47:00.000 --> 00:47:59.999 align:start position:0%
M account we don't have space in the current events as there as they defined to include both like both the txl and the MX information. So an option, that Dio mentioned is we could just emit a system event similar to how we CAP 67 emits a fee event and, that event will just contain the the the TX memo. If one existed anyone have any thoughts on, that I mean I you're saying sorry sorry like. So you're saying like you would not evit emit a m or whatever like know this destination destination memo event. If you have a transaction memo no. So. When I'm saying is like on a payment. If you use a MOX account you will have a des station memo in the transfer event right. But. If that transaction also had a TX memo set what do you do yeah. But. But
00:48:00.000 --> 00:48:59.999 align:start position:0%
First of all like I'd like to understand what happens. If you only have a transaction memo and not a Max destination yeah. So the CAP currently, that says, that you there's like an order of Precedence. So you would pull the TX memo and put it into the event. But. If you emitted the TX memo separately it would probably make sense to ignore ignore, that order of Precedence and have the consumer pull the information, that they want right no, that's mistake yeah. Because we saw with Horizon right like the this model where you let clients kind of decide we I think this is the opportunity to actually fully specify this precedence order. So, that you don't have ambiguity right. Because I'm pretty sure I mean I don't know I don't want to put you know exchanges in in you know in trouble. But I imagine, that the This president's order is not
00:49:00.000 --> 00:49:59.999 align:start position:0%
Actually respected. Because it's actually fairly complicated no what well let's let's I step back for a second is is the ability to re for an exchange to replay from Genesis using events a requirement. Because. If it is. Then you you can't make assumptions about. If they care like you know certain exchanges may care about the TX Momo and some may care about the M information right I think this is a new event stream. So we get to do what makes sense. If I think yes you don't want to lose the information, that there was a TX memo yeah at the same time I do think, that the transfer events should contain the you know what we think is the I mean as as per specific as per the specification of transfer events what we believe is the the right you know destination memo in this case yeah and I think on, that point it
00:50:00.000 --> 00:50:59.999 align:start position:0%
Doesn't I'm not actually sure. If reap like we can't we change this this is a new event Stream. So the replay can use the new semantics. While the previous versions of meta and the transactions still describe the old semantics yeah the the events can you know do whatever we can be specified. However we want them to be maybe I wasn't clear like like what I was initially saying is, that the the TX memo would be in this new event and the transfer event would only have any it only have MOX account information and and I think ni you're saying, that in some some cases we should push the TX memo into the transfer event as well I think for yeah like. If we are going forward like it's more like yeah what do we want the those events to look like for Classic Events I think we want them to properly represent the
00:51:00.000 --> 00:51:59.999 align:start position:0%
Destination and. Therefore you need to see the transfer event with the proper destination plus memo like you know like option one let's say right even. If the memo is actually at the trans has been specified at the transac only at the transaction layer okay. So. If the account wasn't moxed. Then for the the memo into the transfer event and the M basically indistinguishable. If you have like only the transaction level memo only the destination you know M account on either transaction or operation right those three cases should all end up with the right U you know transfer event with the added memo information as far as like the you know do we need a an event for the memo I don't know what the use cases for, that are. So
00:52:00.000 --> 00:52:59.999 align:start position:0%
Yeah like like people you can already get, that by by pulling the transaction itself and you know cracking it open basically. If you want. If you really, that. But I agree, that that you can do, that that. But like didn't didn't we want consumers to not have to do, that I guess it depends on. If that's a requirement or not we care about in the context of. If I think the context of the CAP was transfers in the context of transfers this sound seems to be out of scope okay sorry I'm I'm not totally tracking with
00:53:00.000 --> 00:53:59.999 align:start position:0%
With what we've just said. So Nico is saying, that the, that that the emitting an event purely for the TX memo like a separate event is out of scope in in terms in in the context of transfers I'm not sure about this spe I'm specifically thinking about the the replay case for exchanges cuz I you know. If you what what what is what happens. If you have a transaction of the TX memo and MX MX destination account. Because without the TX memo event you can only show one right. But in, that case the thing is, that. If people have like complex logic they will have to actually derive it from the transaction they have to know exactly okay did we, which combination of things right where they into I think, that's why I'm saying like the the transaction memo is not sufficient. If you. If you're get. If you're starting to pull, that thread like you have to do transaction
00:54:00.000 --> 00:54:59.999 align:start position:0%
Memo two second on the transac I mean destination oh actually no this one I guess the override can only happen on the two. So it there's only one place. But. If it's the source, that's where you have like the transaction Source or the operation Source right, that are on yeah yeah the source does make this more complicated this is well I'm actually not sure. If the source makes it, though much more complicated does it isn't isn't the complexity, that an exchange might be reading the TX memo today and actually ignoring the M the MOX address and just using the G part of the max address isn't, that the complex part yeah well. So, that's the, that's scenario, that I like this event might help you solve maybe right. Because I'm sure, that I'm guessing, that happens today like. If I send a an a payment to coinbase with the MOX account set and a TX memo like they. If they they probably just I'm guessing they treat it as. If the account
00:55:00.000 --> 00:55:59.999 align:start position:0%
Wasn't mxed right no, that's why we don't know. Because it's yeah under specified okay I guess for this we'll like to me, that yeah like the we this discussion is more like I see the historical stuff as more like as a best effort. Because really like exchanges in particular are they really I mean do you really want people to to be reinges you know from Genesis or something like they already ingested already reconcile all these data in their back end yeah, that's a good point okay there's also the additional ambiguity of. If someone's sending to a m address and has a memo at the transaction level you shouldn't necessarily assume, that that transaction memo is a specification of a user on the destination side right it could just be
00:56:00.000 --> 00:56:59.999 align:start position:0%
Some free text just for the purposes of describing the transaction yeah the point of this event was just to you know show all the information and have the consumers deal with it. But it sounds like we we we don't need to deal with this right. Now also we're out of time the last thing we were going to discuss we we can maybe do this offline is, that we don't we no longer need CAP 64. But I don't know Deo. If you want to say anything about, that yeah I guess the consensus of the discussions has been, that yeah CAP 64 is not needed and yeah this is just an official announcement, that we Are CL on it. Because MOS will be implemented differently yeah, that's it all right. Then we're out of time for today thank thank you for joining and thanks everyone for participating.