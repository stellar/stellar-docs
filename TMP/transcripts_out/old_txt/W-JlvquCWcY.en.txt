hi everyone
hi everyone
hope everybody is having a fantastic
hope everybody is having a fantastic
hope everybody is having a fantastic
friday morning afternoon wherever you
friday morning afternoon wherever you
friday morning afternoon wherever you
are
are
are
my name is devneal I'm a software
my name is devneal I'm a software
my name is devneal I'm a software
engineer at sdf on the voyager team
engineer at sdf on the voyager team
engineer at sdf on the voyager team
we focus on exploring the Stellar
we focus on exploring the Stellar
we focus on exploring the Stellar
ecosystem through data
ecosystem through data
ecosystem through data
analytics and liquidity today i'll be
analytics and liquidity today i'll be
analytics and liquidity today i'll be
talking about data analytics on Stellar
talking about data analytics on Stellar
talking about data analytics on Stellar
so the goal of our team as well as a lot
so the goal of our team as well as a lot
so the goal of our team as well as a lot
of the work that I do at sdf
of the work that I do at sdf
of the work that I do at sdf
is to do the fundamental meta work that
is to do the fundamental meta work that
is to do the fundamental meta work that
powers the rest of the network
powers the rest of the network
powers the rest of the network
how can we ensure that assets have
how can we ensure that assets have
how can we ensure that assets have
robust markets
robust markets
robust markets
how can we improve the visibility of the
how can we improve the visibility of the
how can we improve the visibility of the
network both inside
network both inside
network both inside
and outside sdf and how do we use data
and outside sdf and how do we use data
and outside sdf and how do we use data
to further drive network growth
to further drive network growth
to further drive network growth
in this talk i'll be talking about the
in this talk i'll be talking about the
in this talk i'll be talking about the
first version of our data analytics
first version of our data analytics
first version of our data analytics
system
system
system
targeted and answering those three
targeted and answering those three
targeted and answering those three
questions as well as many others
questions as well as many others
questions as well as many others
so who is this helpful for anyone
so who is this helpful for anyone
so who is this helpful for anyone
interested in
interested in
interested in
one building analytics pipelines from
one building analytics pipelines from
one building analytics pipelines from
zero to one
zero to one
zero to one
I hope our experience is generally
I hope our experience is generally
I hope our experience is generally
helpful to people who have a bunch of
helpful to people who have a bunch of
helpful to people who have a bunch of
data
data
data
that are just trying to build out some
that are just trying to build out some
that are just trying to build out some
analytic system
analytic system
analytic system
two exploring the Stellar network i'll
two exploring the Stellar network i'll
two exploring the Stellar network i'll
present some useful access patterns
present some useful access patterns
present some useful access patterns
tips for navigating the Stellar data set
tips for navigating the Stellar data set
tips for navigating the Stellar data set
and a few illustrative examples
and a few illustrative examples
and a few illustrative examples
with basic sql knowledge you can ask
with basic sql knowledge you can ask
with basic sql knowledge you can ask
some powerful network-wide questions
some powerful network-wide questions
some powerful network-wide questions
three scaling analytics from one to one
three scaling analytics from one to one
three scaling analytics from one to one
hundred
hundred
hundred
if you have a working data pipeline
if you have a working data pipeline
if you have a working data pipeline
what's next i'll share some of my
what's next i'll share some of my
what's next i'll share some of my
thoughts on the subject
thoughts on the subject
thoughts on the subject
and i'd love to hear your wants
and i'd love to hear your wants
and i'd love to hear your wants
as a brief roadmap of the talk it'll be
as a brief roadmap of the talk it'll be
as a brief roadmap of the talk it'll be
in four parts
in four parts
in four parts
first design what we wanted to build
first design what we wanted to build
first design what we wanted to build
second implementation how we built it
second implementation how we built it
second implementation how we built it
design and implementation are the meat
design and implementation are the meat
design and implementation are the meat
of this talk
of this talk
of this talk
as it is an engineering talk after all
as it is an engineering talk after all
as it is an engineering talk after all
third analysis
third analysis
third analysis
i'll display some interesting queries
i'll display some interesting queries
i'll display some interesting queries
along with some strategic tips on using
along with some strategic tips on using
along with some strategic tips on using
our public data set
our public data set
our public data set
in the interest of time and network
in the interest of time and network
in the interest of time and network
connections over the talk
connections over the talk
connections over the talk
I'm not going to live code but I will
I'm not going to live code but I will
I'm not going to live code but I will
share links for folks do their own
share links for folks do their own
share links for folks do their own
exploring
exploring
exploring
and finally next steps what's in the
and finally next steps what's in the
and finally next steps what's in the
pipeline no pun intended for data
pipeline no pun intended for data
pipeline no pun intended for data
analytics
analytics
analytics
I note that if you have questions
I note that if you have questions
I note that if you have questions
there's a qr code
there's a qr code
there's a qr code
on the youtube and you can also ask
on the youtube and you can also ask
on the youtube and you can also ask
questions of the youtube chat
questions of the youtube chat
questions of the youtube chat
and i'll be answering those questions at
and i'll be answering those questions at
and i'll be answering those questions at
the end to make sure I get through all
the end to make sure I get through all
the end to make sure I get through all
this material
this material
this material
so first design
to understand the design goals let's
to understand the design goals let's
first talk about our motivations
first talk about our motivations
first talk about our motivations
why did we even want a cloud scale data
why did we even want a cloud scale data
why did we even want a cloud scale data
pipeline
pipeline
pipeline
ultimately we want to quickly and
ultimately we want to quickly and
ultimately we want to quickly and
efficiently generate the histories of
efficiently generate the histories of
efficiently generate the histories of
assets accounts markets whatever over
assets accounts markets whatever over
assets accounts markets whatever over
the history of the network
the history of the network
the history of the network
the primary use case is internal
the primary use case is internal
the primary use case is internal
business analytics we wanted to make it
business analytics we wanted to make it
business analytics we wanted to make it
as
as
as
easy as possible for our business
easy as possible for our business
easy as possible for our business
development and ecosystem teams
development and ecosystem teams
development and ecosystem teams
to understand the effects of their
to understand the effects of their
to understand the effects of their
efforts so Stellar uses the widely used
efforts so Stellar uses the widely used
efforts so Stellar uses the widely used
database as some postgres which has been
database as some postgres which has been
database as some postgres which has been
an industry standard for
an industry standard for
an industry standard for
20 25 years so Stellar core writes data
20 25 years so Stellar core writes data
20 25 years so Stellar core writes data
to postgres tables
to postgres tables
to postgres tables
and then horizon our api to Stellar core
and then horizon our api to Stellar core
and then horizon our api to Stellar core
uses
uses
uses
the core data but it also has its own
the core data but it also has its own
the core data but it also has its own
database because it's a web application
database because it's a web application
database because it's a web application
so the pros of this are that it's well
so the pros of this are that it's well
so the pros of this are that it's well
known and well documented
known and well documented
known and well documented
it's great for tran processing a bunch
it's great for tran processing a bunch
it's great for tran processing a bunch
of online transactions
of online transactions
of online transactions
when there's a bunch coming into you in
when there's a bunch coming into you in
when there's a bunch coming into you in
a highly concurrent heavy write
a highly concurrent heavy write
a highly concurrent heavy write
environment
environment
environment
the cons are also pretty well
the cons are also pretty well
the cons are also pretty well
documented
documented
documented
it's slow for historical queries for
it's slow for historical queries for
it's slow for historical queries for
specific column values
specific column values
specific column values
which makes it much worse for analytics
which makes it much worse for analytics
which makes it much worse for analytics
horizons database structure and indices
horizons database structure and indices
horizons database structure and indices
are optimized for the exposed api of
are optimized for the exposed api of
are optimized for the exposed api of
verizon
verizon
verizon
that also means that if you're trying to
that also means that if you're trying to
that also means that if you're trying to
do deeper queries across a bunch of
do deeper queries across a bunch of
do deeper queries across a bunch of
different accounts or tables
different accounts or tables
different accounts or tables
it quickly becomes inefficient so for
it quickly becomes inefficient so for
it quickly becomes inefficient so for
example complex joins or filters
example complex joins or filters
example complex joins or filters
become really extremely time inefficient
become really extremely time inefficient
become really extremely time inefficient
apps and indexes
apps and indexes
apps and indexes
a good example of this would be trying
a good example of this would be trying
a good example of this would be trying
to do analysis of the network but
to do analysis of the network but
to do analysis of the network but
excluding
excluding
excluding
arbitrage operations because that would
arbitrage operations because that would
arbitrage operations because that would
require a bunch of joints of different
require a bunch of joints of different
require a bunch of joints of different
tables
tables
tables
and then now you have to make filters
and then now you have to make filters
and then now you have to make filters
over a really really big table
over a really really big table
over a really really big table
so to understand behavior at scale it
so to understand behavior at scale it
so to understand behavior at scale it
became pretty clear to us that we would
became pretty clear to us that we would
became pretty clear to us that we would
have to build some new infrastructure
it's also important to talk about our
it's also important to talk about our
goals so above all
goals so above all
goals so above all
we wanted value for internal
we wanted value for internal
we wanted value for internal
stakeholders this is a really important
stakeholders this is a really important
stakeholders this is a really important
node when you're building data products
node when you're building data products
node when you're building data products
it's really easy to nerd out and build
it's really easy to nerd out and build
it's really easy to nerd out and build
something that's really cool for
something that's really cool for
something that's really cool for
engineers
engineers
engineers
but the end user is always your
but the end user is always your
but the end user is always your
non-technical users if product
non-technical users if product
non-technical users if product
guarantees
guarantees
guarantees
don't align with business needs then you
don't align with business needs then you
don't align with business needs then you
won't ship the right solution for your
won't ship the right solution for your
won't ship the right solution for your
end users
end users
end users
and even worse you might just make more
and even worse you might just make more
and even worse you might just make more
work for yourself because you have to
work for yourself because you have to
work for yourself because you have to
onboard a bunch of people into a
onboard a bunch of people into a
onboard a bunch of people into a
non-intuitive system
non-intuitive system
non-intuitive system
second open source or open access open
second open source or open access open
second open source or open access open
source is really core to fdf dna
source is really core to fdf dna
source is really core to fdf dna
and we want to support open source tools
and we want to support open source tools
and we want to support open source tools
wherever possible
wherever possible
wherever possible
of course some things require spend like
of course some things require spend like
of course some things require spend like
cloud infrastructure
cloud infrastructure
cloud infrastructure
but we want to optimize for open access
but we want to optimize for open access
but we want to optimize for open access
in the organization
in the organization
in the organization
followed by easy public access third
followed by easy public access third
followed by easy public access third
a daily updated data set well some
a daily updated data set well some
a daily updated data set well some
businesses need real-time updates
businesses need real-time updates
businesses need real-time updates
at the point that we were when we
at the point that we were when we
at the point that we were when we
started building this daily updates were
started building this daily updates were
started building this daily updates were
sufficient for the course grain metrics
sufficient for the course grain metrics
sufficient for the course grain metrics
that we wanted to do
that we wanted to do
that we wanted to do
fourth seamless integration with our
fourth seamless integration with our
fourth seamless integration with our
current staff
current staff
current staff
as mentioned before we rely heavily on
as mentioned before we rely heavily on
as mentioned before we rely heavily on
postgres
postgres
postgres
as our databases and when you have
as our databases and when you have
as our databases and when you have
existing tools
existing tools
existing tools
you need to make sure that support for
you need to make sure that support for
you need to make sure that support for
those tools is well tested in anything
those tools is well tested in anything
those tools is well tested in anything
you bolt onto your system
you bolt onto your system
you bolt onto your system
additionally it had to also be deployed
additionally it had to also be deployed
additionally it had to also be deployed
easily
easily
easily
it had to be in-house controlled on our
it had to be in-house controlled on our
it had to be in-house controlled on our
infrastructure and easy to deploy by our
infrastructure and easy to deploy by our
infrastructure and easy to deploy by our
site for liability and ops team
site for liability and ops team
site for liability and ops team
so our stack last year migrated from
so our stack last year migrated from
so our stack last year migrated from
puppet to docker and kubernetes
puppet to docker and kubernetes
puppet to docker and kubernetes
so we needed technology that easily
so we needed technology that easily
so we needed technology that easily
integrated with this and for some quick
integrated with this and for some quick
integrated with this and for some quick
buzzword explanation
buzzword explanation
buzzword explanation
puppet is a legacy system administration
puppet is a legacy system administration
puppet is a legacy system administration
software docker lets you
software docker lets you
software docker lets you
contain custom programs in their
contain custom programs in their
contain custom programs in their
environment and kubernetes is
environment and kubernetes is
environment and kubernetes is
orchestration software that lets you
orchestration software that lets you
orchestration software that lets you
decide how those containers
decide how those containers
decide how those containers
are then deployed and run and fifth and
are then deployed and run and fifth and
are then deployed and run and fifth and
finally easy metrics and visualization
finally easy metrics and visualization
finally easy metrics and visualization
this is pretty self-explanatory it
this is pretty self-explanatory it
this is pretty self-explanatory it
lowers the bar for non-technical users
lowers the bar for non-technical users
lowers the bar for non-technical users
and it brings much more value to the
and it brings much more value to the
and it brings much more value to the
organization as a whole
so many of the requirements about birth
so many of the requirements about birth
fuzzy some are more technical and tools
fuzzy some are more technical and tools
fuzzy some are more technical and tools
oriented
oriented
oriented
so how do those break down into
so how do those break down into
so how do those break down into
technical decisions
technical decisions
technical decisions
so this is ordered from most to least
so this is ordered from most to least
so this is ordered from most to least
defined
defined
defined
as a deployment infrastructure we would
as a deployment infrastructure we would
as a deployment infrastructure we would
use docker and kubernetes
use docker and kubernetes
use docker and kubernetes
this would be important for
this would be important for
this would be important for
orchestrating software having regularly
orchestrating software having regularly
orchestrating software having regularly
scheduled cron jobs and the like
scheduled cron jobs and the like
scheduled cron jobs and the like
it was already our technical stack so we
it was already our technical stack so we
it was already our technical stack so we
needed to play with it
needed to play with it
needed to play with it
second the cloud scale warehouse this
second the cloud scale warehouse this
second the cloud scale warehouse this
needed a bunch of capabilities
needed a bunch of capabilities
needed a bunch of capabilities
determined by what I just said
determined by what I just said
determined by what I just said
it had to have scripting abilities
it had to have scripting abilities
it had to have scripting abilities
really good postgres integration
really good postgres integration
really good postgres integration
and really easy organization-wide
and really easy organization-wide
and really easy organization-wide
credentialing so all engineers and
credentialing so all engineers and
credentialing so all engineers and
non-engineers
non-engineers
non-engineers
could easily access the warehouse and
could easily access the warehouse and
could easily access the warehouse and
make their own queries
make their own queries
make their own queries
third metrics and visualization this was
third metrics and visualization this was
third metrics and visualization this was
the least defined for sure
the least defined for sure
the least defined for sure
we decided that it would be secondary to
we decided that it would be secondary to
we decided that it would be secondary to
a data warehouse because ultimately the
a data warehouse because ultimately the
a data warehouse because ultimately the
engine
engine
engine
matters more than whatever you're doing
matters more than whatever you're doing
matters more than whatever you're doing
on top of it but we did know that we
on top of it but we did know that we
on top of it but we did know that we
want this to be open source
want this to be open source
want this to be open source
free and easy for non-technical users
free and easy for non-technical users
free and easy for non-technical users
through something like the drag and drop
interface
interface
let's now talk about implementation
so the first was infrastructure docker
so the first was infrastructure docker
and kubernetes
and kubernetes
and kubernetes
while this decision was made for us some
while this decision was made for us some
while this decision was made for us some
details of it made everything a lot
details of it made everything a lot
details of it made everything a lot
easier
easier
easier
which is what commonly happens when you
which is what commonly happens when you
which is what commonly happens when you
have to integrate with an existing stack
have to integrate with an existing stack
have to integrate with an existing stack
docker-based containerization gave us a
docker-based containerization gave us a
docker-based containerization gave us a
really easy standard for evaluation of
really easy standard for evaluation of
really easy standard for evaluation of
other tools
other tools
other tools
particularly visualization could it be
particularly visualization could it be
particularly visualization could it be
easily deployed on our infrastructure
easily deployed on our infrastructure
easily deployed on our infrastructure
second kubernetes cron jobs gave us an
second kubernetes cron jobs gave us an
second kubernetes cron jobs gave us an
easy scheduling method
easy scheduling method
easy scheduling method
for running scripts deployed via docker
for running scripts deployed via docker
for running scripts deployed via docker
we could just set a schedule and run the
we could just set a schedule and run the
we could just set a schedule and run the
procedure as
procedure as
procedure as
is it was also really easy to integrate
is it was also really easy to integrate
is it was also really easy to integrate
the postgres cluster
the postgres cluster
the postgres cluster
it was easy to provision external
it was easy to provision external
it was easy to provision external
storage in case we needed to have
storage in case we needed to have
storage in case we needed to have
external memory for the data pipeline
external memory for the data pipeline
external memory for the data pipeline
and it also allowed for retries on
and it also allowed for retries on
and it also allowed for retries on
failure
failure
failure
in all this is a really good deployment
in all this is a really good deployment
in all this is a really good deployment
stack and it's pretty clear why it's
stack and it's pretty clear why it's
stack and it's pretty clear why it's
become the modern stack of choice
become the modern stack of choice
become the modern stack of choice
it's really good for integrating a lot
it's really good for integrating a lot
it's really good for integrating a lot
of different technology it's really
of different technology it's really
of different technology it's really
resilient
resilient
resilient
in general it's pretty easy to work with
in general it's pretty easy to work with
in general it's pretty easy to work with
no real complaints about docker and
no real complaints about docker and
no real complaints about docker and
kubernetes
second for the cloud data warehouse i
second for the cloud data warehouse i
was kind of worried about this at first
was kind of worried about this at first
was kind of worried about this at first
because there are a ton of options
because there are a ton of options
because there are a ton of options
but google bigquery actually ended up
but google bigquery actually ended up
but google bigquery actually ended up
being a really easy choice for us
being a really easy choice for us
being a really easy choice for us
for one the queries are super fast they
for one the queries are super fast they
for one the queries are super fast they
were 10 to even a thousand times faster
were 10 to even a thousand times faster
were 10 to even a thousand times faster
than some queries from the verizon
than some queries from the verizon
than some queries from the verizon
database
database
database
we were honestly just blown away by how
we were honestly just blown away by how
we were honestly just blown away by how
much better it was
much better it was
much better it was
second intermediate cloud storage where
second intermediate cloud storage where
second intermediate cloud storage where
do files live
do files live
do files live
during the data pipeline google cloud
during the data pipeline google cloud
during the data pipeline google cloud
has a cloud storage service which is
has a cloud storage service which is
has a cloud storage service which is
called google cloud storage
called google cloud storage
called google cloud storage
this means that we can separate the
this means that we can separate the
this means that we can separate the
pipeline into a few different parts
pipeline into a few different parts
pipeline into a few different parts
one export tables from postgres to disk
one export tables from postgres to disk
one export tables from postgres to disk
to
to
to
upload from the disk to cloud storage
upload from the disk to cloud storage
upload from the disk to cloud storage
and three download from cloud storage to
and three download from cloud storage to
and three download from cloud storage to
bigquery
bigquery
bigquery
so separating the pipeline like that
so separating the pipeline like that
so separating the pipeline like that
reduced the risk of failure and it also
reduced the risk of failure and it also
reduced the risk of failure and it also
made retries less expensive because we
made retries less expensive because we
made retries less expensive because we
would just retry one of the scripts
would just retry one of the scripts
would just retry one of the scripts
third there was really painless
third there was really painless
third there was really painless
command-line scripting
command-line scripting
command-line scripting
it's super straightforward to script
it's super straightforward to script
it's super straightforward to script
exporting files from postgres then
exporting files from postgres then
exporting files from postgres then
uploading to bigquery
uploading to bigquery
uploading to bigquery
it made creating a basic pipeline really
it made creating a basic pipeline really
it made creating a basic pipeline really
easy to reason about from the command
easy to reason about from the command
easy to reason about from the command
line
line
line
and also in turn pretty easy to
and also in turn pretty easy to
and also in turn pretty easy to
containerize because we were just
containerize because we were just
containerize because we were just
uploading a bash script into the docker
uploading a bash script into the docker
uploading a bash script into the docker
container
container
container
fourth google suite authentication so
fourth google suite authentication so
fourth google suite authentication so
within
within
within
sdf we used g suite so it meant that
sdf we used g suite so it meant that
sdf we used g suite so it meant that
everyone had g suite permissions
everyone had g suite permissions
everyone had g suite permissions
it also meant it was really easy to set
it also meant it was really easy to set
it also meant it was really easy to set
up and share permissions across the
up and share permissions across the
up and share permissions across the
organization
organization
organization
I would say that this is like a low
I would say that this is like a low
I would say that this is like a low
priority in terms of deciding a
priority in terms of deciding a
priority in terms of deciding a
warehouse but it is actually why we
warehouse but it is actually why we
warehouse but it is actually why we
tried
tried
tried
bigquery up first because it was really
bigquery up first because it was really
bigquery up first because it was really
easy to integrate within our
easy to integrate within our
easy to integrate within our
organization
organization
organization
and I suspect that organizations that
and I suspect that organizations that
and I suspect that organizations that
run on microsoft like microsoft teams or
run on microsoft like microsoft teams or
run on microsoft like microsoft teams or
whatever
whatever
whatever
might have similar experience with azure
might have similar experience with azure
might have similar experience with azure
so I do think it probably determines
so I do think it probably determines
so I do think it probably determines
live organizational needs
third for metrics we decided to use
third for metrics we decided to use
google sheets
google sheets
google sheets
this was actually more straightforward
this was actually more straightforward
this was actually more straightforward
than the warehouse because we decided
than the warehouse because we decided
than the warehouse because we decided
that we wanted some basic data science
that we wanted some basic data science
that we wanted some basic data science
capabilities that were slightly outside
capabilities that were slightly outside
capabilities that were slightly outside
the
the
the
scope of queries and after we talked to
scope of queries and after we talked to
scope of queries and after we talked to
a bunch of folks around the organization
a bunch of folks around the organization
a bunch of folks around the organization
it made the most sense to surface this
it made the most sense to surface this
it made the most sense to surface this
through spreadsheets it's a really
through spreadsheets it's a really
through spreadsheets it's a really
common user interface for non-technical
common user interface for non-technical
common user interface for non-technical
folks and it keeps data tabular so you
folks and it keeps data tabular so you
folks and it keeps data tabular so you
can pretty easily connect
can pretty easily connect
can pretty easily connect
here's whatever the table I got out and
here's whatever the table I got out and
here's whatever the table I got out and
here's how it looks on the actual
here's how it looks on the actual
here's how it looks on the actual
spreadsheet
spreadsheet
spreadsheet
so python scripts are also the right
so python scripts are also the right
so python scripts are also the right
tool for post processing by a lot
tool for post processing by a lot
tool for post processing by a lot
it really is a swiss army knife for data
it really is a swiss army knife for data
it really is a swiss army knife for data
you can really easily read a table
you can really easily read a table
you can really easily read a table
from bigquery run some custom
from bigquery run some custom
from bigquery run some custom
post-processing using common data
post-processing using common data
post-processing using common data
science tools like pandas
science tools like pandas
science tools like pandas
and then write the output to a google
and then write the output to a google
and then write the output to a google
sheet finally note that we deployed
sheet finally note that we deployed
sheet finally note that we deployed
these scripts in a server-less fashion
these scripts in a server-less fashion
these scripts in a server-less fashion
on google cloud scheduler
on google cloud scheduler
on google cloud scheduler
once the bigquery dataset was updated by
once the bigquery dataset was updated by
once the bigquery dataset was updated by
the kubernetes orchestrated cron job
the kubernetes orchestrated cron job
the kubernetes orchestrated cron job
you could then trigger these scripts and
you could then trigger these scripts and
you could then trigger these scripts and
then update the spreadsheet it was a
then update the spreadsheet it was a
then update the spreadsheet it was a
really cool event driven architecture
really cool event driven architecture
really cool event driven architecture
really simple really powerful and
really simple really powerful and
really simple really powerful and
honestly I think that
honestly I think that
honestly I think that
this sort of way to automate metrics is
this sort of way to automate metrics is
this sort of way to automate metrics is
a really good one
fourth and finally visualization this
fourth and finally visualization this
was by and far away the hardest part of
was by and far away the hardest part of
was by and far away the hardest part of
the implementation
the implementation
the implementation
since there's actually a million tools
since there's actually a million tools
since there's actually a million tools
and documentation that compares them
and documentation that compares them
and documentation that compares them
directly doesn't really exist
directly doesn't really exist
directly doesn't really exist
so at this point like we've settled on
so at this point like we've settled on
so at this point like we've settled on
bigquery so we wanted really easy
bigquery so we wanted really easy
bigquery so we wanted really easy
bigquery integration
bigquery integration
bigquery integration
really easy deployment on docker and
really easy deployment on docker and
really easy deployment on docker and
kubernetes some nice visualizations that
kubernetes some nice visualizations that
kubernetes some nice visualizations that
use drag and drop
use drag and drop
use drag and drop
and some sql and we also wanted to be
and some sql and we also wanted to be
and some sql and we also wanted to be
open source so I tried a lot of tools
open source so I tried a lot of tools
open source so I tried a lot of tools
that
that
that
fit some or all of those capabilities
fit some or all of those capabilities
fit some or all of those capabilities
some of the most
some of the most
some of the most
prominent ones that we looked at were
prominent ones that we looked at were
prominent ones that we looked at were
google data studio apache superset and
google data studio apache superset and
google data studio apache superset and
looker
looker
looker
what we generally found was the tools
what we generally found was the tools
what we generally found was the tools
that played nice with bigquery
that played nice with bigquery
that played nice with bigquery
usually either didn't have drag and drop
usually either didn't have drag and drop
usually either didn't have drag and drop
or weren't free
or weren't free
or weren't free
and so we ended up settling on metabase
and so we ended up settling on metabase
and so we ended up settling on metabase
because it honestly fit all of our
because it honestly fit all of our
because it honestly fit all of our
original pillars quite well
original pillars quite well
original pillars quite well
it has both sql as well as a drag and
it has both sql as well as a drag and
it has both sql as well as a drag and
drop interface
drop interface
drop interface
it's free and really easy to set up and
it's free and really easy to set up and
it's free and really easy to set up and
I think if you need to mvp a pipeline
I think if you need to mvp a pipeline
I think if you need to mvp a pipeline
it's a really good option
finally let's talk about some of the
finally let's talk about some of the
downsides of our v1 implementation
downsides of our v1 implementation
downsides of our v1 implementation
for one daily frequency is slow while
for one daily frequency is slow while
for one daily frequency is slow while
good enough for initial use cases
good enough for initial use cases
good enough for initial use cases
a daily update limits building out data
a daily update limits building out data
a daily update limits building out data
intensive apps on seller
intensive apps on seller
intensive apps on seller
we want to get closer to real-time
we want to get closer to real-time
we want to get closer to real-time
updates for next version of the system
updates for next version of the system
updates for next version of the system
two observing failures is hard we were
two observing failures is hard we were
two observing failures is hard we were
still learning our way around kubernetes
still learning our way around kubernetes
still learning our way around kubernetes
logging
logging
logging
and ideally we want to be able to reach
and ideally we want to be able to reach
and ideally we want to be able to reach
by really specific granular portions
by really specific granular portions
by really specific granular portions
when they fail
when they fail
when they fail
so there are good task management
so there are good task management
so there are good task management
systems out there and that seemed like a
systems out there and that seemed like a
systems out there and that seemed like a
natural evolution of the system
natural evolution of the system
natural evolution of the system
three visualizations were private we'd
three visualizations were private we'd
three visualizations were private we'd
love to expose our information
love to expose our information
love to expose our information
visualizations publicly
visualizations publicly
visualizations publicly
but we can't mix the platform that we
but we can't mix the platform that we
but we can't mix the platform that we
use for internal business analytics with
use for internal business analytics with
use for internal business analytics with
everyone else
everyone else
everyone else
so we decided that we'd have to think
so we decided that we'd have to think
so we decided that we'd have to think
about an intermediate solution
about an intermediate solution
about an intermediate solution
and four exploring data is painful so
and four exploring data is painful so
and four exploring data is painful so
you'll notice I didn't actually talk
you'll notice I didn't actually talk
you'll notice I didn't actually talk
about a data science platform above
about a data science platform above
about a data science platform above
and while serverless functions provide
and while serverless functions provide
and while serverless functions provide
some capabilities for robust and regular
some capabilities for robust and regular
some capabilities for robust and regular
jobs
jobs
jobs
ideally the platform enables exploratory
ideally the platform enables exploratory
ideally the platform enables exploratory
data analysis through scripts
data analysis through scripts
data analysis through scripts
every data scientist now uses jupiter
every data scientist now uses jupiter
every data scientist now uses jupiter
notebooks and
notebooks and
notebooks and
we want to make it really easy to do the
we want to make it really easy to do the
we want to make it really easy to do the
same on Stellar data
so now let's look at some basic analysis
so now let's look at some basic analysis
of some queries on our system
so for one we'll start off with an easy
so for one we'll start off with an easy
query what account has the highest lumen
query what account has the highest lumen
query what account has the highest lumen
balance
balance
balance
I call this easy because it's pretty
I call this easy because it's pretty
I call this easy because it's pretty
short but it's really cool because it
short but it's really cool because it
short but it's really cool because it
illustrates
illustrates
illustrates
how powerful even basic sql tools are so
how powerful even basic sql tools are so
how powerful even basic sql tools are so
this shows some really basic sql syntax
this shows some really basic sql syntax
this shows some really basic sql syntax
select from order by and limit
select from order by and limit
select from order by and limit
those give you the tools to ask basic
those give you the tools to ask basic
those give you the tools to ask basic
ordinal questions about Stellar history
ordinal questions about Stellar history
ordinal questions about Stellar history
select from chooses specific fields from
select from chooses specific fields from
select from chooses specific fields from
a table order by orders the results of
a table order by orders the results of
a table order by orders the results of
the field
the field
the field
and limit says how many you want to see
and limit says how many you want to see
and limit says how many you want to see
as you can all see the account with the
as you can all see the account with the
as you can all see the account with the
most lumens is the galaxy void account
most lumens is the galaxy void account
most lumens is the galaxy void account
which received the lumen burn last
which received the lumen burn last
which received the lumen burn last
merity
now a medium difficulty ferry how many
now a medium difficulty ferry how many
payments of an asset are made daily
payments of an asset are made daily
payments of an asset are made daily
so we show you some new syntax here date
so we show you some new syntax here date
so we show you some new syntax here date
converts a time to justice day
converts a time to justice day
converts a time to justice day
sum is an example aggregation function
sum is an example aggregation function
sum is an example aggregation function
which takes a bunch of
which takes a bunch of
which takes a bunch of
results and then combines them into one
results and then combines them into one
results and then combines them into one
specific number
specific number
specific number
and where can be used for various
and where can be used for various
and where can be used for various
condition where clauses
condition where clauses
condition where clauses
shown here finally group by will group
shown here finally group by will group
shown here finally group by will group
by
by
by
a specific field so this lets us pretty
a specific field so this lets us pretty
a specific field so this lets us pretty
organize
organize
organize
pretty quickly organize and group
pretty quickly organize and group
pretty quickly organize and group
results by day
results by day
results by day
compute daily amounts and do some pretty
compute daily amounts and do some pretty
compute daily amounts and do some pretty
good aggregations
good aggregations
good aggregations
all in all it's actually really simple
all in all it's actually really simple
all in all it's actually really simple
to be able to make these
to be able to make these
to be able to make these
sort of day-by-day analysis and it's
sort of day-by-day analysis and it's
sort of day-by-day analysis and it's
really core part of some of
really core part of some of
really core part of some of
the organizational metrics we track
so finally a high difficulty query how
so finally a high difficulty query how
many trades of a trading pair are made
many trades of a trading pair are made
many trades of a trading pair are made
per day
per day
per day
you'll notice that this has a lot of
you'll notice that this has a lot of
you'll notice that this has a lot of
lines but the actual primitives are
lines but the actual primitives are
lines but the actual primitives are
pretty similar to things you just saw
pretty similar to things you just saw
pretty similar to things you just saw
it has some new syntax so we use with as
it has some new syntax so we use with as
it has some new syntax so we use with as
to create some temporary in-memory
to create some temporary in-memory
to create some temporary in-memory
tables to query and join lets us join
tables to query and join lets us join
tables to query and join lets us join
together different tables on common
together different tables on common
together different tables on common
fields
fields
fields
so you can have some really big tables
so you can have some really big tables
so you can have some really big tables
that you can now condition
that you can now condition
that you can now condition
filter group so on so forth
filter group so on so forth
filter group so on so forth
once again I want to say that like the
once again I want to say that like the
once again I want to say that like the
queries are not the focus of this
queries are not the focus of this
queries are not the focus of this
particular talk the engineering is much
particular talk the engineering is much
particular talk the engineering is much
more of one
more of one
more of one
but feel free to reach out to me either
but feel free to reach out to me either
but feel free to reach out to me either
on the youtube chat or after
on the youtube chat or after
on the youtube chat or after
I'm happy to provide more instructions
I'm happy to provide more instructions
I'm happy to provide more instructions
on how anyone
on how anyone
on how anyone
can make these queries we also put out a
can make these queries we also put out a
can make these queries we also put out a
blog post earlier this summer
blog post earlier this summer
blog post earlier this summer
that covers a lot of this and I highly
that covers a lot of this and I highly
that covers a lot of this and I highly
recommend checking it out
so forth and finally let's talk about
so forth and finally let's talk about
some next steps
some next steps
some next steps
to motivate these think about the
to motivate these think about the
to motivate these think about the
downsides from implementation and we'll
downsides from implementation and we'll
downsides from implementation and we'll
talk about some of the things we could
talk about some of the things we could
talk about some of the things we could
do
do
do
so for one going from slow to real-time
so for one going from slow to real-time
so for one going from slow to real-time
frequency
frequency
frequency
so new horizon capabilities like the new
so new horizon capabilities like the new
so new horizon capabilities like the new
ingestion engine
ingestion engine
ingestion engine
help us get closer to real time because
help us get closer to real time because
help us get closer to real time because
that enables much faster extraction of
that enables much faster extraction of
that enables much faster extraction of
data from Stellar core
data from Stellar core
data from Stellar core
and history archives our awesome intern
and history archives our awesome intern
and history archives our awesome intern
isaiah turner
isaiah turner
isaiah turner
has been building a command line tool
has been building a command line tool
has been building a command line tool
that uses these capabilities
that uses these capabilities
that uses these capabilities
to read in data in close to real time
to read in data in close to real time
to read in data in close to real time
and then
and then
and then
output it in the expected schema and the
output it in the expected schema and the
output it in the expected schema and the
link to it is right here in the slice
second going from low to high
second going from low to high
observability
observability
observability
fixing failures is pretty hard but task
fixing failures is pretty hard but task
fixing failures is pretty hard but task
management makes observing and debugging
management makes observing and debugging
management makes observing and debugging
a lot easier
a lot easier
a lot easier
so while our current system wasn't
so while our current system wasn't
so while our current system wasn't
unmanageable the number of moving parts
unmanageable the number of moving parts
unmanageable the number of moving parts
made reading kubernetes logs the primary
made reading kubernetes logs the primary
made reading kubernetes logs the primary
solution
solution
solution
it's important to note that we added
it's important to note that we added
it's important to note that we added
some sentry logging around business
some sentry logging around business
some sentry logging around business
metric
metric
metric
but the thing about all of that is that
but the thing about all of that is that
but the thing about all of that is that
it shows you that a problem happened
it shows you that a problem happened
it shows you that a problem happened
it doesn't really tell you where it did
it doesn't really tell you where it did
it doesn't really tell you where it did
or what to do to fix it
or what to do to fix it
or what to do to fix it
so combined with the above tooling
so combined with the above tooling
so combined with the above tooling
isaiah has been working on an airflow
isaiah has been working on an airflow
isaiah has been working on an airflow
task management system for the pipeline
task management system for the pipeline
task management system for the pipeline
airflow is a task management system that
airflow is a task management system that
airflow is a task management system that
airbnb open sourced a few years ago
airbnb open sourced a few years ago
airbnb open sourced a few years ago
and honestly it's been great in our
and honestly it's been great in our
and honestly it's been great in our
experience at being able to orchestrate
experience at being able to orchestrate
experience at being able to orchestrate
a bunch of different smaller scripts
a bunch of different smaller scripts
a bunch of different smaller scripts
being able to say hey this failed and
being able to say hey this failed and
being able to say hey this failed and
giving a really nice ui
giving a really nice ui
giving a really nice ui
for engineers to go and just retry
for engineers to go and just retry
for engineers to go and just retry
different parts so this has the same
different parts so this has the same
different parts so this has the same
overall flow as before
overall flow as before
overall flow as before
it reads ledgers from Stellar core it
it reads ledgers from Stellar core it
it reads ledgers from Stellar core it
writes structured documents to google
writes structured documents to google
writes structured documents to google
cloud
cloud
cloud
and then it uses those as changes to the
and then it uses those as changes to the
and then it uses those as changes to the
bigquery tables
bigquery tables
bigquery tables
so this one is almost done it should be
so this one is almost done it should be
so this one is almost done it should be
done next week and the link to that
done next week and the link to that
done next week and the link to that
which is it's already open
which is it's already open
which is it's already open
source is on the slides as well
source is on the slides as well
source is on the slides as well
third going from private to soon public
third going from private to soon public
third going from private to soon public
visualization
visualization
visualization
we're thinking about displaying markets
we're thinking about displaying markets
we're thinking about displaying markets
and corridors in a public-facing site
and corridors in a public-facing site
and corridors in a public-facing site
like `stellar.org`
like `stellar.org`
like `stellar.org`
it'll make it easier for prospective
it'll make it easier for prospective
it'll make it easier for prospective
anchors to see what the volume looks
anchors to see what the volume looks
anchors to see what the volume looks
like in and out of specific businesses
like in and out of specific businesses
like in and out of specific businesses
and countries
and countries
and countries
we're just reasoning about the right
we're just reasoning about the right
we're just reasoning about the right
strategy in a way that meets both
strategy in a way that meets both
strategy in a way that meets both
internal and external needs
internal and external needs
internal and external needs
so once the new data system is stable
so once the new data system is stable
so once the new data system is stable
we're going to see how you can leverage
we're going to see how you can leverage
we're going to see how you can leverage
bigquery data warehousing
bigquery data warehousing
bigquery data warehousing
to build a scalable web application on
to build a scalable web application on
to build a scalable web application on
top of it it's its own engineering
top of it it's its own engineering
top of it it's its own engineering
challenge
challenge
challenge
because it's pretty hard to do that in a
because it's pretty hard to do that in a
because it's pretty hard to do that in a
time efficient way
time efficient way
time efficient way
but it's a really exciting one and I'm
but it's a really exciting one and I'm
but it's a really exciting one and I'm
excited to get cracking on it
fourth and finally data exploration is
fourth and finally data exploration is
painful so a data science platform is
painful so a data science platform is
painful so a data science platform is
very much tbd
very much tbd
very much tbd
if anybody in the community wants to
if anybody in the community wants to
if anybody in the community wants to
take this challenge on
take this challenge on
take this challenge on
I'm more than happy to see some
I'm more than happy to see some
I'm more than happy to see some
community implementation
community implementation
community implementation
and feel free to reach out to me with
and feel free to reach out to me with
and feel free to reach out to me with
either ideas or
either ideas or
either ideas or
a desire to try to figure out how to do
a desire to try to figure out how to do
a desire to try to figure out how to do
it I'm very happy to talk about it
it I'm very happy to talk about it
it I'm very happy to talk about it
so that's all for me I hope you really
so that's all for me I hope you really
so that's all for me I hope you really
enjoyed hearing about this pipeline and
enjoyed hearing about this pipeline and
enjoyed hearing about this pipeline and
all the stuff we've been doing
all the stuff we've been doing
all the stuff we've been doing
and I'm happy to answer any questions
so one question that's been asked are
so one question that's been asked are
there any cool projects using this data
there any cool projects using this data
there any cool projects using this data
set that you wish existed
set that you wish existed
set that you wish existed
so i'll start by plugging again the two
so i'll start by plugging again the two
so i'll start by plugging again the two
things that I just said
things that I just said
things that I just said
because I think they enable a lot of the
because I think they enable a lot of the
because I think they enable a lot of the
cool projects so for one I think it
cool projects so for one I think it
cool projects so for one I think it
should be really easy to see
should be really easy to see
should be really easy to see
here's what all the major anchors on
here's what all the major anchors on
here's what all the major anchors on
Stellar are doing and
Stellar are doing and
Stellar are doing and
it should be really easy to see what the
it should be really easy to see what the
it should be really easy to see what the
volume in and out of specific quarters
volume in and out of specific quarters
volume in and out of specific quarters
looks like
looks like
looks like
and it should be even easier to see what
and it should be even easier to see what
and it should be even easier to see what
the rates look like
the rates look like
the rates look like
I think the rates are really hard to be
I think the rates are really hard to be
I think the rates are really hard to be
able to do on this data set but really
able to do on this data set but really
able to do on this data set but really
powerful
powerful
powerful
so for example one of the reasons that
so for example one of the reasons that
so for example one of the reasons that
the
the
the
the euro t to naira corridor has been
the euro t to naira corridor has been
the euro t to naira corridor has been
killing it lately
killing it lately
killing it lately
has been because the rates for that are
has been because the rates for that are
has been because the rates for that are
so much better than what you would get
so much better than what you would get
so much better than what you would get
when you have really good rates on
when you have really good rates on
when you have really good rates on
Stellar it makes the whole network work
Stellar it makes the whole network work
Stellar it makes the whole network work
and I think that applications that
and I think that applications that
and I think that applications that
surface information like that like the
surface information like that like the
surface information like that like the
key killer applications of Stellar
key killer applications of Stellar
key killer applications of Stellar
are the most useful to leverage this
are the most useful to leverage this
are the most useful to leverage this
data set in the short term
data set in the short term
data set in the short term
longer term things that I think would be
longer term things that I think would be
longer term things that I think would be
cool that leveraged this data set
cool that leveraged this data set
cool that leveraged this data set
I think it could be really cool to
I think it could be really cool to
I think it could be really cool to
see how assets on the
see how assets on the
see how assets on the
decks itself can function as a hedge
decks itself can function as a hedge
decks itself can function as a hedge
against inflation
against inflation
against inflation
through sort of price histories over
through sort of price histories over
through sort of price histories over
time this is one of the things that
time this is one of the things that
time this is one of the things that
people talk about as a goal for crypto
people talk about as a goal for crypto
people talk about as a goal for crypto
and one of the things that with vibrant
and one of the things that with vibrant
and one of the things that with vibrant
sdf has started working on
sdf has started working on
sdf has started working on
and I think that if there were projects
and I think that if there were projects
and I think that if there were projects
that demonstrated that longitudinal
that demonstrated that longitudinal
that demonstrated that longitudinal
history it would be another really cool
history it would be another really cool
history it would be another really cool
value
value
value
for Stellar in the network
for Stellar in the network
for Stellar in the network
so another question what can a community
so another question what can a community
so another question what can a community
do to help expand Stellar
do to help expand Stellar
do to help expand Stellar
and improve it for those who do not
and improve it for those who do not
and improve it for those who do not
understand the engineering aspect of
understand the engineering aspect of
understand the engineering aspect of
that
that
that
so that's a good and interesting
so that's a good and interesting
so that's a good and interesting
question
question
question
I will say that you don't need to
I will say that you don't need to
I will say that you don't need to
understand the engineering aspect of
understand the engineering aspect of
understand the engineering aspect of
what I just talked about to use the data
what I just talked about to use the data
what I just talked about to use the data
set
set
set
that's one thing that we really tried to
that's one thing that we really tried to
that's one thing that we really tried to
make sure we could do which is just
make sure we could do which is just
make sure we could do which is just
being able to use some basic sql queries
being able to use some basic sql queries
being able to use some basic sql queries



and show some really powerful data what
and show some really powerful data what
and show some really powerful data what
can the community do to expand
can the community do to expand
can the community do to expand
on it lots of things but within the
on it lots of things but within the
on it lots of things but within the
scope of this talk
scope of this talk
scope of this talk
I would say that it looks like telling
I would say that it looks like telling
I would say that it looks like telling
people that hey Stellar is really cool
people that hey Stellar is really cool
people that hey Stellar is really cool
but then also showing them what the
but then also showing them what the
but then also showing them what the
volume on Stellar looks like
volume on Stellar looks like
volume on Stellar looks like
so this is one thing that i've thought a
so this is one thing that i've thought a
so this is one thing that i've thought a
lot over the course of the summer
lot over the course of the summer
lot over the course of the summer
when we've had a lot of volume on
when we've had a lot of volume on
when we've had a lot of volume on
ethereum with d5 right
ethereum with d5 right
ethereum with d5 right
how do you show similar volume with
how do you show similar volume with
how do you show similar volume with
Stellar because Stellar is one of the
Stellar because Stellar is one of the
Stellar because Stellar is one of the
few layer ones that can actually do
few layer ones that can actually do
few layer ones that can actually do
layer two things like that
layer two things like that
layer two things like that
so I think demonstrating that value like
so I think demonstrating that value like
so I think demonstrating that value like
that exists
that exists
that exists
and showing people that seller isn't
and showing people that seller isn't
and showing people that seller isn't
just a payments platform with xlm
just a payments platform with xlm
just a payments platform with xlm
there's all this other stuff you can do
there's all this other stuff you can do
there's all this other stuff you can do
on top of it I think that's one of the
on top of it I think that's one of the
on top of it I think that's one of the
things that becomes a lot easier
things that becomes a lot easier
things that becomes a lot easier
with really publicly queriable network
with really publicly queriable network
with really publicly queriable network
history it would be really cool for
history it would be really cool for
history it would be really cool for
community members
community members
community members
to promote it in a data-driven fashion
to promote it in a data-driven fashion
to promote it in a data-driven fashion
awesome so it looks like no more
awesome so it looks like no more
awesome so it looks like no more
questions so
questions so
questions so
last call if anyone has anything else
last call if anyone has anything else
last call if anyone has anything else
but
but
but
feel free to reach out to me either over
feel free to reach out to me either over
feel free to reach out to me either over
key base my key base username is devnet
key base my key base username is devnet
key base my key base username is devnet
nil or over twitter my twitter username
nil or over twitter my twitter username
nil or over twitter my twitter username
is debna sir
is debna sir
is debna sir
d-e-b-n-i-l-s-u-r I'm happy to
d-e-b-n-i-l-s-u-r I'm happy to
d-e-b-n-i-l-s-u-r I'm happy to
talk about things Stellar related as
talk about things Stellar related as
talk about things Stellar related as
well as waste lovers data set in the
well as waste lovers data set in the
well as waste lovers data set in the
community
