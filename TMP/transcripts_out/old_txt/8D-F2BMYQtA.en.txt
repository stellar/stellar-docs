hello everyone
welcome to the open protocol meeting
which is being live streamed and
for all of you watching at home I just
want to give a quick overview
the goal of these meetings is to talk
about and plan for changes to upcoming
versions of the Stellar protocol so
we go over core advancement proposals
aka caps
which are open source specs and they
describe new features designed to evolve
the protocol and meet ecosystem needs
and the cap life cycle begins with the
draft and today that's what we're
discussing
a draft specifically a draft of cap 21
which is titled generalized transaction
preconditions
this cap has actually been kicking
around for quite a while it was first
created in may of 2019 but with the
recent addition of claimable balances
which were introduced in protocol 15
there were some new possibilities that
opened up and this week david naziris
has been adapting the original proposal
with those claimable balances
possibilities
in mind so fair warning this is a
technical discussion so if you want to
follow along
I suggest reading the cap and the recent
developer
mailing list thread about it both of
which are linked to in the event
description
so I think you know just a sort of
quick overview of cap 21 it generalizes
the time balance field in transaction
to support other conditions including
conditions that relax sequence number
checking
and that provide relative time locks it
does that by extending account entry to
keep track
of the time and ledger number which an
account sequence number was last changed
it also replaces the time bounce field
of transaction with a union
that allows more general transaction
preconditions
so the goal is to advance network
scalability by facilitating off-chain
payment channels
and that's sort of like what we're
talking about today is this
are there questions that we can answer
will this cap help
create those payment channels it's
also to advance security and simplicity
and interoperability with other networks
by enabling relative time locks
and finally it should make it easier for
developers to create highly usable
products
by enabling time-delayed queue recovery
so today it's the first discussion of
this newly revised
cap so part of what we're trying to do
here is really just get like a sanity
check
before we start prototyping anything
does anything have anyone have anything
they want to want to add here at the top
yeah as well as insanity check I think
there's also so this one question is is
the overall approach saying and the
other question is
nico's raised some points
many of which are you know things one
could go either way on and so
it'd be nice to just kind of see what
the consensus is
for for where we should go
great I mean and since this is sort of
something that you've been working on do
you want to
start out with any any questions that
you might have or sort of pick a point
where you think the discussions will
start we can go from there yeah i
mean I think
thanks for I think your summary was
was pretty good here I mean I guess the
the things we could discuss are
one you know does this seem useful for
like a bunch of different scenarios
because if you have one mechanism that
supports like a bunch of different
things then that's good so i've got
four examples of things that you can do
with this
you know if people accept those
that's great if people have questions
it's also great if people have other
things like could it do this like I was
very grateful lee kind of suggested this
that you have a one-way payment channel
and maybe this isn't perfect but this is
but the fact that I was able to cook
something up
pretty quickly using this mechanism to
do something that
hadn't been one of the things we'd
anticipated was
you know an encouraging sign I would say
yeah and then the other thing is like
sort of nitpicky like technical
questions that we should get consensus
on
so where should we start application
like uses or
or just dive right into the nitpicky
questions
david can you give a high level overview
why these things are relevant for
payment channels ah okay good so
the the the kind of overall
architecture
of a lot of payment channels and a lot
of other
protocols frankly higher level
protocols on blockchains
involves kind of a two-phase thing
where you want someone to be able to
kind of recover unilaterally
from a failure if the other party goes
away or starts becoming non-cooperative
but you don't want people to do
something
invalid so there's kind of one phase
where you disclose that you're going to
do something
and then there's a certain amount of
time in which someone else can object
if you're doing something that's not
quite right like you're trying to for
example
close a payment channel with an old
closing state and there's a
more recent closing state but then if
nobody objects
then after that time delay you're you're
able to to close the channel so this
pattern of kind of disclose and then
finalize something is extremely
important in a number of contexts
and so
with without cap 21 it is possible
but but both extremely tricky to do
with Stellar
and you have to sort of pay a time
penalty and that things where like for
example when someone fails you might in
a payment channel you might lose access
to your funds for twice as long
because you cannot the only way to do it
is with kind of these
pairs of transactions that have
non-overlapping absolute times
in them essentially so we've we've
done stuff like this like
starlight a long time ago was was was
a proposal it uses it just gets
super complicated and so the idea here
is like let's just make it a let's just
provide as a primitive the thing you
actually want
which is kind of the ability to do
something after some relative
delay and since we already have this
notion of accounts and sequence numbers
it seems like and since sequence
numbers are extremely useful for sort of
invalidating a bunch of stale
transactions you can just kind of give
them successive sequence numbers
it seems like the simplest way to
address this is to just
have a a transaction precondition says
you can do this transaction but only
when the account has been idled for a
certain amount of time
therefore if the attack count gets
changed when someone discloses that they
want to do something
you have to wait that amount of time
before they can actually do the thing
and in that time
somebody else can object by you know
raising the sequence number further and
invalidating whatever you were going to
do to close the transaction
so so that's kind of what what what led
to this
the proposal so it might be worth
mentioning that
the bitcoin protocol has relative
time locks
they added it specifically for enabling
the lightning
network just as a reference
but it seems that david like you were
talking about relative time locks but
your
proposal is actually much bigger than
that and also includes some some
sequence number changes and maybe you
can talk a bit about that and why that's
relevant
yeah so
so the
the sigma summer changes are because we
have
basically it's our sequence
sequence numbers are extremely brittle
and hard to use
right in in protocols because basically
you have to have you have to know the
exact sequence number in order for
for a transaction to run so so for
example
one consequence of this is that
in a you know if we don't have cap 21
and you're implementing payment channels
the kind of disclosure disclosure
transaction that sets you up to to close
a payment channel
needs to be signed on multiple source
accounts you need multiple versions of
it because
you know if you submit yours
but you submit the wrong one then i
still need to submit one
and so and so it needs to be on a
different source account because you've
already burned the sequence number of
yours
another example is you want to set it
like a pre-signed
transaction that will that you
can kind of submit at any time to do
something like clean up some
mess or something and again the
account
that's only valid if the count is like
in a particular sequence number and so
without I think overly complicating
things I added a feature where
you can optionally for an account say by
the way this transaction is valid
for a range of sequence numbers so
whenever you execute a transaction you
always leave the account state
the the the invariant is the
transaction is only valid
when the sequence number of the
transaction is
greater than the sequence number of the
account and after you've executed
a transaction the sequence number of the
account is always the sequence number
the transaction you just
executed until now it's always been the
case that
it also that the sequence number the
account has to be exactly one
less than the sequence number of the
transaction in order for the transaction
to be valid
with this new optional feature you can
add a different
a minimum sequence number so you can say
actually I want this transaction to be
valid
for any sequence number below the
sequence number of the transaction or
for you know the last hundred sequence
numbers
and so this makes transactions that
you've kind of signed ahead of time a
lot less brittle
the particular you know particular
example of where
where I use this well actually it seems
to come up in in
actually all of the the proposed
applications so in payment channels
it's useful because I can submit a
disclosure transaction and if it's the
wrong one you can submit a disclosure
transaction and they can both just be on
the escrow account
we didn't need to have our special other
accounts just for the sequence number
because
you know an earlier disclosure
transaction doesn't invalidate a later
one because the disclosure transactions
are signed
to accept a range of sequence numbers
you know another place where this
might come up is
where you have you want to be submitting
large
numbers of transactions on one account
you have like a farm of 100 servers that
are all like you know each
each round they're kind of submitting
a transaction
on on the same source account and using
the new feature you can accept gaps in
the in the sequence number space so if
like one
server happens to be down or not
produce a
assigned transaction time that's okay
you can just skip over its transaction
another example that I had was
was recovering like if you want a
friend to be able to help you recover
your account in case you lose your keys
you know you want to pre-sign a
transaction that you give to them
that they can just submit and will
will add their signing key to your
account but of course
you don't want them to be able to do
that immediately you want to have some
chance to object in case somebody
like steals their key and so again you
want
one transaction you can just submit that
will bump this disclose that this is
going to happen and bump the sequence
number all the way up to the point where
your friend can take over the account
and then a second transaction with a
relative time lock that allows your
friend after a few days or whatever to
take over
that account and help you regain access
to your funds
one thing that I wanted to can you guys
hear me
yes excellent one thing that I wanted to

to kind of ask about was how you
anticipate this interrupt
excuse me interacting with claimable
balance ids
which are sequence number dependent is
the anticipation that
when you do one of these range
bounded
transactions on the sequence number that
the sequence number is bumped to the
last sequence number prior
to submission like prior to the
operations being applied so that
no matter where you were applied in the
range the
any claimable balance generated would
always be generated using an id that is
equal to the actual sequence number
of the transaction so there should be no
change the the the definition
of the operation id
still applies unchanged in the sense
that every transaction still has a
sequence number
the only thing we're changing and always
leaves the account with that sequence
number when it's finished executing
the difference is simply that the
transaction may be valid
even if a transaction with the prior
sequence numbers have not executed yet
so just to make sure I'm 100 on the same
page as you if the sequence number
bounds were minimum one maximum three
whether I played the transaction at
sequence number one two or three
the claimable balance would always be
created as if it was ab sequence number
three
I think what you're saying is
technically correct but
that's not maybe not the clearest way to
view it so I just view it as there's no
maximum sequence number there's just a
sequence number
which is just the sequence number of
your transaction
and then there's a minimum sequence
number that says when your transaction
starts being valid
and the minimum sequence number by
default if you don't specify it is just
one less than the sequence number of the
transaction meaning like every
transaction
can be submitted at exactly one sequence
number but you can
you can reduce that minimum sequence
number
down to all the way down to zero if you
want the reason I'm kind of asking about
it and asking about it specifically in
this way is that the the language you
keep using is that
when the transaction finishes executing
you will be at blah blah blah sequence
number
yeah but I actually think that the
phrase you want to use is when the
operation start executing you will be at
blah blah sequence number
because otherwise it's quite ambiguous
about which sequence number you're at
when you're actually doing these
operations and also it's quite ambiguous
what it means to a bump sequence
okay so let me actually address so
there's several points so
I so the way I was viewing it is that
the
the the operation id
in a claimable balance is depends on the
actual sequence number of the
transaction not the sequence number of
the account
and the reason is that I was assuming
that you kind of
execute transactions in two phases one
in one phase you kind of
claim all the fees and and bump all the
sequence and address those sequence
numbers and you know validate the
sequence numbers
and then in a second phase you do all
the operations including things like
bump sequence
but it is currently the case that for
example
you could you could submit two
transactions
in the same block right and
depending on the order in which they
actually one of them could like bump
sequence to invalidate the other right
if they have different transaction level
source accounts and so
that behavior is sort of unchanged
in that like all the validation and
checking whatever is still
all happening before bump sequence
but regardless of bump sequence when
you're generating a so forget cap 21
when you're generating an operation id
it's still based on the sequence number
of the transaction not the sequence
number of the account in the sense that
if you have a bump transaction
that's not going to affect the operation
ids right I'm actually
I'm actually trying to confirm that
right now I was under the impression
that it was based off of the actual
sequence number of the
account at the time that it executes so
that would make it difficult to predict
the the operation ids which i
think
might be a a problem with claimable
balances if it's the case so that might
be something
independent of cap 21 that we might want
to revisit
regardless right maybe it's not it's
it's not because you don't know the
order in which transactions on different
source accounts are going to execute in
the same block so
you could have a situation where you you
have a you have a transaction it you
know
it it creates some claimable balances
and then because some other
transaction happened to call bump
sequence
that the claimable balances have a
different op id that would be
oh but no no no we no no like the
sequence numbers are strictly
like they are enforced at the time we
apply the transaction
yeah david is right though actually it
comes from the transaction sequence
number
not from the account sequence number and
so given that that's the case
cap 21 doesn't change that that then it
doesn't every every transaction
still has a unique sequence number it's
just we're now we're now can
skip some sequence numbers we're a
little bit more flexible at when a
transaction runs
I have kind of a basic question which is
what was the original rationale for
sequence numbers replay prevention
because we don't have
utxos we need to
we just need to make sure that like a
valid transaction cannot be submitted
multiple times to you know double the
payments
the reason the reason I'm asking is
because I could foresee that if this is
a
feature for convenience
maybe many people would use this feature
so they don't have to think about
sequence numbers
and although that's like a choice that
they've made maybe this actually makes
their implementation less secure
well no they still need to think about
it it's still it still prevents replay
but
one thing that this allows for example
is that let's say that you have a fairly
low
volume you know account where you're
not doing a lot of payments you could
decide
that rather than query for
the the latest sequence number the
account
you could just kind of use the the like
the unix time
epoch as like the low 32 bits of your
sequence number right and and now
if you set your minimum sequence to zero
that that would just
work obviously you would it would not
work
you would like get some transactions
rejected if you happen to
on two different machines use the
generate transactions at exactly the
same time and use the same sequence
number but if that's unlikely to happen
then
maybe that's a that's a better trade-off
in some situations and we would allow
that
and just following up on just to make
sure it's super clear to you eric like
this wouldn't let you ignore sequence
numbers imagine that you wanted to be
like hey you know I'm gonna set the
minimum
number to one and the maximum number to
n64 max that's not going to cause any
problems but again there's no match I'm
not going to work
there's no maximum number exactly please
don't use the term maximum number
it's going to take you straight to in
64 max you can do this one time and now
you're a count stock
I suppose we could we should actually
do the
maybe we should add the limitation the
same way bump sequence doesn't let you
bump to n64 max right because we have
some idea that we want to be able to
delete the account and then
recreate it and and not have old
transactions be valid
it does let you bump into 64 max
actually it just stuck
at that point and then you're just stuck
you need to use another okay because we
can't delete the account okay so great
so fine we can just allow to have the
same thing then
yeah so so is one way to think about
this that it's a bit like a
normal transaction with a bump sequence

built into it yeah but but with a slight
advantage that the bump sequence
happens later in the
processing of a block and this
happens
earlier during the initial phase of like
collecting fees and validating
transactions but yeah it acts a lot
like an implicit
like basically you're you're implicitly
your sequence number is implicitly a
bump sequence now
so where there are also you know i
believe on the Stellar dev mailing list
there were some specific technical
issues
that niko raised and I want to make
sure that we do
if they're important that we do have
time to get to them does it seem like
time to move on to those are there still
more sort of high level or general
questions
let's get specific okay so so the
first one is that
I mean this is something I feel
strongly about but it's not the hill
that I want
cap 21 to die on so
maybe we end up just deferring this
to some some leader cap but
the way we do extensions for unions by
kind of
kind of dangling more and more nested
structures off the nested unions off the
end of a structure
is kind of messy and gross and it seems
like the reason we're doing this
is just because we're like we don't
have
enough like engineering resources to
kind of fix each individual
sdk in a way that like frankly wouldn't
be that hard if we had someone who is
like living and breathing that
that sdk so
so I you know I think it's it's much
better to do
your have your extensions to unions
be kind of like
having like an outer union so you can
just kind of keep improving the data
structure
and you know keep most of the fields the
same as opposed to having like many many
nested unions which is both
you know encodes in a more it takes
more bytes to encode and is like
more of a pain to program to because you
have all these nested unions
so I'm suggesting that the account entry
extension that we replace
the thing that's currently a v2 dangling
off of v1
with with just a
a v3 that that has everything in it
and this isn't even like transaction
state right this is like ledger state so
like
but by the time you talk talking about
software that's actually parsing these
like ledger entries like we're already
in like
pretty advanced software and not like
random end users who were like
doing xdr parsing on the
on the actual blockchain state as
opposed to transactions
I mean I think the by the way this
was the last
thing on the list I think in terms of
priorities I don't know why we're
spending
time yeah so again right now I mean we
can't
okay why don't we defer this to the end
then
so the next next question
is that and this is kind of a more
general
point but it's like coming up here too
we have we're using a combination
of signed and unsigned integers
for durations and time points and it
would be super nice if we could kind of
unify that across everything
and so my proposal so I don't
I don't have a strong opinion on
which because 62 to the 64 or 2 to 63
are both very large numbers of seconds
john has suggested that it's useful
to
you know do queries in sql and that sql
doesn't have
good support for unsigned 64-bit
entities not just sql it's also
no other languages sure so
so what we could do is change time
point to be
assigned 64-bit integer have duration be
assigned 64-bit integer
and we would just say that any time
bounds that
is negative is just treated as
like you know n64 max basically for
backwards compatibility and I doubt any
why would anyone
nobody is going to care about if they've
already signed a transaction whether the
time bounds is like 2 to the 63 or 2 to
the 64 seconds from the epic right
I mean I think a priori I think that
sounds fine to me i'd have to
just look carefully through everything
and make sure that it
doesn't break anything terribly I mean
but a priori
I agree like nobody cares if something's
gonna happen in 2200 or I don't know
two to the 64 must put you into like the
30 000 or something I don't know
something like that
no I mean it's got to be much more than
that because 32 bits already gets us to
like
20 30 something right so 16. yeah no
yeah you're totally right you know
he death of the universe kind of thing
like
I think we got bigger problems to worry
about at that point in time
like yeah even changing crypto yeah
yeah exactly I think my problem said 25
deep by that point
okay so for that one is that is that
where we're landing it sounds a priori
okay but like we should go to sign
64-bit
and we just have to be a little careful
about legacy you know do it in a way
that doesn't
mess up legacy transactions

okay so another question so
someone so again you know I just like
doing things
nice and simple and figure we already
have unions like we've already got
two kinds of precondition now no
precondition
time bounds and then these like
general preconditions so if we want to
add more stuff we could just add a new
kind of
precondition you know
but an alternative would be to kind of
turn this into a little language
like like the claimable balance
preconditions and you know having like
an array of different
things you know
again the proposal could work either
way
I like this way because it's simpler
but if
there's overwhelming desire to go the
other way
we can do that as well
I guess one concern you can go first
nico I was just waiting to see if
anybody wanted to go first
yeah I know I was like thinking that if
we just do this pattern right without
the array I think it would just end up
growing if we add more as we add more
condition even actually with the current
version
like you always use like the worst
almost like max
max maximum size bikewise
that doesn't seem like a you know
a good property I think in terms of
complexities
you know we can make it that it's
actually fairly simple like I would say
like you know
the array has to be strictly ordered by
you know value for example right like
you cannot put like
that's where you have like a normalized
form right you can't
you have to put for example time bomb
before
sequence number right things like
that
and if you did that could you expand
the the possibilities
yeah that's it yeah I mean this thing is
like 20 bytes right if it's not
if it's not doing anything so let's
see there's one there's one
two three four yeah five things so like
20 bytes
I don't know 24 because the direct
duration is like 64 bits
but I mean I mean especially for
things like
yeah I don't know I mean I can make it
work the other way it'll be
it'll be like you know more complicated
to implement everywhere
there'll be like more weird edge
conditions
you know I think that in the end
maybe you'll shave you know
eight or 12 bytes off the size of some
preconditions and others will be
larger and you know maybe like four
bytes bigger or the same
to me I don't know like
to me it's like the you know it's called
generalized but it's not generalized
type of thing you know it's kind of
you know we want it to be generalized
like a place where we can add more and
more conditions and then
what if I called it something less
arrogant than general preconditions
like you know relatives or
relative general preconditions v1 or
something I guess you yeah you ask for
it because
it's like when people call the function
you're smart something you know it's not
smart right
but no no no I'm I'm just saying like

I don't necessarily think it's it's a
name problem
I think it's more of a yeah the pattern
like what what is the pattern that we
want to have here and i
I can see that fairly
you know maybe not in the in the far
future
we'll have like yeah like some new
conditions that pop up and
do I want to again like
you know have like it's it goes back
I guess to this other point about half
the weekend
yeah fractures right how much pain do
you want to have
in the yeah and I guess here I just i
don't
I don't agree that the pain needs to be
very very high I just think there's a
there's a there's like a kind of a bug
in our ecosystem that we make these
union upgrades more painful than
than they should be part
for me kind of what I'm looking at here
is if we think
that this is a pretty reasonable
representation of all the things we'll
need in the near future like near future
being like
let's call it the next year I mean we
lived with just sequence
with just time bounds and single
sequence numbers for like
I don't know much longer than that five
years I guess
so if we think we're gonna make it that
kind of length I don't feel any need to
go
super crazy making this complex and
extensible
but I remember seeing I don't know maybe
it was in the actual proposal maybe it
was in the notes for this meeting i
don't remember which
discussion about whether we should be
like implicitly elevating
and which is the way that it's currently
written you need to meet
all the preconditions versus or
if we do something like if we care
about or
then probably it warrants something more
complicated but I think that or
also might might
might put you into people not being able
to understand what they mean
yeah I mean you're certain like foot
guns and stuff like I mean like
you know first of all I actually haven't
yet come up with a
an example where or you need
or that's not to say they don't exist
and I would appreciate people speaking
up if they have any such examples
you can also do or by just signing
multiple transactions
yeah that's not impossible
so I would really like to I mean
especially because I think like to the
extent we want
to go crazy we can do that with
claimable balances
right like we already have a little or
or we should like try to unify the
languages right like which is somehow
make
like have a notion of precondition that
can apply to both clinical balances and
regular accounts and stuff and once we
start doing this I'm just seeing this
thing like spiral
out of control and I think it's like
we're not like
saying we can never do this like we can
have like a you know
a new we can add a new thing to the
union like when when we decide this is
this is done but like look like you know
I just let's just
try to be good and not perfect for this
because
like what we have here is just simple
it's easy to understand
I think it's not going to be too bad to
implement
and I think it will be already enabled
like a huge number of use cases
you know I mean as oleg was pointing out
this morning like in order to make
lightning really work on
on bitcoin they had to go through like
four different soft forks or something
so like maybe it's not perfect and
maybe we'll want to make other changes
but
we have that ability because we have we
have unions so
I think this claimable balance point is
worth talking about for two minutes
though I mean do we think we're going to
be
wanting to add this kind of thing to
claimable balances
I'm asking because I'm feeling the pain
of clinical balances in horizon right
now and how
we wish we'd made the ids more general
because we built everything around
accounts but it turns out clingable
balances have similar
properties to occur I mean the the thing
that the the predicates on
climate balances have is that they
don't they they're less monotonic
than this stuff so kind of intentionally
like things like duration and
and like sorry min seek age and and
min secret ledger gap and stuff
they they have a monotonic property that
they'll you know like once they're valid
they'll
they'll stay valid right there's still a
maximum time bounds because we're not
going to get and
get rid of that in the ledger bounds but
and I think that that
that monotonicity makes it a lot
easier to reason about like when you're
sort of forwarding
multiple transactions on the same
source account you know whether they
can all be in the same block
you know we don't want to have
situations where someone can kind of
waste a bunch of bandwidth by causing
validators to forward around invalid
transactions and things like that and so
the monotonicity
helps with that as well you know once
you start adding in not in all these
other
operators that you no longer have that
and it just gets more complicated to
reason about these things
nico and john any pitfalls that you
see in in
implementing this whether it's a an sdf
team or someone in the ecosystem trying
to prototype this and still a core
for which part the the condition like
the
I guess the only
thing I thought so so in terms of like
the captain itself
like at apply time I don't think
there are like real
problems from what I see like they are i
mean it's a fairly simple change
actually
I'm still kind of
trying to kind of really
wrap my head around like the
like the
the coupling I guess in in some of those
things like the
like does that only work basically in
for example like they are like the
limitations on the flooding that
david added last night that I read
this morning
in particular the the ones that are
related to
relative timelocks themselves I think
this
really only works if you basically do
like the same type of setup or you have
like two
transactions where one kind of allows
you to
to gate the disclosure and then the
actual right you always have to do this
right it's kind of and in a way it kind
of bothers me a little bit that
you know we have those constructs and
they don't work independently I mean
like all one actually requires the other
one
and I don't know it kind of sorry but
that's the point right you want that you
want to do you want to have to
performing the action should require the
disclosure right you know I understand
but it's
in terms of the construct like you
have this construct that cannot be used
outside of of the
the combination right like normally we
try to make things that
like for example the sequence number
thing that can be used in
any other source of context right the
other one
the relative condition
has to be used with sequence numbers
like I mean like actually
like other transactions actually it has
to be paired with some other scheme
otherwise it's a food gun right like
like
people will not realize maybe that the
you know it's actually a fairly subtle
thing right that
you it you know if some evil
person is is constantly kind of
pushing transactions in front of you
then your relative
time kind of keeps moving but it's
always you know
not where you want it to be right
and you're in in the it's not it's like
you have to use it I mean there are
other patterns where you could use it
right you can imagine
you know if my account is idle for a
year I want
you know my family members to be able to
like
access the the funds or something
right so you could just
you could do it as a kind of a a trigger
for for idleness
so it doesn't have to it doesn't have
to be for that but it seems like the
the most most of the cases do involve
this this pattern
of disclose and then act
but I mean I think it's kind of
a very useful pattern right so it is
something
no the pattern is useful what I'm saying
is more like
like I guess you gave an example that
where I mean this is useful in a context
so we
you don't pre-sign many transactions and
maybe that's okay
right I don't know I mean maybe so
actually
I thought I understood your point but
now I'm actually confused so I thought
that your pro your problem was like well
it's kind of inefficient because it like
prevents you from pipelining
back-to-back
transactions or something but
it's it was not an efficiency
question it was more of a
like a potential attack right like
you pre-signed a bunch of transactions
and then you expect
the that last one to just work but you
don't realize that maybe
there are ways to touch the account
basically
because you have all like an example of
a payment channel right like you can
imagine that

you can actually if there was no if
if the sequence number was not working
in a way that it would
remove
all transactions you would end up in
situations
in a situation where
the timestamp would keep moving from all
transactions right so you end up
invalidating
basically your latest one and that's not
the one you
you want to invalidate right we're not
invalidating you're just
delaying it like you sort of you're
worried about something like a live lock
situation
where yeah someone has low signing
threshold on the account and so they
keep
you know exactly like this kind of stuff
right yeah I don't know
from my perspective on this it's kind of
like if you're doing pre-signed
transactions like
you better know what you're doing or
you're probably going to screw yourself
up no matter what the pitfall is
but you can imagine a day where say
someone provides a service that does
pre-signed transactions
right where where some of that
difficulty would be
concealed but I still think that you
know like cap 21 is only going to make
that less error-prone
right because of the fact that you
sequence something less brittle so
I mean you know there are
things you can do that are would be
weird with this
but but they would be weird anyway
I mean like you could have a
situation where like someone has low
signing threshold in the account and
they keep
you know bumping a sequence number and
so my my idol thing
you so my idol condition never kicks
in and I can't execute this but they
could also
use bump sequence to bump the sequence
number to
you know max 64 and lock the account
too right so it's kind of like
you're already giving someone the power
to shoot you in the head and then
don't you know I guess be happy if they
only shoot you in the foot instead of
the head or something but
so can we just kind of accept that yes
there there are ways to I mean
yeah it was more of a yeah like
like I said like a a concern that
we are adding more complicated things
that you have to know to use
exactly right otherwise you know I mean
I guess maybe that's what
john is saying like you know those are
to be used only if you
really understand what you're doing and
you know in a way like I think
like when I when I see the
the actual payment channel protocol is
actually super easy to understand like
you can
you know like it takes five minutes to
actually get it right like and you know
it's correct
unlike you know like previous
attempts so you know
to me this is like the big win
tomer had asked about you know
implementation challenges and i
I agree with nikola that the apply time
part of it should be like
super easy I mean a couple new if
conditions a couple of
fields to update but like there's not
really any logic here so it's
I think it's actually probably the
forwarding logic so there's two
places where that's what I was going to
say dude
and the forwarding logic is like a
little bit more complicated but I think
you know after I kind of thought it
through and wrote that new section last
night which
yeah by the way thank you nico for
pointing that out should have been in
the
first version of this I think it's
not too bad
I think like the main challenge will
just be you know
the the forwarding logic is already
complicated like there's lots and lots
of
conditions on conditions on conditions
and the main new challenge here is just
the additional
bookkeeping burden of things that used
to not be possible for example like you
receive a
trans transaction that's like signum
three to seven or minsek three seek
number seven as david would prefer me
prefer I specify it and then the next
thing you receive is
min seek four sequinum six and now you
can actually add that to the queue and
so it's all about like do our data
structures allow us to do these things
efficiently
yes no I'm not sure probably not
actually right now
so we'll probably have to redesign
that stuff to make those things fast
but like it's probably within the
realm of
doable just the type of thing that
we'll have to do a kind of detailed
study of like what do we actually have
to do before we touch anything
lots of positive feedback here
yeah this is exciting
okay so in terms of my to-do things
that I should revise here
it sounds like well I guess we
never really resolve the union thing
if if I don't it sounds like if i
don't want to
I don't want to predicate this in an
argument about like unions and ledger
state I should just dangle
the extension v3 off of v2
which is my favorite but whatever i'll
just do that if I have to
sounds like there is consensus that
we should have a duration
and time that we should have duration
and time point types that these should
be signed throughout
and so I can change that in this cap
and then it sounds like there's also
kind of reasonable consensus that it's
okay
to stick with just one big structure
with all the preconditions as opposed to
trying to build a little language like
for claimable balances
and does it make sense for instance john
you know you were saying that
you would need to to do a detailed study
to figure out if the data structure
would allow us to do these things
efficiently does it make sense to also
start doing that or is that something
that should happen
post these revisions
yeah I mean our general goal is to
try to do more stuff in parallel than we
used to so we can go faster
we have a lot of stuff to do so i
don't know when that's going to get onto
our schedule
david my guess is david will beat us
but in theory we we can start that
whenever at this point I would say
maybe nikola descents but I there's
nothing blocking us from doing that and
we've we've been doing a lot of work on
that code recently so it's very fresh in
our mind so it actually could be a
a pretty good time to do it
are not mandatory to to write kind of
like a
you know like a quick dirty perhaps
dirty prototype
and obviously if we accept
cap 21 in the future and and you know
merge changes
you know we'll need to optimize but we
can think about it let's do that first
cool
this this cap is premised on the idea
that it actually solves payment channels
though right
so we add another solution to payment
channels we'd have to revisit whether
this is something we want to do
or or if I mean we do have other
solutions they just have undesirable
properties right so this was the
best solution for payment channels it
would go ahead but if it wasn't then i
guess we'd re-evaluate whether it was
still worth doing is that right
yeah I mean or or we would do that we
would tweak this because
probably it seems unlikely that a good
solution for payment channels
would not involve some kind of relative
time lock it just could be that there's
some other feature we need to add or
something
or there's some small tweak that we
need here
so yeah definitely feedback
challenges like
you know again it was great like lee
came up with this idea of you know
the one-way payment channels with
different trade-offs and so yeah so
maybe i'll keep thinking about that
too see if see if we can push on that to
do like top-ups and stuff
in there yeah I think
what I imagine actually is that there
might be more work to do
as people think in more detail about
the closing like what really happens
when you close the payment
payment channel like I know in the
past a lot of the complexity
in the in the starlight
implementation was that
balances well we didn't have claimable
balances
and
and then you have like yeah all the
things that can fail and then you know
there's no way to retry
and then you're kind of stuck
and yeah like thinking about
yeah like how to ensure that things
are safe even if you go beyond the one
transaction right like
because in this case you have this one
transaction I mean I think it
probably works if nothing fails if
everything is claimed our claimable
balances but that's kind of you know
we'll know as we
actually go a little further yeah I mean
the major major pain point was that
like paying out to the responder
could actually fail and so therefore you
had to make sure that
like you know it was a separate
transaction from like restoring the
account
and now the claimable balances can't
fail
it's like it's fantastic right it's just
you can do everything and just like one
transaction that like fixes the thing
yeah what I'm saying is more like the
limit right there's a limit of 100
operations
in a in one transaction so are there
cases where you have to go beyond that
and if so is it just a matter of like
right now you do two times I maybe it's
like three times I is that all there is
to it I don't know saying like
yeah a payment channel with like 100
assets in it or something
that that would be interesting i
think we actually could do well
yeah or like it depends if you do like
multi-parties you know more than two
parties like
you know all this stuff right yeah so
yeah and I actually think all that will
work but I could
if you'd like I could add a section on a
like a a
multi-party multi-asset channel that
needs to span
more than one trans closing transaction
yeah I mean there's really no reason you
can't just have
multiple closing transactions with just
kind of successive sequence numbers
as long as they never fail right that's
kind of the
thing no no they can fail actually
because because it still consumes a
sequence number they can't be invalid
but they can fail right so if it turns
out you'd rather pay out with an
with an actual payment instead of a
create clinical balance
you can still do that it's just now
you have to consider the fact that that
transaction could fail therefore you
can't pay out to multiple users in the
same transaction you just have to have
multiple closing transactions yeah and
then you have like the whole like
what do you do with the leftover at the
end and yeah you know the leftover at
the end is you just
the initiator gets control of the
account yeah but like that's you know
I guess that's one decision you have to
make
on that front which is because we don't
have a way to
like the only thing we can do is
basically
leave it leave full control at the end
of the leftover to like a given party
you know which I think you want
anyway because someone had to like put
up the
base reserve and stuff for that account
so why not let them just get control
it's also it has this other advantage
that it lets the initiator
unilaterally top up right that you
don't have to like do some complicated
protocol to top up like
the initiator can just kind of throw
more funds in there and then it can
either spend those or
it'll get them back automatically when
it when it closes the channel
leigh are you raising your hand
yeah I have a question back on so i
think I think we're getting in the
details of like
the specific payment channel
implementation but I just had a
thought on
something that you were raising nico
about
you know the foot gun of just that min
sequence age
and I'm wondering if like one of the
early
proposals I think david that you shared
attempted to use claimant balances
as like the relative timeline so as
opposed to having the relative time lock
in the account
it existed out in this external thing
somewhere else in the ledger
and I think that has some like
undesirable
properties that you know we wouldn't
want to do that with claimable balances
but
is is it worthless exploring that
idea of having relative time locks being
like
like a very simple small thing on the
ledger
they get created outside of the account

and we can define things like when
they expire
and therefore transactions yeah
so actually the this I you know i
think we could still make
payment channels work if we got rid of
the min sequence number
but actually it would have more foot
guns right I actually think the min
sequence number
is there to reduce foot guns and to make
a lot of things
simpler by making sequence numbers less
brittle
I'm also interested in lee's question
though it's something i've been
wondering this whole conversation
like are there things that we can do
beyond changing the account state that
might be more powerful
than just changing the underlying
account state like you know recording
some other state or
you know transmuting claimable
balances on a transaction
exactly I was actually referring to the
sequence age so I was actually meaning
like move that out of the account
into like some you know you create a
lock and that lock is
automatically locked for like a specific
age or something like that
okay so I mean I can tell you a couple
things you could do but
they're all going to be more
complicated so one thing you could do is
you could somehow guarantee that
a claim claimable balance will never
be
valid and fail right so then you could
kind of
use a claimable balances as a kind of
synchronization primitive and be
guaranteed that you're not accidentally
going to burn
a sequence number another thing that you
could do
is you could add a replay cache to each
account so you can have a new kind of
transaction
that instead of instead of
altering the sequence number it like
adds itself to the replay cache for
which you have to pay
you know a base reserve and then
the transactions would get you know
garbage collected from the replay cache
based on their
their max time or maybe based on like
bumping the sequence number
this starts getting complicated because
you don't want a single transaction to
be able to kind of delete a million
things from the database just because
then that would be like an expensive
transaction so you'd have to kind of
limit the per account number of entries
in the replay cache or somehow ensure
that they can't all be deleted at once
or
have some other operation that deletes
like only up to 100
things from your replay cache that
are stale
so that that again would that that
would simplify things because
again you could kind of submit
transactions it would be more a little
bit more general and useful than this
because now you wouldn't even have to
worry about
the relative sequence of these
transactions you could have two
transactions on the same source account
that could be submitted in either order
and they would both be allowed to to
execute
so I'm happy to
to cook up a proposal along this lines
of a replay cache
and I think it would be have some nice
usability properties
I think it would be much harder to
implement and I think it would end up
having some annoying warts owing to the
fact that
we want to bound the amount of work
that any single transaction
can cause validators to do so there's
either gonna be like
limits the replay cash or limits to how
quickly it gets garbage collected
leigh do you have more to say I say
you're still unmuted
i'll leave okay on the replay topic i
I have tons of ideas about this david if
you want to talk about it that I want to
talk about in this context
I actually drafted like a short proposal
somewhere
about this that you could do this in
a in a very like no storage kind of way
on the ledger
and still have no undesirable replay
things
we could talk about it offline if you
want to okay
would it would it is it was your
proposal good enough that we should
consider
instead of min sequence number or talk
about that
no it's kind of orthogonal to min
sequence number it's
it avoids other kinds of problems but it
doesn't fix those problems so
but it does allow you to submit
transactions without changing the
sequence number
it does okay yeah let's talk about
flying about that cool
and I think we're pretty much out of
time I mean I don't know if if there's
anything anyone wants to say just at the
end here but it sounds like there's some
pretty clear
next steps any final
parting words parting shots clever jokes
awesome everyone well thank you for
coming into everyone who's watching
thank you for watching this was
a nice deep technical dive into cap 21
and
more to come on there if you want to
know what's going on you can always
join the Stellar death mailing list and
you can also look at the github repo and
look at the actual
drafts for these kinds of proposals
and I appreciate
everyone here for joining in the
conversation thanks so much
you
