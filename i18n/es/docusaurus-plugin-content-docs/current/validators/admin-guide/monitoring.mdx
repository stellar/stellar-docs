---
title: Monitoreo
sidebar_position: 80
---

import { Alert } from "@site/src/components/Alert";

Una vez que el nodo está activo y en ejecución, es importante vigilarlo para asegurarse de que se mantiene a flote y sigue contribuyendo a la salud de la red general. Para ayudarlo, Stellar Core expone información vital que puede utilizar para monitorear su nodo y diagnosticar problemas potenciales.

Puede acceder a esta información usando comandos e inspeccionar la salida de Stellar Core. La primera mitad de esta página cubrirá este enfoque. También puede conectar [Prometheus](#using-prometheus) para facilitar el monitoreo, combinarlo con [Alertmanager](#configure-notifications-using-alertmanager) para automatizar la notificación, y utilice [Tableros de Grafana](#visualize-metrics-using-grafana) preconstruidos para crear representaciones visuales del bienestar de su nodo.

<Alert>

[**Stellarbeat**](https://www.stellarbeat.io), un panel de monitorización de gestión comunitaria, también puede ser útil para ver la salud de la red en su conjunto. Deberías vigilar muy de cerca tu(s) nodo(s) usando algunas de las herramientas sugeridas en esta página, pero la supervisión del rendimiento de todos los nodos de la red también puede ser útil para entender cómo todos interactúan entre sí.

</Alert>

Sin embargo usted decide monitor, lo más importante es que usted tiene un sistema en marcha para asegurar que su integración siga funcionando.

## Información general del nodo

Si ejecutas `$ stellar-core http-command 'info'`, la salida se verá algo así:

```json
{
  "info": {
    "build": "v20.4. ",
    "ledger": {
      "age": 0,
      "baseFee": 100,
      "baseReserve": 100000000,
      "closeTime": 0,
      "hash": "39c2a3cd4141b2853e70d84601faa44744660334b48f3228e0309342e3f4eb48",
      "maxTxSetSize": 100,
      "num": 1,
      "versión": 0
    },
    "red": "Public Global Stellar Network ; Septiembre de 2015",
    "peers": {
      "autenticated_count": 8,
      "pendiente_count": 2
    },
    "protocol_version": 20,
    "quorum": {
      "node": "GCRQF",
      "qset": {
        "agree": 22,
        "cost": 37256128,
        "retrasado": 0,
        "en desacuerdo": 0,
        "fail_at": 6,
        "hash": "5c464e",
        "lag_ms": 1942,
        "ledger": 51251628,
        "desaparecido": 1,
        "fase": "EXTERNALIZE"
      },
      "transitive": {
        "critical": null,
        "intersección": verdadero,
        "last_check_ledger": 51251539,
        "node_count": 24
      }
    },
    "startedOn": "2024-04-15T16:16:25Z",
    "state": "catch up",
    "status": "Synced!
  }
}
```

Algunos campos notables de este punto final 'info' son:

- `build`: el número de compilación para esta instancia de Stellar Core
- `ledger`: una representación del estado local de tu nodo, que puede ser diferente del estado de la red si el nodo fue desconectado de la red, por ejemplo. Algunos subcampos importantes:
  - `edad`: tiempo transcurrido desde que este libro cerrado (durante la operación normal menos de 10 segundos)
  - `num`: número de ledger
  - `version`: versión de protocolo soportada por este ledger
- `network` la [frase de contraseña de red](../../learn/encyclopedia/network-configuration/network-passphrases.mdx) para la red que esta instancia del núcleo está usando
- `pares`: información sobre la conectividad a la red
  - `authated_count`: el número de conexiones live
  - `pending_count`: el número de conexiones que aún no están totalmente establecidas
- `protocol_version`: la versión máxima del protocolo que esta instancia reconoce
- `state`: el estado de sincronización del nodo relativo a la red
- `quorum`: resumen del estado de los participantes en el protocolo SCP, que es la misma información devuelta por el comando `quorum` ([ver abajo](#quorum-health)).

## Overlay Information

El comando `peers` devuelve información sobre los pares a los que tu nodo está conectado.

Esta lista es el resultado de ambas conexiones entrantes de otros pares y conexiones salientes de este nodo a otros pares. Si `compact=false` es usado en el comando, entonces también devuelve algunas métricas extra en cada par, como el número de mensajes soltados.

```bash
stellar-core http-comando 'pares'
```

La salida se verá algo como:

```json
{
  "authenticated_peers": {
    "inbound": [
      {
        "address": "18.234.41.75",
        "elapsed": 6,
        "flow_control": {
          "local_capacity": {
            "flood": 200,
            "reading": 200
          },
          "local_capacity_bytes": {
            "flood": 300000
          },
          "peer_capacity": 175,
          "peer_capacity_bytes": 291340
        },
        "id": "SDF 1",
        "latency": 172,
        "olver": 32,
        "ver": "stellar-core 20.4.0 (7fc7671b8bc1ccc3b1f16a6ab83bc9f671db8b70)"
      }
    ],
    "outbound": [
      {
        "address": "3.238.239.100:11625",
        "elapsed": 105,
        "flow_control": {
          "local_capacity": {
            "flood": 200,
            "reading": 200
          },
          "local_capacity_bytes": {
            "flood": 300000
          },
          "peer_capacity": 175,
          "peer_capacity_bytes": 291340
        },
        "id": "SDF 3",
        "latency": 172,
        "olver": 32,
        "ver": "stellar-core 20.4.0 (7fc7671b8bc1ccc3b1f16a6ab83bc9f671db8b70)"
      },
      {
        "address": "85.190.254.217:11625",
        "elapsed": 295,
        "flow_control": {
          "local_capacity": {
            "flood": 200,
            "reading": 200
          },
          "local_capacity_bytes": {
            "flood": 300000
          },
          "peer_capacity": 169,
          "peer_capacity_bytes": 288408
        },
        "id": "SatoshiPay Frankfurt",
        "latency": 282,
        "olver": 32,
        "ver": "stellar-core 20.4.0 (7fc7671b8bc1ccc3b1f16a6ab83bc9f671db8b70)"
      }
    ]
  },
  "pending_peers": {
    "inbound": ["211.249.63.74:11625", "45.77.5.118:11625"],
    "outbound": ["178.21.47.226:11625", "178.131.109.241:11625"]
  }
}
```

### Encuesta de Topología de Capa

Hay un mecanismo de encuesta en la superposición que permite a un validador solicitar información de conexión de otros nodos en la red. La encuesta puede ser activada desde un validador, y inundará la red como cualquier otro mensaje, pero solicitará información de otros nodos sobre los cuales está conectado y un breve resumen de sus volúmenes de tráfico por conexión.

Por defecto, un nodo repetirá o responderá a un mensaje de encuesta si el mensaje se originó desde un nodo en el quórum transitorio del nodo receptor. Este comportamiento se puede anular estableciendo el campo `SURVEYOR_KEYS` en el archivo de configuración a un conjunto de nodos más restrictivo al que retransmitir o responder. Establece `SURVIVOR_KEYS` a `["$self"]` para no responder a las solicitudes de la encuesta completamente.

La encuesta trabaja en dos fases: la fase de recogida y la fase de presentación de informes. Durante la fase de recolección, los nodos registran información sobre sí mismos y sus pares, como el número de mensajes enviados a un par dado. Durante la fase de notificación, el encuestador solicita los resultados de la fase de recogida de los nodos de la red.

El encuestador comienza la fase de recogida emitiendo un `TimeSlicedSurveyStartCollectingMessage`. El encuestador finaliza la fase de recogida e inicia la fase de presentación de informes emitiendo un `TimeSlicedSurveyStopCollectingMessage`. Estos mensajes "iniciar/detener la recolección" aseguran que la fase de recolección sea aproximadamente igual en la duración de todos los nodos presentes durante la fase completa de recolección. Recomendamos enviar el mensaje "stop collecting" unos 20 minutos después del mensaje "start collecting". Si transcurren 30 minutos sin recibir un mensaje de "dejar de recoger", la encuesta cambiará automáticamente a la fase de informe.

Adicionalmente, los mensajes "stop/start collecting" contienen un campo `nonce` que identifica la instancia de la encuesta. El nonce en el mensaje "stop collecting" debe coincidir con el nonce del mensaje "start collecting". El encuestador debe elegir un entero sin signo aleatorio de 32 bits para la nueva.

Durante la fase de informes, el encuestador envía `TimeSlicedSurveyRequestMessage`s a nodos individuales para reunir la información que el nodo grabó durante la fase de recolección.

#### Script de Encuesta de Capa

Para simplificar la ejecución de una encuesta de superposición, stellar-core viene con un script [`OverlaySurvey.py`](https://github.com/stellar/stellar-core/blob/master/scripts/OverlaySurvey.py) en el directorio [`scripts`](https://github.com/stellar/stellar-core/tree/master/scripts). Este script recorre la red usando los puntos finales de la encuesta de superposición HTTP para construir un gráfico que contenga la topología de la red de superposición. El script genera este gráfico tanto en formato JSON como en GraphML. Puede analizar el archivo GraphML usando un visor GraphML como [Gephi](https://gephi.org/).

Un ejemplo de uso del script de la encuesta para ejecutar una encuesta de overlay es el siguiente:

```bash
$ encuesta de python3 OverlaySurvey.py -n http://127.0.0.1:11626 -c 20 -sr sr.json -gmlw gmlw.graphml
```

Los argumentos que utiliza este ejemplo son:

- subcomando `survey` - ejecuta la encuesta y analiza
  - `-n NODE`, `--node nodo` - dirección del nodo inicial de la encuesta
  - `-c DURACION`, `--collect-duration DURATION` - duración de la fase de recogida de la encuesta en minutos
  - `-gmlw GRAPHMLWRITE`, `--graphmlWrite GRAPHMLWRITE` - archivo de salida para el archivo graphml
  - `-sr SURVEYRESULT`, `--surveyResult SURVEYRESULT` - archivo de salida para los resultados de la encuesta

Por lo tanto, este ejemplo ejecutará una encuesta desde un nodo estelar-core corriendo en la máquina local con una duración de la fase de recolección de 20 minutos y la salida de los resultados a `sr. son` y `gmlw.graphml`.

El script de la encuesta contiene subcomandos adicionales y opciones para analizar los resultados de la encuesta. Puede encontrar una lista completa de subcomandos ejecutando:

```bash
$ python3 OverlaySurvey.py -h
```

Desde ahí, puedes correr:

```bash
$ python3 OverlaySurvey.py <subcommand> -h
```

para más información sobre cualquier subcomando.

#### Comando de Ejemplo de Encuesta Usando Endpoints HTTP

Esta sección recorre un ejemplo de cómo ejecutar una encuesta de superposición llamando directamente a los puntos finales de la encuesta HTTP. Recomendamos encarecidamente usar el script de encuesta de overlay en su lugar. Esta sección puede ser útil para cualquiera que quiera modificar el script de la encuesta, o cualquiera que tenga curiosidad sobre los detalles de nivel inferior de cómo funciona la encuesta y los datos que incluye.

En este ejemplo, tenemos tres nodos `GBBN`, `GDEX` y `GBUI` (los referiremos por las primeras cuatro letras de sus claves públicas). Ejecutaremos los siguientes comandos desde `GBUI`, y observaremos que `GBBN` tiene `SURVEYOR_KEYS=["$self"]` en su archivo de configuración, así que `GBBN` no repetirá ni responderá a ningún mensaje de encuesta.

```bash
# 1. Comience la fase de recolección del encuestador
stellar-core http-command 'startsurveycollecting?nonce=1234'
# 2. Detener la fase de recolección del protector y comenzar la fase de reporte
stellar-core http-command 'stopsurveycollecting?nonce=1234'
# 3. Solicitar resultados de la encuesta del nodo `GBBN`
stellar-core http-command 'surveytopologytimesliced?node=GBBNXPPGDFDUQYH6RT5VGPDSOWLZEXFD3ACUPG5YXRHLTATTUKY42CL&inboundpeerindex=0&outboundpeerindex=0'
# 4. Solicitar resultados de la encuesta del nodo `GDEX`
stellar-core http-command 'surveytopologytimesliced?node=GDEXJV6XKKLDUWKTSXOOYVOYWZGVNIKKQ7GVNR5FOV7V5K4MGJT5US4&inboundpeerindex=0&outboundpeerindex=0'
# 3. Recuperar y mostrar los resultados de los comandos de encuesta emitidos
stellar-core http-command 'getsurveyresult'
```

Una vez recibidas las respuestas, el comando `getsurveyresult` devolverá un resultado como este:

```json
{
  "backlog": [],
  "badResponseNodes": null,
  "surveyInProgress": true,
  "topology": {
    "GBBNXPPGDFDUQYH6RT5VGPDSOWLZEXXFD3ACUPG5YXRHLTATTUKY42CL": null,
    "GDEXJV6XKKLDUWKTSXOOYVOYWZGVNIKKQ7GVNR5FOV7VV5K4MGJT5US4": {
      "inboundPeers": [
        {
          "bytesRead": 26392,
          "bytesWritten": 26960,
          "duplicateFetchBytesRecv": 0,
          "duplicateFetchMessageRecv": 0,
          "duplicateFloodBytesRecv": 10424,
          "duplicateFloodMessageRecv": 43,
          "messagesRead": 93,
          "messagesWritten": 96,
          "nodeId": "GBBNXPPGDFDUQYH6RT5VGPDSOWLZEXXFD3ACUPG5YXRHLTATTUKY42CL",
          "secondsConnected": 22,
          "uniqueFetchBytesRecv": 0,
          "uniqueFetchMessageRecv": 0,
          "uniqueFloodBytesRecv": 11200,
          "uniqueFloodMessageRecv": 46,
          "version": "v12.2.0-46-g61aadd29"
        },
        {
          "bytesRead": 32204,
          "bytesWritten": 31212,
          "duplicateFetchBytesRecv": 0,
          "duplicateFetchMessageRecv": 0,
          "duplicateFloodBytesRecv": 11200,
          "duplicateFloodMessageRecv": 46,
          "messagesRead": 115,
          "messagesWritten": 112,
          "nodeId": "GBUICIITZTGKL7PUBHUPWD67GDRAIYUA4KCOH2PUIMMZ6JQLNVA7C4JL",
          "secondsConnected": 23,
          "uniqueFetchBytesRecv": 176,
          "uniqueFetchMessageRecv": 2,
          "uniqueFloodBytesRecv": 14968,
          "uniqueFloodMessageRecv": 62,
          "version": "v12.2.0-46-g61aadd29"
        }
      ],
      "numTotalInboundPeers": 2,
      "numTotalOutboundPeers": 0,
      "maxInboundPeerCount": 64,
      "maxOutboundPeerCount": 8,
      "addedAuthenticatedPeers": 0,
      "droppedAuthenticatedPeers": 0,
      "p75SCPFirstToSelfLatencyMs": 72,
      "p75SCPSelfToOtherLatencyMs": 112,
      "lostSyncCount": 0,
      "isValidator": false,
      "outboundPeers": null
    }
  }
}
```

En este ejemplo, ten en cuenta que el nodo `GBBN` bajo el campo `topology` tiene un valor `null` porque está configurado para no responder al mensaje de la encuesta.

Algunos campos notables de este punto final 'getsurveyresult' son:

- `backlog`: Lista de nodos para los cuales la solicitud de encuesta aún está por ser enviada
- `badResponseNodes`: Lista de nodos que enviaron una respuesta mal formada
- `topology`: Mapa de nodos a la información de conexión
  - `inboundPeers`/`outboundPeers`: Lista de información de conexión por nodos
    - `promedio de latencias`: Promedio de latencia con este par en milisegundos.
    - `bytesRead`: El número total de bytes leídos de este par.
    - `bytesWritten`: El número total de bytes escritos a este par.
    - `duplicateFetchBytesRecv`: El número de bytes recibidos que fueron duplicados conjuntos de transacciones y conjuntos de quórum.
    - `duplicateFetchMessageRecv`: El recuento de conjuntos de transacciones duplicadas y conjuntos de quórum recibidos de este par.
    - `duplicateFloodBytesRecv`: El número de bytes recibidos que fueron transacciones y votos SCP duplicados.
    - `duplicateFloodMessageRecv`: El recuento de transacciones duplicadas y votos SCP recibidos de este par.
    - `messagesRead`: El número total de mensajes leídos de este par.
    - `messagesWritten`: El número total de mensajes escritos a este par.
    - `nodeId`: Clave pública de Node.
    - `secondsConnected`: El número total de segundos que este par ha sido conectado al nodo encuestado.
    - `uniqueFetchBytesRecv`: El número de bytes recibidos que eran conjuntos de transacciones únicas y conjuntos de quórum.
    - `uniqueFetchMessageRecv`: El recuento de conjuntos de transacciones únicas y conjuntos de quórum recibidos de este par.
    - `uniqueFloodBytesRecv`: El número de bytes recibidos que fueron transacciones únicas y votos SCP.
    - `uniqueFloodMessageRecv`: El recuento de transacciones únicas y votos SCP recibidos de este par.
    - `version`: versión stellar-núcleo.
- `numTotalInboundPeers`/`numTotalOutboundPeers`: El número total de pares entrantes y salientes a los que este nodo está conectado. La respuesta tendrá un subconjunto aleatorio de 25 pares conectados por dirección (inbound/outbound). Estos campos le dicen si faltan nodos así que puede enviar otra solicitud para obtener otro subconjunto aleatorio de nodos.
- `maxInboundPeerCount`/`maxOutboundPeerCount`: El número total de pares entrantes y salientes que este nodo puede aceptar. Estos campos corresponden a configuraciones stellar-core `MAX_ADDITIONAL_PEER_CONNECTIONS` y `TARGET_PEER_CONNECTIONS`, respectivamente.
- `addedAuthenticatedPeers`: El número de pares autenticados añadidos.
- `droppedAuthenticatedPeers`: El número de pares autenticados ha caído.
- `p75SCPFirstToSelfLatencyMs`: 75a latencia percentil para escuchar sobre nuevos mensajes SCP en milisegundos.
- `p75SCPSelfToOtherLatencyMs`: 75a latencia percentil para otros nodos para escuchar los mensajes SCP de este nodo en milisegundos.
- `lostSyncCount`: El número de veces que este nodo perdió la sincronización.
- `isValidator`: ¿Es este nodo un validador?

## Salud del quórum

Para ayudar a los operadores de nodos a monitorear sus conjuntos de quórum y mantener la salud de la red general El núcleo estelar también proporciona métricas en otros nodos del conjunto de quórum. Deberías controlarlos para asegurarte de que están funcionando y que su conjunto de quórum mantiene buenas coincidencias con el resto de la red.

### Diagnósticos de Quorum Set

El comando `quorum` le permite diagnosticar problemas con el conjunto de quórum del nodo local.

Si ejecutas:

```bash
comando 'quorum' stellar-core http'
```

La salida se verá algo como:

```json
{
  "node": "GCTSF",
  "qset": {
    "agree": 6,
    "cost": 20883268,
    "delayed": null,
    "disagree": null,
    "fail_at": 2,
    "fail_with": ["sdf_watcher1", "sdf_watcher2"],
    "hash": "d5c247",
    "lag_ms": {
      "sdf_watcher1": 192,
      "sdf_watcher2": 215,
      "sdf_watcher3": 79,
      "stronghold1": 321,
      "eno": 266,
      "tempo.eu.com": 225,
      "satoshipay": 249
    },
    "ledger": 24311847,
    "missing": ["stronghold1"],
    "phase": "EXTERNALIZE",
    "value": {
      "t": 3,
      "v": [
        "sdf_watcher1",
        "sdf_watcher2",
        "sdf_watcher3",
        {
          "t": 3,
          "v": ["stronghold1", "eno", "tempo.eu.com", "satoshipay"]
        }
      ]
    }
  },
  "transitive": {
    "critical": [["GDM7M"]],
    "intersection": true,
    "last_check_ledger": 24311536,
    "node_count": 21
  }
}
```

Esta salida tiene dos secciones principales: `qset` y `transitive`. La primera describe el nodo y su conjunto de quórum. Esta última describe el cierre transitorio del conjunto de quórum del nodo.

### Información de Quorum set por nodo

Las entradas para observar en la sección `qset`, que describen el nodo y su conjunto de quórum, son:

- `de acuerdo`: el número de nodos en el conjunto de quórum que parecen estar funcionando como se esperaba. El nodo local no tiene ninguna razón para creer que este nodo es `delayed`, `disagree` o `falta`. Tenga en cuenta que `agree` no tiene nada que ver con términos SCP como "accept" o "confirmando".
- `delayed`: los nodos que están participando en el consenso pero parecen estar atrás.
- `disagree`: los nodos que están participando pero que no están de acuerdo con esta instancia.
- `fail_at`: el número de nodos fallidos que _would_ causan que esta instancia se detuva.
- `fail_with`: un ejemplo de tal fallo potencial.
- `falta`: los nodos que aparecen en esta ronda de consenso.
- `value`: el quórum usado por este nodo (`t` es el umbral expresado como un número de nodos).

En el ejemplo anterior, 6 nodos están funcionando correctamente, uno está abajo (`stronghold1`), y la instancia fallará si los dos nodos que aún funcionen (o un nodo y uno interior de quorum-set) fallan también.

Si un nodo está atascado en estado `Uniendo SCP`, este comando permite encontrar rápidamente la razón:

- demasiados validadores que faltan (abajo o sin una buena conectividad), las soluciones son:
  - [ajusta tu conjunto de quórum](./configuring.mdx#eligiendo-tu-quorum-set) (umbrales, agrupación, etc.) basado en los nodos que no faltan
  - intenta obtener una [mejor ruta de conectividad](./configuring.mdx#quorum-and-overlay-network) a los validadores faltantes
- la división de red causaría que SCP se pegara debido a los nodos que no están de acuerdo. Esto sucedería si hay un error en SCP, la red no tiene intersección de quórum, o los nodos que no están de acuerdo son erróneos (comprometidos, etc.).

Tenga en cuenta que el nodo no ser capaz de alcanzar el consenso no significa que la red en su conjunto sea incapaz de alcanzar el consenso (y lo contrario es verdadero). la red puede fallar debido a un conjunto diferente de validadores que fallan).

Se puede obtener una sensación del estado de quórum de un nodo diferente usando:

```bash
# el `NAME` de un validador
stellar-core http-command 'quorum?node=$sdf1'
# O el `PUBLIC_KEY` de un validador
stellar-core http-command 'quorum?node=@GABCDE'
```

La salud general de la red se puede evaluar caminando por todos los nodos y mirando su salud. Tenga en cuenta que esto es sólo una aproximación, como nodos remotos pueden no haber recibido los mismos mensajes (en particular: `faltante` para otros nodos no es fiable).

### Resumen de Closure Transitive

Cuando se muestra información de quórum sobre el nodo local en lugar de algún otro nodo, también se proporciona un resumen del cierre transitorio del conjunto de quórum en el campo `transitive`. Esto tiene varios subcampos importantes:

- `last_check_ledger`: el último libro en el que el cierre transitorio fue comprobado para la intersección de quórum. Esto se restablecerá cuando el nodo arranca y cada vez que un nodo del quórum transitivo cambie su conjunto de quórum. Puede retrasarse detrás del último contador cerrado por unos cuantos contadores dependiendo del costo computacional de comprobar la intersección de quórum.
- `node_count`: el número de nodos en el cierre transitorio, que se consideran al calcular la intersección de quórum.
- `intersección`: si el cierre transitorio disfrutaba o no de la intersección de quórum en la comprobación más reciente. Esto es de **máxima importancia** en la prevención de divisiones de red. Siempre debería ser cierto. Si alguna vez es falso, uno o más nodos en el cierre transitorio del conjunto de quórum está _actualmente_ mal configurado, y la red corre el riesgo de dividirse. Se deben tomar medidas correctivas inmediatamente, para las que se presentarán dos subcampos adicionales para ayudar a sugerir medios:
  - `last_good_ledger`: esto notará el último libro para el cual el campo `intersection` fue evaluado como verdadero; si algún nodo reconfigurado en o alrededor de ese ledger, revertir ese cambio de configuración es la acción correctiva más fácil de tomar.
  - `potential_split`: este contendrá un par de listas de identificadores de validador, que es un par potencial de quórum desarticulado permitido por la configuración actual. En otras palabras, una posible división en el consenso permitido por la configuración actual. Esto puede ayudar a limitar la causa de la mala configuración: probablemente involucre un umbral de consenso demasiado bajo en uno de los dos posibles quórumes, y/o la ausencia de una relación de fideicomiso obligatoria que pudiera tender un puente entre ambos.
- `critical`: un campo de "aviso previo" que lista los nodos que _podrían causar_ que la red no pudiera disfrutar de intersección con quórum, si estaban mal configurados. En una configuración de red transitoria saludable, este campo será `null`. Si no es `null` entonces la red está esencialmente "una mala configuración" (de los conjuntos de quórum de los nodos listados) lejos de dejar de disfrutar de la intersección de quórum, y de nuevo, se debe tomar una acción correctiva: ajuste cuidadoso a los conjuntos de _nodos quórum que dependen de_ los nodos listados, típicamente para fortalecer los quórum que dependen de ellos.

### Análisis de Quórum Transitivo detallado

El punto final del quórum también puede recuperar información detallada sobre el quórum transitorio. Este es un formato que es más fácil de procesar que lo que `scp` regresa, ya que no contiene todos los mensajes SCP.

```bash
stellar-core comando http-'quorum?transitive=true'
```

La salida se ve algo como:

```json
{
  "critical": null,
  "intersection": true,
  "last_check_ledger": 121235,
  "node_count": 4,
  "nodes": [
    {
      "distance": 0,
      "escuchado": 121235,
      "node": "GB7LI",
      "qset": {
        "t": 2,
        "v": ["sdf1", "sdf2", "sdf3"]
      },
      "status": "seguimiento",
      "value": "[ txH: d99591, ct: 1557426183, actualizaciones: [ ] ]",
      "valor_id": 1
    },
    {
      "distance": 1,
      "oído": 121235,
      "node": "sdf2",
      "qset": {
        "t": 2,
        "v": ["sdf1", "sdf2", "sdf3"]
      },
      "status": "tracking",
      "value": "[ txH: d99591, ct: 1557426183, actualizaciones: [ ] ]",
      "valor_id": 1
    },
    {
      "distance": 1,
      "oído": 121235,
      "node": "sdf3",
      "qset": {
        "t": 2,
        "v": ["sdf1", "sdf2", "sdf3"]
      },
      "status": "seguimiento",
      "value": "[ txH: d99591, ct: 1557426183, actualizaciones: [ ] ]",
      "valor_id": 1
    },
    {
      "distance": 1,
      "oído": 121235,
      "node": "sdf1",
      "qset": {
        "t": 2,
        "v": ["sdf1", "sdf2", "sdf3"]
      },
      "status": "seguimiento",
      "valor": "[ txH: d99591, ct: 1557426183, actualizaciones: [ ] ]",
      "value_id": 1
    }
  ]
}
```

La salida comienza con la misma información de resumen que en el bloque `transitive` de la consulta no transitiva (si se consulta para el nodo local), pero también incluye una matriz `nodes` que representa una caminata del quórum transitivo centrada en el nodo de consulta.

Los campos notables contenidos en esta respuesta son:

- `node`: la identidad del validador
- `distance`: qué tan lejos está ese nodo del nodo raíz (es decir, cuántos saltos de quórum)
- `escuchar`: el último número de secuencia de contadores en el que este nodo emite un voto
- `qset`: el conjunto de quórum del nodo
- `status`: uno de `behind|tracking|ahead` (comparado con el nodo raíz) o `ausente|unknown` (cuando no hay mensajes SCP recientes para ese nodo)
- `value_id`: un ID único para lo que el nodo está votando (le permite saber rápidamente si los nodos están votando por la misma cosa)
- `valor`: qué está votando el nodo

## Usando Prometeo

Monitorear `stellar-core` usando Prometheus es con diferencia la solución más sencilla, especialmente si ya tienes un servidor Prometheus dentro de tu infraestructura. Prometheus es una base de datos libre y de código abierto con un lenguaje de consulta simple pero increíblemente potente `PromQL`. Prometheus también está fuertemente integrado con Grafana, por lo que puedes realizar visualizaciones complejas con facilidad.

Para que Prometheus rasque las métricas de aplicación `stellar-core`, necesitará instalar el exportador de stellar-core-prometheub (`apt-get install stellar-core-prometheum-exporter`) y configurar su servidor de Prometheus para raspar este exportador (por defecto: `9473`). En la parte superior de ese grafito se puede utilizar para visualizar métricas.

### Instalar un servidor Prometheus dentro de su infraestructura

La instalación y configuración de un servidor Prometheus está fuera del ámbito de este documento, Sin embargo, es un proceso bastante simple: Prometheus es un único binario Go que se puede descargar de https://prometheus. o/docs/prometheus/latest/installation/.

### Instala el exportador \`stellar-core-promethe→

El exportador de stellar-core-promethe)[video] es un exportador que raspa el punto final de las métricas `stellar-core` (`http://localhost:11626/metrics`) y las hace en el formato basado en texto Prometheus disponible para que Prometheus rasque y almacene en su base de datos de series de tiempo.

El exportador necesita ser instalado en cada nodo de núcleo estelar que desee monitor.

```bash
apt-get install stellar-core-prometheus-exporter
```

Necesitarás abrir el puerto `9473` entre tu servidor Prometheus y todos tus nodos Núcleo Stellar para que tu servidor Prometheus pueda raspar métricas.

### Apunta a Prometeo a un exportador estelar-core-prometo

Señalar su instancia de Prometheus al exportador se puede lograr configurando manualmente un trabajo de scrape; sin embargo, dependiendo del número de anfitriones que necesite para monitorear esto rápidamente puede volverse inmanejable. Por suerte, el proceso también se puede automatizar usando los distintos plugins de Prometheus "service discovery". Por ejemplo con la instancia alojada en AWS puedes usar el plugin `ec2_sd_config`.

#### Manual

```yaml
- job_name: "stellar-core"
  scrape_interval: 10s
  scrape_timeout: 10s
  static_configs:
    - targets: [
          "core-node-001. xample. om:9473",
          "core-node-002.example. om:9473",
        ] # stellar-core-prometheo's exporter default port is 9473
    - labels:
      application: "stellar-core"
```

#### Utilizando Service Discovery (EC2)

```yaml
- job_name: stellar-core
  scrape_interval: 10s
  scrape_timeout: 10s
  ec2_sd_configs:
    - region: eu-west-1
      port: 9473
  relabel_configs:
    # ignore stopped instances
    - source_labels: [__meta_ec2_instance_state]
      regex: stopped
      action: drop
    # only keep with `core` in the Name tag
    - source_labels: [__meta_ec2_tag_Name]
      regex: "(. núcleo. )"
      action: keep
    # use Name tag as instance label
    - source_labels: [__meta_ec2_tag_Name]
      regex: "(. )"
      : reemplace
      replacement: "${1}"
      target_label: instance
    # set application label to stellar-core
    - source_labels: [__meta_ec2_tag_Name]
      regex: "(. core.*)"
      acción: reemplazar
      reemplazo: stellar-core
      target_label: aplicación
```

### Crear reglas de alerta

Una vez que Prometheus recorre las métricas podemos añadir normas de alerta. Las reglas recomendadas son [**aquí**](https://github.com/stellar/packages/blob/master/docs/stellar-core-alerting.rules) (require Prometheus 2.0 o posterior). Copie las reglas a _/etc/prometheus/stellar-core-alerting.rules_ en el servidor Prometheus y añada lo siguiente al archivo de configuración prometheus para incluir el archivo:

```yaml
rule_files:
  - "mañ/prometheus/stellar-core-alerting.rules"
```

Las reglas están documentadas en línea, y recomendamos encarecidamente que las revise y verifique ya que cada entorno es diferente.

### Configurar notificaciones usando Alertmanager

Alertmanager es responsable del envío de notificaciones. La instalación y configuración de un servidor Alertmanager está fuera del ámbito de este documento, pero es un proceso bastante simple. La documentación oficial es [here](https://github.com/prometheus/alertmanager/).

Todas las reglas de alerta recomendadas tienen la etiqueta "severidad":

- El **crítico** normalmente requiere atención inmediata. Indican una interrupción continua o muy probable. Recomendamos que las alertas críticas notifiquen a los administradores 24x7
- El **aviso** normalmente puede esperar hasta horas laborables. Las advertencias indican problemas que probablemente no tengan impacto en la producción, pero pueden llevar a alertas críticas o interrupciones si no se manejan

La siguiente configuración del gestor de alertas muestra cómo enviar notificaciones utilizando diferentes métodos basados en la etiqueta de gravedad:

```yaml
global:
  smtp_smarthost: localhost:25
  smtp_from: alertmanager@example. om
ruta:
  receptor: default-receiver
  group_by: [alertname]
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 1h
  ruta:
    - receptor: critical-alerts
      coincidencia:
        severidad: crítico
    - receptor: warning-alerts
      match:
        severity: warning
receivers:
  - name: critical-alerts
    pagerduty_configs:
      - routing_key: <PD routing key>
  - name: warning-alerts
    slack_configs:
      - api_url: https://hooks. lack.com/services/slack/warning/channel/webhook
  - name: default-receiver
    email_configs:
      - to: alerts-fallback@example.com
```

En los ejemplos anteriores, las alertas con severidad "crítica" se envían a pagerduty y las advertencias se envían al slack.

### Exportadores útiles

Usted puede encontrar los exportadores de abajo útiles para monitorear su infraestructura ya que proporcionan una visión increíble de su sistema operativo y métricas de base de datos. Instalar y configurar estos exportadores está fuera del alcance de este documento, pero debería ser relativamente sencillo.

- [node_exporter](https://prometheus.io/docs/guides/node-exporter/) puede utilizarse para rastrear todas las métricas del sistema operativo.
- [postgresql_exporter](https://github.com/uesnel/postgres_exporter) puede utilizarse para supervisar la base de datos local de stellar-core .

### Visualizar métricas utilizando Grafana

Una vez que haya configurado Prometheus para rascar y almacenar sus métricas de núcleo estelar, querrá una buena manera de renderizar estos datos para el consumo humano. Grafana ofrece la forma más simple y eficaz de lograrlo. La instalación de Grafana está fuera del ámbito de este documento pero es un proceso muy simple, especialmente cuando se utilizan [paquetes apt precompilados](https://grafana.com/docs/installation/debian/#apt-repository)

Recomendamos que los administradores importen los siguientes dos paneles de control en sus implementaciones de grafanos:

- [**Monitorización de Núcleo Estelar**](https://grafana.com/grafana/dashboards/10603) - muestra las métricas más importantes, el estado de los nodos e intenta superar problemas comunes. Es un buen punto de partida para la solución de problemas
- [**Stellar Core Full**](https://grafana.com/grafana/dashboards/10334) - muestra un simple resumen de salud, así como todas las métricas expuestas por el `stellar-core-prometheFirstexporter`. Es mucho más detallado que el _Stellar Core Monitoring_ y puede ser útil durante la resolución de problemas en profundidad
