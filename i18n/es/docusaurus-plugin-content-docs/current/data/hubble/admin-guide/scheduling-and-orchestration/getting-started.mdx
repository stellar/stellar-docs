---
title: Comenzando
sidebar_position: 20
---

import history_table_export from "/img/hubble/history_table_export.png";
import state_table_export from "/img/hubble/state_table_export.png";
import dbt_enriched_base_tables from "/img/hubble/dbt_enriched_base_tables.png";

[stellar-etl-airflow GitHub repository](https://github.com/stellar/stellar-etl-airflow/tree/master)

## Configuración de cuenta GCP

La Stellar Development Foundation ejecuta Hubble en GCP usando Composer y BigQuery. Para seguir el mismo despliegue necesitará tener acceso al proyecto GCP. Las instrucciones se pueden encontrar en la documentación [Comencemos](https://cloud.google.com/docs/get-started) de Google.

Nota: BigQuery y Composer deberían estar disponibles por defecto. Si no lo son, puedes encontrar instrucciones para habilitarlos en la documentación [BigQuery](https://cloud.google.com/bigquery?hl=en) o [Composer](https://cloud.google.com/composer?hl=en) de Google.

## Crear instancia de compositor GCP para ejecutar Airflow

Las instrucciones sobre cómo crear una instancia de GCP Composer para ejecutar Hubble se pueden encontrar en la sección [Installation and Setup](https://github.com/stellar/stellar-etl-airflow?tab=readme-ov-file#installation-and-setup) en el repositorio [stellar-etl-airflow](https://github.com/stellar/stellar-etl-airflow).

:::note

Los requerimientos de hardware pueden ser muy diferentes dependiendo de los datos de la red Stellar que usted requiera. Los valores por defecto de GCP pueden ser superior/inferiores a los requeridos.

:::

## Configurando el Airflow de GCP Composer

Hay dos cosas necesarias para la configuración y configuración de GCP Composer Airflow:

- Subir DAGs al cubo Composer Airflow
- Configure las variables de Airflow para su configuración GCP

Para instrucciones más detalladas, por favor vea la documentación [stellar-etl-airflow Installation and Setup](https://github.com/stellar/stellar-etl-airflow?tab=readme-ov-file#installation-and-setup).

### Subiendo DAGs

Dentro del repositorio [stellar-etl-airflow](https://github.com/stellar/stellar-etl-airflow) hay un script de shell [upload_static_to_gcs.sh](https://github.com/stellar/stellar-etl-airflow/blob/master/upload_static_to_gcs.sh) que subirá todos los DAGs y esquemas en tu cubo Composer Airflow.

Esto también puede hacerse usando el [gcloud CLI o consola](https://cloud.google.com/storage/docs/uploading-objects) y seleccionando manualmente los dags y esquemas que desea subir.

### Configurar variables de flujo de aire

Por favor vea la documentación [Explicación de variables de Airflow](https://github.com/stellar/stellar-etl-airflow?tab=readme-ov-file#airflow-variables-explication) para más información sobre lo que debe y necesita ser configurado.

## Ejecutando los DAGs

Para ejecutar un DAG todo lo que tiene que hacer es encender/apagar el DAG como se ve a continuación

![Alternar DAGs](/img/hubble/airflow_dag_toggle.png)

Puede encontrar más información sobre cada DAG en la documentación de [Diagramas DAG](https://github.com/stellar/stellar-etl-airflow?tab=readme-ov-file#dag-diagrams).

## DAG disponibles

Puede encontrar más información [here](https://github.com/stellar/stellar-etl-airflow/blob/master/README.md#public-dags)

### Tabla de Historial Exportar DAG

[Este DAG](https://github.com/stellar/stellar-etl-airflow/blob/master/dags/history_tables_dag.py):

- Exporta parte de las fuentes: contadores, operaciones, transacciones, transacciones, operaciones, efectos y activos de Stellar utilizando el lago de datos de archivos LedgerCloseMeta
  - Opcionalmente, esto puede ingerir datos usando el núcleo cautivo, pero no es ideal ni recomendable para su uso con Airflow
- Insertos en BigQuery

<img src={history_table_export} width="300" />

### Tabla de Estado Exportar DAG

[Este DAG](https://github.com/stellar/stellar-etl-airflow/blob/master/dags/state_table_dag.py)

- Exporta cuentas, signatarios, ofertas, saldos de reclamación, reservas de liquidez, líneas de confianza, contract_data, contract_code, config_settings y ttl.
- Insertos en BigQuery

<img src={state_table_export} width="300" />

### DBT Tablas Base Enriched DAG

[Este DAG](https://github.com/stellar/stellar-etl-airflow/blob/master/dags/dbt_enriched_base_tables_dag.py)

- Crea las vistas de escenificación de DBT para modelos
- Actualiza la tabla enriched_history_operations
- Actualiza las tablas de estado actuales
- (Opcional) advertencias y errores se envían al slack.

<img src={dbt_enriched_base_tables} width="300" />
