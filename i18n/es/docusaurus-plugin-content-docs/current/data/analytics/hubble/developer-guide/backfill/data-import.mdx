---
title: Importación de Datos
sidebar_position: 0
---

Este documento describe métodos para realizar un respaldo inicial al configurar hubble.

# Usar SDF ETL Data como Fuente

## 1. Exportar Datos a Almacenamiento en la Nube y Cargar Datos en BigQuery

- Usa el comando [EXPORT](https://cloud.google.com/bigquery/docs/reference/standard-sql/export-statements) proporcionado por Google Cloud Platform (GCP) para exportar tu conjunto de datos en el formato requerido (por ejemplo, Avro, Parquet).
- Usa el comando [LOAD](https://cloud.google.com/bigquery/docs/reference/standard-sql/load-statements) para cargar los archivos exportados en tu conjunto de datos de BigQuery.

#### Ejemplo:

```sql
EXPORT DATA OPTIONS(
  uri='gs://my-bucket/history-transactions/*',
  format='PARQUET',
  overwrite=true) AS
SELECT * FROM crypto-stellar.crypto_stellar.history_transactions;

LOAD DATA INTO mydataset.transactions
  FROM FILES(
    format='PARQUET',
    uris = ['gs://my-bucket/history-transactions/*']
  )
  WITH PARTITION COLUMNS;
```

## 2. Usa la API / Consola de BigQuery para reflejar el conjunto de datos de SDF

La Stellar Development Foundation proporciona acceso público a los datos totalmente transformados de la red Stellar a través de los conjuntos de datos y tablas públicas en GCP BigQuery. Las instrucciones sobre cómo acceder a estos datos se pueden encontrar en la sección de [Conexión](../../developer-guide/connecting-to-bigquery/README.mdx).

Usa la declaración [Create Table Copy](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#create_table_copy) para copiar datos entre conjuntos de datos.

```sql
CREATE [ OR REPLACE ] TABLE [ IF NOT EXISTS ] table_name
COPY source_table_name
...
[OPTIONS(table_option_list)]
```

# Usar Galexie como fuente

[Galexie](../../../../indexers/build-your-own/galexie/README.mdx) es una herramienta para extraer, procesar y exportar metadatos del ledger Stellar a almacenamiento externo, creando un lago de datos de metadatos del ledger preprocesados. Esta es una fuente de datos ascendente para Hubble, útil cuando tienes un pipeline personalizado de Stellar-ETL.

**Pasos**

1. Asegúrate de proporcionar el valor correcto para datastore-path en los [flags de comando](https://github.com/stellar/stellar-etl/tree/master?tab=readme-ov-file#common-flags) de Stellar-ETL. Esto representa el nombre del bucket donde tu instancia de Galexie genera metadatos de cierre del ledger.
2. Configura un [sistema de orquestación como Airflow](../../developer-guide/scheduling-and-orchestration/getting-started.mdx).
3. En tu instancia de Airflow, activa el DAG history_table_export para fechas anteriores.
